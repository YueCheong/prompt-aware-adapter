| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[4]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[4]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 6:18:56  lr: 0.000001  loss: 1.9912  time: 22.7367  data: 0.0000  max mem: 35964
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 0:35:24  lr: 0.000001  loss: 1.7866  time: 2.1246  data: 0.0000  max mem: 26889
Train: data epoch: [0]  [  50/1000]  eta: 0:05:49  lr: 0.000001  loss: 1.5609  time: 0.3295  data: 0.0000  max mem: 32124
Train: data epoch: [0]  [ 100/1000]  eta: 0:05:19  lr: 0.000002  loss: 1.5544  time: 0.3295  data: 0.0000  max mem: 32124
Train: data epoch: [0]  [ 150/1000]  eta: 0:04:55  lr: 0.000002  loss: 1.3489  time: 0.3361  data: 0.0000  max mem: 32124
Train: data epoch: [0]  [ 350/1000]  eta: 0:03:25  lr: 0.000004  loss: 2.0058  time: 0.3120  data: 0.0000  max mem: 28513
Train: data epoch: [0]  [ 400/1000]  eta: 0:03:09  lr: 0.000005  loss: 1.8311  time: 0.3091  data: 0.0000  max mem: 28513
Train: data epoch: [0]  [ 450/1000]  eta: 0:02:52  lr: 0.000005  loss: 1.9149  time: 0.3101  data: 0.0000  max mem: 28513
Train: data epoch: [0]  [ 500/1000]  eta: 0:02:37  lr: 0.000005  loss: 1.8184  time: 0.3087  data: 0.0000  max mem: 28513
Train: data epoch: [0]  [ 550/1000]  eta: 0:02:21  lr: 0.000006  loss: 1.7692  time: 0.3109  data: 0.0000  max mem: 28513
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 0:46:05  lr: 0.000001  loss: 1.8693  time: 2.7657  data: 0.0000  max mem: 34927
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[1]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 0:42:31  lr: 0.000001  loss: 1.6811  time: 2.5516  data: 0.0000  max mem: 26351
Train: data epoch: [0]  [  50/1000]  eta: 0:05:05  lr: 0.000001  loss: 1.6926  time: 0.2747  data: 0.0000  max mem: 30266
Train: data epoch: [0]  [ 100/1000]  eta: 0:04:28  lr: 0.000002  loss: 1.4194  time: 0.2735  data: 0.0000  max mem: 30266
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 7:32:11  lr: 0.000001  loss: 3.2093  time: 27.1313  data: 0.0000  max mem: 26096
Train: data epoch: [0]  [  50/1000]  eta: 0:13:46  lr: 0.000001  loss: 2.3012  time: 0.3232  data: 0.0000  max mem: 29333
Train: data epoch: [0]  [ 100/1000]  eta: 0:08:54  lr: 0.000002  loss: 1.7989  time: 0.3137  data: 0.0000  max mem: 29333
Train: data epoch: [0]  [ 150/1000]  eta: 0:07:07  lr: 0.000002  loss: 1.6141  time: 0.3202  data: 0.0000  max mem: 30721
Train: data epoch: [0]  [ 200/1000]  eta: 0:06:05  lr: 0.000003  loss: 1.7609  time: 0.3189  data: 0.0000  max mem: 30721
Train: data epoch: [0]  [ 250/1000]  eta: 0:05:21  lr: 0.000003  loss: 1.6330  time: 0.3182  data: 0.0000  max mem: 30980
Train: data epoch: [0]  [ 300/1000]  eta: 0:04:47  lr: 0.000004  loss: 1.4877  time: 0.3187  data: 0.0000  max mem: 30980
Train: data epoch: [0]  [ 350/1000]  eta: 0:04:18  lr: 0.000004  loss: 1.4831  time: 0.3209  data: 0.0000  max mem: 30980
Train: data epoch: [0]  [ 400/1000]  eta: 0:03:52  lr: 0.000005  loss: 1.6265  time: 0.3117  data: 0.0000  max mem: 30980
Train: data epoch: [0]  [ 450/1000]  eta: 0:03:28  lr: 0.000005  loss: 1.1972  time: 0.3186  data: 0.0000  max mem: 30980
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
CaptionToObject instruction <Img><ImageHere></Img> [detection] Lone person in a canoe , holding a rope , enjoying the scenery of the blue mountains and glassy water 
CaptionToObject answer <p>Lone person</p> {<63><43><77><60>}
<p>a canoe</p> {<39><47><82><64>}
<p>a rope</p> {<63><45><68><56>}
<p>the scenery of the blue mountains</p> {<1><21><100><44>}
<p>glassy water</p> {<0><41><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a gray jacket and khaki pants stands on dead grass next to a lake 
CaptionToObject answer <p>A man</p> {<12><58><37><100>}
<p>a gray jacket</p> {<10><63><39><86>}
<p>khaki pants</p> {<15><83><33><99>}
<p>dead grass</p> {<0><82><49><100>}
<p>a lake</p> {<0><10><100><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A cook in a restaurant wearing a colorful hat , standing in front of a lamb rotisserie , squeezes a sauce onto food wrapped in foil while another man watches with his back turned 
CaptionToObject answer <p>A cook</p> {<24><0><85><100>}
<p>a restaurant</p> {<1><1><100><100>}
<p>a colorful hat</p> {<47><0><80><34>}
<p>a lamb rotisserie</p> {<3><22><22><88>}
<p>a sauce</p> {<25><77><44><96>}
<p>foil</p> {<11><92><41><100>}
<p>another man</p> {<57><15><100><100>}
<p>his back</p> {<60><66><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing sunglasses , a black shirt and gray jeans is playing guitar on stage with a band 
CaptionToObject answer <p>A man</p> {<37><24><67><99>}
<p>sunglasses</p> {<42><29><50><42>}
<p>a black shirt</p> {<46><35><66><75>}
<p>gray jeans</p> {<46><71><65><100>}
<p>guitar</p> {<37><37><52><79>}<delim>{<1><78><9><91>}
<p>a band</p> {<37><24><67><99>}<delim>{<33><57><46><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with short brown hair wearing black pants , and a light blue sweater is smiling and skiing atop a snow covered mountain with a scenic view in the background 
CaptionToObject answer <p>A woman</p> {<53><24><74><93>}
<p>short brown hair</p> {<54><25><61><35>}
<p>black pants</p> {<56><57><72><86>}
<p>a light blue sweater</p> {<52><34><68><62>}
<p>a snow covered mountain</p> {<1><79><100><100>}
<p>a scenic view</p> {<0><31><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a woman in a coat watching a man in a jacket kick balls 
CaptionToObject answer <p>a woman</p> {<80><37><100><99>}
<p>a coat</p> {<81><46><99><76>}
<p>a man</p> {<32><37><47><75>}
<p>a jacket</p> {<32><42><44><57>}
<p>balls</p> {<33><72><62><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a suit presents a powerpoint presentation as a woman sits nearby , operating the computer 
CaptionToObject answer <p>A man</p> {<56><9><95><100>}
<p>a suit</p> {<64><26><95><100>}
<p>a powerpoint presentation</p> {<8><19><46><69>}
<p>a woman</p> {<24><53><49><90>}
<p>the computer</p> {<7><70><27><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with red-hair and a black shirt has her eyes closed and a mirror behind her 
CaptionToObject answer <p>A woman</p> {<1><1><80><100>}
<p>red-hair</p> {<14><0><76><86>}
<p>a black shirt</p> {<1><62><81><100>}
<p>her eyes</p> {<44><23><71><40>}
<p>a mirror</p> {<59><6><86><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A cowgirl in a white shirt and black hat riding a brown horse ropes a calf 
CaptionToObject answer <p>A cowgirl</p> {<58><25><74><72>}
<p>a white shirt</p> {<60><31><73><46>}
<p>black hat</p> {<62><24><69><32>}
<p>a brown horse</p> {<64><46><78><60>}
<p>a calf</p> {<19><54><51><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The batter keeps his eye on the ball during his follow through with the umpire and catcher watching on with onlookers watching behind a chain link fence 
CaptionToObject answer <p>The batter</p> {<68><46><81><82>}
<p>his eye</p> {<46><34><51><40>}
<p>the umpire</p> {<82><33><99><85>}
<p>catcher</p> {<64><47><82><84>}
<p>onlookers</p> {<64><47><82><84>}<delim>{<82><33><99><85>}<delim>{<40><22><49><63>}<delim>{<95><23><100><62>}<delim>{<64><40><70><61>}
<p>a chain link fence</p> {<1><0><100><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a beige and white striped shirt , brown shorts and shoes with one hand on his face and one foot up looks ahead 
CaptionToObject answer <p>A man</p> {<27><10><68><95>}
<p>a beige</p> {<40><19><68><54>}
<p>white striped shirt</p> {<40><19><68><54>}
<p>brown shorts</p> {<28><50><70><80>}
<p>shoes</p> {<25><80><46><88>}
<p>one hand</p> {<38><18><44><26>}
<p>his face</p> {<39><17><53><25>}
<p>one foot</p> {<25><82><44><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in pink and a man wearing an apron watch a food covered grill 
CaptionToObject answer <p>A woman</p> {<19><24><47><82>}
<p>pink</p> {<19><42><47><81>}
<p>a man</p> {<60><1><100><100>}
<p>an apron</p> {<63><71><93><100>}
<p>a food covered grill</p> {<1><82><68><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a hot pink inflatable bed is walking along the water with a young girl in a red dress 
CaptionToObject answer <p>A woman</p> {<45><19><59><94>}
<p>a hot pink inflatable bed</p> {<26><31><83><66>}
<p>the water</p> {<0><0><100><24>}
<p>a young girl</p> {<53><36><66><100>}
<p>a red dress</p> {<54><47><67><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a tuxedo shirt , vest , and bowtie is kissing another man wearing the same thing on the cheek 
CaptionToObject answer <p>A man</p> {<42><20><97><100>}
<p>a tuxedo shirt</p> {<1><41><50><100>}<delim>{<44><52><97><100>}
<p>vest</p> {<8><44><48><99>}<delim>{<47><55><73><100>}
<p>bowtie</p> {<45><55><67><73>}
<p>another man</p> {<42><20><71><52>}
<p>the same thing</p> {<1><41><82><100>}
<p>the cheek</p> {<44><32><47><45>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian man lies on a tiled floor with two children , using old clothes for pillows 
CaptionToObject answer <p>An Asian man</p> {<19><48><56><82>}
<p>a tiled floor</p> {<19><53><100><100>}
<p>two children</p> {<37><52><96><91>}<delim>{<70><45><100><60>}
<p>old clothes</p> {<69><54><85><62>}
<p>pillows</p> {<17><47><39><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a shorts and an orange tank top is kicking a very large red ball with people around him 
CaptionToObject answer <p>A man</p> {<54><13><87><87>}
<p>a shorts</p> {<66><40><81><63>}
<p>an orange tank top</p> {<69><25><84><54>}
<p>a very large red ball</p> {<50><18><67><39>}
<p>people</p> {<54><13><87><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with her face partially covered in silver face paint sits on a plastic tote looking in a mirror 
CaptionToObject answer <p>A woman</p> {<18><13><86><99>}
<p>her face</p> {<40><15><55><29>}
<p>silver face paint</p> {<41><15><51><28>}
<p>a plastic tote</p> {<1><69><55><100>}
<p>a mirror</p> {<66><15><79><24>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women riding in a bicycle wearing blue and orange dress on the streets and a man walking wearing a red shirt 
CaptionToObject answer <p>Two women</p> {<80><38><100><75>}<delim>{<60><46><70><66>}
<p>a bicycle</p> {<62><52><73><71>}
<p>blue and orange dress</p> {<81><44><93><62>}
<p>a man</p> {<19><66><30><94>}
<p>a red shirt</p> {<19><71><28><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Cowboy is riding a bucking horse in a red shirt , blue jeans , and cowboy boots in a rodeo 
CaptionToObject answer <p>Cowboy</p> {<7><37><39><79>}
<p>a bucking horse</p> {<1><41><68><100>}
<p>a red shirt</p> {<23><42><39><63>}
<p>blue jeans</p> {<10><55><33><71>}
<p>cowboy boots</p> {<10><74><16><80>}<delim>{<8><61><12><68>}
<p>a rodeo</p> {<1><28><100><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A child in a yellow plastic safety swing is laughing as a dark-haired woman in pink and coral pants stands behind her 
CaptionToObject answer <p>A child</p> {<36><46><100><95>}
<p>a yellow plastic safety swing</p> {<44><60><80><86>}
<p>a dark-haired woman</p> {<18><38><34><76>}
<p>pink</p> {<19><44><30><54>}
<p>coral pants</p> {<19><53><31><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A football game ; player 44 has the ball in a blue jersey with the opposition in white jerseys 
CaptionToObject answer <p>player 44</p> {<51><14><90><97>}
<p>the ball</p> {<54><41><62><50>}
<p>a blue jersey</p> {<52><27><81><56>}
<p>the opposition</p> {<28><7><64><63>}
<p>white jerseys</p> {<37><14><56><46>}<delim>{<11><23><24><43>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young topless man carries a Brazilian flag whilst wearing a colorful bracelet on his arm and flowers around his neck 
CaptionToObject answer <p>A young topless man</p> {<17><1><100><100>}
<p>a Brazilian flag</p> {<57><1><100><44>}
<p>a colorful bracelet</p> {<65><54><89><69>}
<p>his arm</p> {<24><52><94><92>}<delim>{<17><50><94><92>}
<p>flowers</p> {<32><39><100><94>}
<p>his neck</p> {<45><35><75><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brown and a black and brown dog are playing in the water and the black one is carrying a long stick in its mouth CaptionToObject instruction
 CaptionToObject answer<Img><ImageHere></Img> [detection] A Japanese man wearing a light-colored button-down shirt and brown slacks is speaking into a microphone with a white head  
<p>A brown</p> {<5><50><57><100>}
<p>a black and brown dog</p> {<70><25><100><90>}
<p>the black one</p> {<70><25><100><90>}
<p>a long stick</p> {<44><38><100><57>}
<p>its mouth</p> {<73><40><82><48>}<delim>{<73><38><83><46>}
CaptionToObject answer
 <p>A Japanese man</p> {<18><20><73><75>}
<p>a light-colored button-down shirt</p> {<25><32><73><59>}
<p>brown slacks</p> {<35><56><68><74>}
<p>a microphone</p> {<49><30><55><41>}
<p>a white head</p> {<49><30><55><34>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a redhead covering is standing with a man wear a shirt with stripes on it 
CaptionToObject answer <p>A woman</p> {<51><14><91><100>}
<p>a redhead</p> {<51><14><91><100>}
<p>a man</p> {<12><5><54><100>}
<p>a shirt</p> {<10><32><56><100>}
<p>stripes</p> {<17><75><48><81>}<delim>{<39><42><50><51>}<delim>{<17><66><49><72>}<delim>{<33><55><46><64>}

CaptionToObject instructionCaptionToObject instruction  <Img><ImageHere></Img> [detection] Three snake charmers stand in the road while one pulls a snake out of a box , and another large snake rears its head back in the fore-ground <Img><ImageHere></Img> [detection] A man wearing a blue denim shirt is standing in front of a man who is squirting a condiment on something 

CaptionToObject answerCaptionToObject answer  <p>Three snake charmers</p> {<5><21><37><69>}<delim>{<65><1><98><75>}<delim>{<45><0><68><58>}
<p>one</p> {<5><21><37><69>}
<p>a snake</p> {<41><83><71><95>}<delim>{<9><47><30><61>}
<p>a box</p> {<0><51><13><68>}
<p>another large snake</p> {<41><77><73><97>}
<p>its head</p> {<61><84><71><94>}
<p>A man</p> {<57><35><96><98>}
<p>a blue denim shirt</p> {<56><34><97><96>}
<p>a man</p> {<1><0><66><100>}
<p>a condiment</p> {<49><63><69><95>}
<p>something</p> {<39><68><62><100>}


CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women with long black hair , one in a denim jacket , the other in a black coat and holding her purse , ordering food at a restaurant 
CaptionToObject answer <p>Two women</p> {<12><27><45><100>}<delim>{<42><22><79><100>}
<p>long black hair</p> {<19><27><41><64>}<delim>{<48><23><69><58>}
<p>one</p> {<12><27><45><100>}
<p>a denim jacket</p> {<12><51><46><100>}
<p>the other</p> {<42><22><79><100>}
<p>a black coat</p> {<43><49><77><100>}
<p>her purse</p> {<72><82><82><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man in a black hat sits with a female in a pink shirt and jean shorts in an amphitheater in the city 
CaptionToObject answer <p>Man</p> {<1><38><63><99>}
<p>a black hat</p> {<46><37><57><50>}
<p>a female</p> {<1><47><56><99>}
<p>a pink shirt</p> {<31><59><53><90>}
<p>jean shorts</p> {<32><73><34><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man who appears to be the band leader is reading from a large white card which he is holding in his left hand , while facing persons holding tubas 
CaptionToObject answer <p>A man</p> {<30><34><73><100>}
<p>the band leader</p> {<30><34><73><100>}
<p>a large white card</p> {<45><61><72><82>}
<p>his left hand</p> {<54><72><64><90>}
<p>persons</p> {<0><27><31><100>}<delim>{<77><30><100><100>}
<p>tubas</p> {<1><1><49><100>}<delim>{<55><1><97><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt speaking with a man in a maroon shirt , while a man in a black shirt and jeans videotapes the conversation 
CaptionToObject answer <p>A man</p> {<26><47><41><64>}
<p>a blue shirt</p> {<29><33><61><78>}
<p>a man</p> {<29><17><60><99>}<delim>{<3><11><31><100>}<delim>{<64><12><99><100>}
<p>a maroon shirt</p> {<3><29><33><98>}<delim>{<3><28><29><94>}
<p>a black shirt</p> {<70><36><98><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men are walking up the stairs one is wearing a blue shirt and the other one is wearing a gray shirt 
CaptionToObject answer <p>Two men</p> {<18><13><38><97>}<delim>{<58><22><73><91>}
<p>the stairs</p> {<1><40><100><99>}
<p>a blue shirt</p> {<20><26><38><62>}
<p>the other one</p> {<58><22><73><91>}
<p>a gray shirt</p> {<59><32><74><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a ponytail is playing a decorated piano in the street next to a table with a red cloth 
CaptionToObject answer <p>A man</p> {<25><8><54><100>}
<p>a ponytail</p> {<41><12><49><32>}
<p>a decorated piano</p> {<1><7><44><100>}
<p>a table</p> {<51><60><85><100>}
<p>a red cloth</p> {<54><57><84><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue hat rests his head on a blue and cream bag , with his leg up , while looking at an out of focus woman in a field with yellow flowers 
CaptionToObject answer <p>A man</p> {<9><37><53><63>}
<p>a blue hat</p> {<33><42><50><61>}
<p>his head</p> {<33><46><49><63>}
<p>cream bag</p> {<13><58><68><86>}
<p>his leg</p> {<10><30><53><63>}
<p>an out of focus woman</p> {<52><46><66><67>}
<p>a field</p> {<0><51><100><85>}
<p>yellow flowers</p> {<52><49><100><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in an orange shirt and baseball cap sits in a grassy field next to a black ball 
CaptionToObject answer <p>A boy</p> {<14><18><56><88>}
<p>an orange shirt</p> {<14><39><44><83>}
<p>baseball cap</p> {<20><19><40><38>}
<p>a grassy field</p> {<1><12><100><100>}
<p>a black ball</p> {<68><64><85><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Child with pink strings on head dancing surrounded by confetti , balloons 
CaptionToObject answer <p>Child</p> {<21><3><93><97>}
<p>pink strings</p> {<36><0><70><17>}
<p>head</p> {<45><14><61><31>}
<p>confetti</p> {<88><61><100><81>}
<p>balloons</p> {<10><44><33><58>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a striped skirt and head covering is walking with a bowl on her head while a child follows behind 
CaptionToObject answer <p>A person</p> {<83><70><98><96>}
<p>a striped skirt</p> {<83><82><96><95>}
<p>a bowl</p> {<83><67><95><70>}
<p>her head</p> {<85><69><92><74>}
<p>a child</p> {<41><77><50><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person has jumped in the air with one foot stretched toward a man on the ground who is wearing a red shirt and a hat 
CaptionToObject answer <p>A person</p> {<28><10><61><66>}
<p>one foot</p> {<42><31><53><52>}
<p>a man</p> {<55><30><91><100>}
<p>a red shirt</p> {<67><50><90><92>}
<p>a hat</p> {<67><32><83><44>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two young men wearing potato sacks pull a decorated cart down a street onlookers watch on the side of the street 
CaptionToObject answer <p>Two young men</p> {<39><36><56><92>}<delim>{<26><37><42><93>}
<p>potato sacks</p> {<25><43><41><82>}<delim>{<39><44><56><87>}
<p>a decorated cart</p> {<4><19><65><92>}
<p>a street</p> {<1><52><100><100>}
<p>onlookers</p> {<57><37><100><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man sporting London olympic wear carries a torch down a road lined with spectators while a yellow BMW follows him 
CaptionToObject answer <p>A man</p> {<46><44><73><78>}
<p>London olympic wear</p> {<49><49><70><76>}
<p>a torch</p> {<40><40><53><60>}
<p>spectators</p> {<0><42><89><67>}
<p>a yellow BMW</p> {<68><50><100><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman walking in a large marble made hall with a jacket , jeans , boots , and a bag , with a few people behind walking in different directions behind her 
CaptionToObject answer <p>A woman</p> {<37><38><61><79>}
<p>a jacket</p> {<37><43><59><62>}
<p>jeans</p> {<40><60><54><68>}
<p>boots</p> {<41><66><56><79>}
<p>a bag</p> {<40><52><62><61>}
<p>a few people</p> {<27><36><40><58>}<delim>{<55><38><78><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three males and one female are posing for a photograph with snow on the ground and mountains covered with green trees and snow in the background 
CaptionToObject answer <p>Three males</p> {<58><29><82><94>}<delim>{<20><31><37><91>}<delim>{<36><31><53><94>}
<p>one female</p> {<50><36><63><93>}
<p>snow</p> {<0><71><100><100>}<delim>{<0><71><100><100>}
<p>mountains</p> {<0><24><99><72>}
<p>green trees</p> {<0><28><100><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl with long blond-hair wearing sunglasses , a jacket and gloves walks along side a street on a brick path 
CaptionToObject answer <p>A girl</p> {<44><12><96><94>}
<p>long blond-hair</p> {<59><12><82><34>}
<p>sunglasses</p> {<58><16><70><21>}
<p>a jacket</p> {<56><24><93><62>}
<p>gloves</p> {<54><53><61><61>}<delim>{<86><52><96><61>}
<p>a street</p> {<0><22><100><100>}
<p>a brick path</p> {<1><62><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two construction workers wearing yellow jackets work on their hands and knees on a street during the day 
CaptionToObject answer <p>Two construction workers</p> {<37><67><49><83>}<delim>{<40><61><56><75>}
<p>yellow jackets</p> {<44><61><54><75>}
<p>knees</p> {<40><78><45><85>}<delim>{<52><71><56><76>}
<p>a street</p> {<38><66><100><100>}
<p>the day</p> {<2><61><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a determined look on his face holds a small wooden hammer while wearing a bib displaying a large red crab , another red crustacean held in his hand while another man sits and holds some food behind him 
CaptionToObject answer <p>A man</p> {<23><0><100><100>}
<p>his face</p> {<57><2><82><42>}
<p>a small wooden hammer</p> {<85><2><100><54>}
<p>a bib</p> {<48><24><97><100>}
<p>a large red crab</p> {<54><68><74><99>}
<p>another red crustacean</p> {<35><67><52><85>}
<p>his hand</p> {<84><30><100><68>}<delim>{<23><61><42><86>}
<p>another man</p> {<2><12><51><68>}
<p>some food</p> {<37><68><51><84>}<delim>{<2><40><10><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man on a bicycle wearing an orange and black sweatshirt is carrying a long bunch of sticks 
CaptionToObject answer <p>A man</p> {<43><21><60><80>}
<p>a bicycle</p> {<33><46><76><95>}
<p>an orange</p> {<43><30><52><49>}
<p>black sweatshirt</p> {<43><37><53><59>}
<p>a long bunch of sticks</p> {<17><42><84><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women in traditional European dress sit on a stoop , one drinking , the other reading 
CaptionToObject answer <p>Two women</p> {<53><45><76><99>}<delim>{<31><41><55><85>}
<p>traditional European dress</p> {<53><45><76><99>}<delim>{<34><43><55><88>}
<p>a stoop</p> {<33><70><95><100>}
<p>one</p> {<34><43><55><88>}
<p>the other reading</p> {<53><45><76><99>}

CaptionToObject instructionCaptionToObject instruction  <Img><ImageHere></Img> [detection] A man in a white t-shirt is talking with another man in an orange shirt near a stone building with another man talking to someone in the car <Img><ImageHere></Img> [detection] A bridge with green supports leads to a sidewalk lining a row of houses with slanted roofs , a person is visible in the background walking towards the photographer past a bicycle 

CaptionToObject answerCaptionToObject answer  <p>A man</p> {<30><24><63><100>}
<p>a white t-shirt</p> {<36><39><62><79>}
<p>another man</p> {<82><20><100><99>}<delim>{<1><47><48><100>}
<p>an orange shirt</p> {<82><38><100><79>}
<p>a stone building</p> {<63><0><100><83>}
<p>the car</p> {<0><56><17><100>}
<p>green supports</p> {<32><30><87><92>}
<p>a sidewalk</p> {<23><66><97><100>}
<p>a row of houses</p> {<0><0><52><86>}
<p>slanted roofs</p> {<15><0><46><32>}
<p>a person</p> {<57><63><61><74>}
<p>the photographer</p> {<57><61><61><74>}
<p>a bicycle</p> {<48><67><53><76>}


CaptionToObject instruction <Img><ImageHere></Img> [detection] The older male wearing a green shirt and shorts with black hair is teaching the younger male , wearing a graphic tee with blond-hair how to play a game , called bump off 
CaptionToObject answer <p>The older male</p> {<16><1><100><53>}
<p>a green shirt</p> {<34><5><83><33>}
<p>shorts</p> {<44><30><100><51>}
<p>black hair</p> {<28><0><51><5>}
<p>the younger male</p> {<35><0><99><54>}
<p>a graphic tee</p> {<44><15><92><51>}
<p>blond-hair</p> {<51><0><78><13>}
<p>a game</p> {<1><50><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a long brown robe is playing the guitar while another person is sitting at the drums and yet another is wearing a long gray robe and singing 
CaptionToObject answer <p>A man</p> {<1><22><34><100>}
<p>a long brown robe</p> {<76><67><93><91>}<delim>{<0><34><25><100>}
<p>the guitar</p> {<9><52><40><82>}
<p>another person</p> {<21><47><34><74>}
<p>the drums</p> {<23><70><53><100>}
<p>a long gray robe</p> {<73><27><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in shorts and white top grilling meat on a bar-b-que 
CaptionToObject answer <p>A girl</p> {<9><4><60><100>}
<p>shorts</p> {<8><48><38><70>}
<p>white top</p> {<9><15><41><52>}
<p>meat</p> {<62><50><94><57>}
<p>a bar-b-que</p> {<52><49><99><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Elderly gentleman in brown trench-coat and woman in orange-brown fur coat sitting at table , woman has her back to camera 
CaptionToObject answer <p>Elderly gentleman</p> {<2><13><37><92>}
<p>brown trench-coat</p> {<1><24><53><85>}
<p>woman</p> {<28><17><100><100>}<delim>{<28><17><100><100>}
<p>orange-brown fur coat</p> {<27><30><99><96>}
<p>table</p> {<85><47><100><53>}
<p>her back</p> {<28><31><69><72>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A caucasian woman wearing glasses is holding a darker-skinned little boy outside of a school and both are rolling their tounges 
CaptionToObject answer <p>A caucasian woman</p> {<27><23><75><100>}
<p>glasses</p> {<57><28><71><39>}
<p>a darker-skinned little boy</p> {<16><3><53><100>}
<p>a school</p> {<0><11><100><87>}
<p>their tounges</p> {<58><38><60><43>}<delim>{<39><24><42><27>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing glasses and tan pants leans against a table while there is a large picture on an overhead screen of a word document 
CaptionToObject answer <p>A woman</p> {<13><60><28><100>}
<p>glasses</p> {<20><62><25><66>}
<p>tan pants</p> {<18><84><27><100>}
<p>a table</p> {<1><84><21><100>}
<p>a large picture</p> {<35><14><70><76>}
<p>an overhead screen of a word document</p> {<35><14><70><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Four men in blue soccer uniforms on a soccer field , where one is holding a ball and listening to a man in a black outfit 
CaptionToObject answer <p>Four men</p> {<72><46><97><92>}<delim>{<13><19><21><48>}<delim>{<68><13><74><39>}<delim>{<45><41><56><91>}
<p>blue soccer uniforms</p> {<14><23><21><46>}<delim>{<46><47><56><73>}
<p>a soccer field</p> {<1><20><100><100>}
<p>one</p> {<45><41><56><91>}
<p>a ball</p> {<46><54><50><61>}
<p>a man</p> {<19><42><43><96>}
<p>a black outfit</p> {<28><49><43><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a dark shirt and pants sitting on a small stool , which is in front of a few small shopping desks 
CaptionToObject answer <p>A man</p> {<34><56><71><92>}
<p>a dark shirt</p> {<39><56><67><74>}
<p>pants</p> {<35><74><70><92>}
<p>a small stool</p> {<46><81><65><97>}
<p>a few small shopping desks</p> {<1><70><33><89>}<delim>{<33><68><47><86>}<delim>{<64><64><99><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] While drinking a coupe of Red Stripe beers , a man with a gray t-shirt speaks to another man wearing a blue button up shirt 
CaptionToObject answer <p>a coupe of Red Stripe beers</p> {<71><73><80><100>}
<p>a man</p> {<37><11><91><100>}
<p>a gray t-shirt</p> {<36><48><91><100>}
<p>another man</p> {<1><0><55><100>}
<p>a blue button</p> {<24><82><26><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in jeans and an orange shirt dances in the street with a woman in a blue and white dress while a crowd looks on 
CaptionToObject answer <p>A man</p> {<5><20><46><82>}
<p>jeans</p> {<10><43><32><79>}
<p>an orange shirt</p> {<5><26><35><46>}
<p>the street</p> {<0><65><100><100>}
<p>a woman</p> {<30><17><92><88>}
<p>a blue and white dress</p> {<30><24><92><63>}
<p>a crowd</p> {<0><45><12><67>}<delim>{<30><45><37><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Guy in blue jacket and hat standing in front of some type of machinery while starring up with a big smile 
CaptionToObject answer <p>Guy</p> {<36><45><77><100>}
<p>blue jacket</p> {<35><61><78><100>}
<p>hat</p> {<64><41><77><67>}
<p>some type of machinery</p> {<0><0><100><100>}
<p>a big smile</p> {<61><52><67><58>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a black sweatshirt is pouring liquid detergent into a washer in a laundromat 
CaptionToObject answer <p>A woman</p> {<1><3><60><100>}
<p>a black sweatshirt</p> {<1><20><62><71>}
<p>liquid detergent</p> {<11><49><50><75>}<delim>{<50><65><60><72>}
<p>a washer</p> {<23><33><100><100>}
<p>a laundromat</p> {<0><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A guy with piercings , tattoos and a mohawk is looking at the camera while lounging in a chair 
CaptionToObject answer <p>A guy</p> {<1><35><85><100>}
<p>piercings</p> {<69><51><76><57>}
<p>tattoos</p> {<48><84><83><100>}<delim>{<25><61><43><73>}
<p>a mohawk</p> {<57><34><72><41>}
<p>a chair</p> {<1><62><75><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brunette girl with a white shirt and brown backpack is holding an orange , yellow , and red kite shaped like a fish 
CaptionToObject answer <p>A brunette girl</p> {<44><8><80><99>}
<p>a white shirt</p> {<56><30><81><71>}
<p>brown backpack</p> {<58><34><88><92>}
<p>an orange</p> {<1><29><70><94>}
<p>red kite</p> {<1><29><72><100>}
<p>a fish</p> {<1><29><72><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little boy in a green shirt is playing in water with a little girl in a pink shirt and purple skirt 
CaptionToObject answer <p>A little boy</p> {<2><14><47><81>}
<p>a green shirt</p> {<14><26><39><49>}
<p>water</p> {<0><75><92><90>}
<p>a little girl</p> {<69><1><100><77>}
<p>a pink shirt</p> {<82><14><99><38>}
<p>purple skirt</p> {<76><36><96><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Brown and black dog with yellow object in mouth in the snow 
CaptionToObject answer <p>Brown</p> {<28><17><70><87>}
<p>black dog</p> {<29><16><71><88>}
<p>yellow object</p> {<52><52><72><67>}
<p>mouth</p> {<52><50><67><59>}
<p>the snow</p> {<1><8><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black and blue checkered hooded sweater is looking at a Levi 's advertisement that says , " We Are All Workers " 
CaptionToObject answer <p>A man</p> {<8><18><34><100>}
<p>a black and blue checkered hooded sweater</p> {<7><31><33><78>}
<p>a Levi 's advertisement</p> {<31><4><100><100>}
<p>We</p> {<47><20><58><44>}
<p>Workers</p> {<48><18><92><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady with a white tank top holds a blue yard style cocktail cup with her black tank topped phone holding a phone 
CaptionToObject answer <p>A lady</p> {<23><36><99><100>}
<p>a white tank top</p> {<51><58><84><93>}
<p>a blue yard style cocktail cup</p> {<21><64><38><97>}
<p>her black tank</p> {<78><53><100><100>}
<p>a phone</p> {<48><58><74><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The woman in the crowd with blond braids and sunglasses made an obscene gesture with her finger 
CaptionToObject answer <p>The woman</p> {<56><10><99><100>}
<p>the crowd</p> {<56><10><99><100>}<delim>{<1><14><74><100>}
<p>blond braids</p> {<15><51><43><71>}
<p>sunglasses</p> {<27><36><48><49>}<delim>{<69><19><93><27>}
<p>an obscene gesture</p> {<34><63><55><88>}
<p>her finger</p> {<34><63><46><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman is walking on a sidewalk across the street from a Discount food and clothing store 
CaptionToObject answer <p>A woman</p> {<62><2><82><100>}
<p>a sidewalk</p> {<59><45><100><100>}
<p>the street</p> {<59><45><100><100>}
<p>a Discount food</p> {<0><0><61><40>}
<p>clothing store</p> {<0><0><61><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] One girl is doing a handstand on an outdoor trampoline while another girl stands on the trampoline with one hand in the air 
CaptionToObject answer <p>One girl</p> {<39><23><57><74>}
<p>a handstand</p> {<39><23><57><74>}
<p>an outdoor trampoline</p> {<1><61><99><100>}
<p>another girl</p> {<28><35><39><69>}
<p>the trampoline</p> {<1><61><99><100>}
<p>one hand</p> {<34><35><39><45>}<delim>{<36><35><39><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man on a bicycle going down the street while a man stands nearby on the sidewalk in a striped shirt taking a picture of a sign with an orange cone placed atop it 
CaptionToObject answer <p>A man</p> {<32><55><51><81>}
<p>a bicycle</p> {<28><67><57><87>}
<p>the street</p> {<0><52><100><100>}
<p>a man</p> {<65><46><92><100>}
<p>a striped shirt</p> {<69><54><84><80>}
<p>an orange cone</p> {<3><2><25><21>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man carries a young cow while two cows look on from the distance and one cow has its mouth by the man 's hand 
CaptionToObject answer <p>A man</p> {<54><16><77><88>}
<p>a young cow</p> {<53><18><76><51>}
<p>two cows</p> {<81><26><98><46>}<delim>{<22><27><46><39>}
<p>one cow</p> {<19><33><55><81>}
<p>its mouth</p> {<52><40><56><47>}
<p>the man 's hand</p> {<53><40><58><48>}

CaptionToObject instructionCaptionToObject instruction  <Img><ImageHere></Img> [detection] Two older women in bathing suits are intrigued by a man walking down the stairs with a white parachute over his head <Img><ImageHere></Img> [detection] A young Asian girl in a tube top holds out her camera to get a picture with her friend who is making the peace sign 

CaptionToObject instructionCaptionToObject answerCaptionToObject answer   <Img><ImageHere></Img> [detection] A very young boy is wearing green shorts and socks , is preparing to kick a ball , he is in a field <p>Two older women</p> {<49><64><59><90>}<delim>{<39><71><52><89>}
<p>bathing suits</p> {<50><68><58><79>}
<p>a man</p> {<28><39><35><55>}
<p>the stairs</p> {<1><31><61><69>}
<p>a white parachute</p> {<13><15><47><39>}
<p>his head</p> {<30><39><34><43>}
<p>A young Asian girl</p> {<40><15><95><100>}
<p>a tube top</p> {<57><49><90><95>}
<p>her camera</p> {<81><19><95><33>}
<p>her friend</p> {<1><33><25><100>}
<p>the peace sign</p> {<11><51><16><61>}



CaptionToObject answer <p>A very young boy</p> {<14><2><44><94>}
<p>green shorts</p> {<21><42><40><73>}
<p>socks</p> {<18><70><21><78>}<delim>{<28><78><35><86>}
<p>a ball</p> {<58><71><72><91>}
<p>a field</p> {<1><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two people in black vests are standing in front of children in white vests with an American flag between them 
CaptionToObject instructionCaptionToObject answer  <Img><ImageHere></Img> [detection] A woman in a purple sweater and bucket hat is on a sidewalk carrying many shopping bags <p>Two people</p> {<6><36><22><82>}<delim>{<8><38><37><97>}<delim>{<59><52><71><87>}
<p>black vests</p> {<15><51><36><97>}<delim>{<5><45><18><80>}
<p>children</p> {<27><36><100><61>}
<p>white vests</p> {<1><39><100><54>}<delim>{<61><59><70><80>}
<p>an American flag</p> {<32><48><61><76>}


CaptionToObject answer <p>A woman</p> {<30><3><76><93>}
<p>a purple sweater</p> {<31><17><73><58>}
<p>bucket hat</p> {<31><3><56><17>}
<p>a sidewalk</p> {<0><27><100><100>}
<p>many shopping bags</p> {<9><60><37><88>}<delim>{<58><52><95><82>}<delim>{<22><57><57><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two young women wearing bikini tops and short jean shorts are having a conversation while one is carrying a pink bag and the other a drink 
CaptionToObject answer <p>Two young women</p> {<3><2><48><100>}<delim>{<53><7><93><100>}
<p>bikini tops</p> {<60><28><82><52>}<delim>{<16><23><38><48>}
<p>short jean shorts</p> {<11><62><42><85>}<delim>{<56><66><83><85>}
<p>one</p> {<3><2><48><100>}
<p>a pink bag</p> {<11><45><35><69>}
<p>the other a drink</p> {<53><7><93><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing all black and holding a green can roasts a large hotdog on a stick 
CaptionToObject answer <p>A man</p> {<6><1><79><75>}
<p>all black</p> {<1><12><79><85>}
<p>a green</p> {<34><44><46><60>}
<p>a large hotdog</p> {<60><86><79><99>}
<p>a stick</p> {<41><64><74><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a gray sweater slices into a light brown celebration cake as she sits next to a much older woman holding a plate 
CaptionToObject answer <p>A woman</p> {<21><15><61><73>}
<p>a gray sweater</p> {<21><28><61><74>}
<p>a light brown celebration cake</p> {<29><66><52><89>}
<p>a much older woman</p> {<64><12><100><82>}
<p>a plate</p> {<87><59><100><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a royal blue shirt and a girl with a headband working with yarn 
CaptionToObject answer <p>A girl</p> {<23><8><61><95>}
<p>a royal blue shirt</p> {<23><26><60><82>}
<p>a girl</p> {<50><17><94><100>}
<p>a headband</p> {<67><16><83><32>}
<p>yarn</p> {<50><54><62><100>}<delim>{<16><65><43><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt and black shorts has an orange sun visor on his head 
CaptionToObject answer <p>A man</p> {<4><58><34><100>}
<p>a blue shirt</p> {<14><64><30><83>}
<p>black shorts</p> {<13><81><28><99>}
<p>an orange sun visor</p> {<27><60><34><66>}
<p>his head</p> {<26><58><34><68>}<delim>{<27><58><32><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A couple holding hands and a woman standing beside them pose on a tree lined dirt road 
CaptionToObject answer <p>A couple</p> {<55><17><73><91>}<delim>{<40><16><57><87>}
<p>hands</p> {<53><54><58><59>}
<p>a woman</p> {<23><23><40><87>}
<p>a tree</p> {<91><0><100><45>}
<p>dirt road</p> {<7><4><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] 2 people at a beach burying a 3rd person up to his head in sand 
CaptionToObject answer <p>2 people</p> {<21><21><73><78>}<delim>{<59><27><100><90>}
<p>a beach</p> {<1><38><100><100>}
<p>a 3rd person</p> {<44><58><56><75>}
<p>his head</p> {<44><58><56><75>}
<p>sand</p> {<1><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a small rowboat traveling down a river surrounded by reeds and grasslands on both sides while seagulls fly in the air nearby 
CaptionToObject answer <p>A man</p> {<67><73><72><82>}
<p>a small rowboat</p> {<65><73><75><87>}
<p>a river</p> {<0><4><100><100>}
<p>reeds</p> {<17><4><100><26>}<delim>{<0><6><54><75>}
<p>grasslands</p> {<17><4><100><26>}<delim>{<0><6><54><75>}
<p>seagulls</p> {<58><65><62><70>}<delim>{<75><65><79><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] women in a black shirt standing with a bottle of water in hand in front of wall with Greek writing on it 
CaptionToObject answer <p>women</p> {<30><40><57><100>}
<p>a black shirt</p> {<30><63><57><98>}
<p>a bottle of water</p> {<27><52><38><68>}
<p>hand</p> {<34><60><43><75>}
<p>Greek writing</p> {<32><36><57><49>}<delim>{<2><14><22><31>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A group of co-ed youth hand wash a red truck , one washes the back glass while another washes the side with a rag 
CaptionToObject answer <p>A group of co-ed youth hand</p> {<35><10><59><61>}
<p>a red truck</p> {<0><19><100><100>}
<p>one</p> {<35><10><59><61>}
<p>the back glass</p> {<14><23><42><59>}
<p>a rag</p> {<62><96><69><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A balding man is playing the drums , as another young man holding a guitar plugs in the amp 
CaptionToObject answer <p>A balding man</p> {<0><8><29><94>}
<p>the drums</p> {<0><16><47><99>}
<p>another young man</p> {<57><13><100><100>}
<p>a guitar</p> {<72><34><99><72>}
<p>the amp</p> {<46><36><72><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older man with a cane in a brown hat and sweater rests on a low stone wall , in between tables covered in an assortment of antique goods 
CaptionToObject answer <p>An older man</p> {<3><2><58><71>}
<p>a cane</p> {<27><26><62><70>}
<p>a brown hat</p> {<13><3><28><11>}
<p>sweater</p> {<3><12><41><44>}
<p>a low stone wall</p> {<0><38><40><79>}
<p>tables</p> {<46><48><100><93>}<delim>{<37><28><100><54>}
<p>an assortment of antique goods</p> {<60><40><71><57>}<delim>{<85><44><100><59>}<delim>{<67><34><79><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person in a green outfit and helmet is swinging a baseball bat at a tennis ball in front of a fence 
CaptionToObject answer <p>A person</p> {<22><14><67><90>}
<p>a green outfit</p> {<30><24><57><69>}<delim>{<32><26><54><66>}
<p>helmet</p> {<26><14><44><29>}<delim>{<28><15><43><28>}
<p>a baseball bat</p> {<66><44><92><47>}
<p>a tennis ball</p> {<38><58><45><63>}
<p>a fence</p> {<1><1><100><75>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a beige shirt and blue shorts is carrying a long stick with a dagger at the end in the forest 
CaptionToObject answer <p>A man</p> {<16><29><42><78>}
<p>a beige shirt</p> {<16><34><42><50>}
<p>blue shorts</p> {<18><49><26><56>}<delim>{<19><52><38><61>}
<p>a long stick</p> {<1><20><77><66>}
<p>a dagger</p> {<62><21><76><28>}
<p>the end</p> {<61><22><77><29>}
<p>the forest</p> {<1><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A spray painted hand showing the peace side at the entrance of a small road with a young man in a red shirt riding his bike through it 
CaptionToObject answer <p>A spray</p> {<9><39><35><71>}
<p>hand</p> {<9><39><35><71>}
<p>the entrance of a small road</p> {<12><64><100><100>}
<p>a young man</p> {<58><58><73><79>}
<p>a red shirt</p> {<59><62><72><70>}
<p>his bike</p> {<58><66><73><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a beard and mustache , wearing a baseball cap and sunglasses , and holding a stick is standing near a chain link fence 
CaptionToObject answer <p>A man</p> {<47><19><88><99>}
<p>a beard</p> {<62><38><70><45>}
<p>mustache</p> {<63><34><70><37>}<delim>{<62><34><71><38>}
<p>a baseball cap</p> {<61><18><74><30>}
<p>sunglasses</p> {<61><27><72><34>}
<p>a stick</p> {<33><79><53><96>}
<p>a chain link fence</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A group of people , including one man carrying a silver tripod , stand in front of a large building featuring numerous columns 
CaptionToObject answer <p>A group of people</p> {<0><49><100><100>}
<p>one man</p> {<0><60><24><100>}
<p>a silver tripod</p> {<5><26><18><100>}
<p>a large building</p> {<1><1><100><59>}
<p>numerous columns</p> {<62><8><68><39>}<delim>{<69><5><76><37>}<delim>{<80><1><90><36>}<delim>{<94><0><100><36>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A group of people standing on a city street in front of a red car , in which one woman with red-hair and black shirt with a red suitcase speaking to a portly man wearing a creme shirt and brown shorts 
CaptionToObject answer <p>A group of people</p> {<47><36><77><88>}
<p>a city street</p> {<2><38><100><100>}
<p>a red car</p> {<70><44><97><76>}
<p>which one woman</p> {<47><38><61><88>}
<p>red-hair</p> {<48><39><55><51>}<delim>{<48><39><56><50>}
<p>black shirt</p> {<47><45><60><62>}
<p>a red suitcase</p> {<54><56><59><85>}
<p>a portly man</p> {<59><37><69><89>}
<p>a creme shirt</p> {<58><43><68><63>}
<p>brown shorts</p> {<59><58><67><75>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red jacket plays guitar near a microphone and speaker 
CaptionToObject answer <p>A woman</p> {<31><2><72><100>}
<p>a red jacket</p> {<31><29><74><100>}
<p>guitar</p> {<31><29><74><100>}
<p>a microphone</p> {<24><9><32><25>}
<p>speaker</p> {<0><43><32><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl in a blue t-shirt is looking through a telescope while another girl in a red shirt watches 
CaptionToObject answer <p>A young girl</p> {<64><32><93><100>}
<p>a blue t-shirt</p> {<51><49><66><71>}
<p>a telescope</p> {<9><34><46><100>}
<p>another girl</p> {<64><32><93><100>}
<p>a red shirt</p> {<68><45><89><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A roller derby girl in full regalia - black helmet , tank top , pads , and four wheel skates - maintains her balance as she races down the track 
CaptionToObject answer <p>A roller derby girl</p> {<16><16><88><92>}
<p>black helmet</p> {<34><16><48><27>}
<p>tank top</p> {<35><28><59><54>}
<p>pads</p> {<30><61><43><75>}
<p>four wheel skates</p> {<29><76><50><91>}
<p>the track</p> {<1><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man wearing a gray jacket sitting on a green bench petting a black dog wearing a red collar 
CaptionToObject answer <p>Man</p> {<36><24><67><93>}
<p>a gray jacket</p> {<36><30><57><68>}<delim>{<36><33><55><64>}
<p>a green bench</p> {<23><42><67><96>}
<p>a black dog</p> {<57><46><66><90>}
<p>a red collar</p> {<58><58><65><64>}<delim>{<58><57><65><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A construction worker in a hard hat , red shirt and yellow and orange vest operates a piece of machinery in front of palm trees 
CaptionToObject answer <p>A construction worker</p> {<29><32><52><76>}
<p>a hard hat</p> {<39><33><51><44>}
<p>red shirt and yellow and orange vest</p> {<32><46><52><77>}
<p>a piece of machinery</p> {<23><64><72><97>}
<p>palm trees</p> {<90><47><100><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with sunglasses on top of his head is taking a drink from a glass 
CaptionToObject answer <p>A man</p> {<1><1><77><100>}
<p>sunglasses</p> {<22><0><45><38>}
<p>his head</p> {<2><0><61><78>}
<p>a drink</p> {<57><49><90><82>}
<p>a glass</p> {<57><49><90><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a pink tank top walking with another woman dressed in a gray tank top with a plaid scarf 
CaptionToObject answer <p>A woman</p> {<4><0><54><100>}
<p>a pink tank top</p> {<17><22><50><98>}
<p>another woman</p> {<4><0><54><100>}<delim>{<46><0><72><100>}
<p>a gray tank top</p> {<44><22><72><100>}
<p>a plaid scarf</p> {<50><12><70><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The old man in a black suit and brown shoes is holding a yarn spinner that has spun wool on it 
CaptionToObject answer <p>The old man</p> {<29><4><84><96>}
<p>a black suit</p> {<35><16><85><62>}
<p>brown shoes</p> {<43><87><73><97>}
<p>a yarn spinner</p> {<14><30><78><77>}
<p>wool</p> {<15><29><76><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a scarf on her head sits next to a young boy wearing blue 
CaptionToObject answer <p>A woman</p> {<43><1><100><100>}
<p>a scarf</p> {<56><3><91><55>}
<p>her head</p> {<55><1><90><43>}
<p>a young boy</p> {<20><17><55><100>}
<p>blue</p> {<43><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A cowboy dressed in jeans , competition number , and tan hat is being bucked off his brown horse while two other cowboys dressed in red shirts and brown hats ride along nearby 
CaptionToObject answer <p>A cowboy</p> {<53><19><81><41>}
<p>jeans</p> {<56><23><74><38>}
<p>competition number</p> {<55><20><62><25>}
<p>tan hat</p> {<62><14><70><20>}
<p>his brown horse</p> {<32><33><89><90>}
<p>two other cowboys</p> {<62><14><71><38>}<delim>{<1><32><16><60>}
<p>red shirts</p> {<61><18><71><24>}
<p>brown hats</p> {<62><14><69><19>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Several men are working on a house while using tools like ladders , a shovel , and others 
CaptionToObject answer <p>Several men</p> {<26><51><52><94>}<delim>{<1><1><22><40>}<delim>{<27><11><48><49>}<delim>{<71><9><100><33>}
<p>a house</p> {<0><1><100><100>}
<p>tools</p> {<20><37><43><100>}<delim>{<56><13><65><36>}
<p>ladders</p> {<20><37><52><100>}
<p>a shovel</p> {<56><13><63><36>}
<p>others</p> {<1><1><22><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two boys , one wearing glasses , run across grass Third child partially in shot 
CaptionToObject answer <p>Two boys</p> {<28><16><48><72>}<delim>{<86><14><100><89>}<delim>{<9><18><24><68>}
<p>one</p> {<28><16><48><72>}
<p>glasses</p> {<39><22><46><28>}<delim>{<39><23><46><27>}
<p>grass</p> {<0><29><100><100>}
<p>Third child</p> {<86><14><100><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man holding a frying pan and a woman in a white shirt are standing in a kitchen 
CaptionToObject answer <p>A man</p> {<18><12><52><82>}
<p>a frying pan</p> {<31><44><68><67>}
<p>a woman</p> {<63><20><94><100>}
<p>a white shirt</p> {<74><45><94><94>}
<p>a kitchen</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The snowboarder is wearing a dark top , blue pants and a helmet with goggles 
CaptionToObject answer <p>The snowboarder</p> {<7><30><85><72>}
<p>a dark top</p> {<12><28><75><60>}
<p>blue pants</p> {<40><43><85><64>}
<p>a helmet</p> {<47><32><58><37>}
<p>goggles</p> {<57><30><98><84>}<delim>{<48><34><57><39>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A football player wearing a number 23 white jersey tackles a football player wearing a red , number three jersey while fans cheer 
CaptionToObject answer <p>A football player</p> {<31><44><97><69>}
<p>a number 23 white jersey</p> {<55><51><74><63>}
<p>a football player</p> {<30><33><81><80>}
<p>a red , number</p> {<36><40><61><56>}
<p>three jersey</p> {<55><51><74><63>}
<p>fans</p> {<1><0><100><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian lady wearing a jean jacket and pointed hat carries two baskets counterbalanced with a stick across her shoulder 
CaptionToObject answer <p>An Asian lady</p> {<18><2><71><100>}
<p>a jean jacket</p> {<17><20><71><75>}
<p>hat</p> {<17><3><57><19>}
<p>two baskets</p> {<9><19><95><100>}
<p>a stick</p> {<48><18><74><23>}
<p>her shoulder</p> {<22><26><27><31>}<delim>{<48><22><60><28>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two dogs are running in the dirt , one with a ball in its mouth 
CaptionToObject answer <p>Two dogs</p> {<31><27><64><90>}<delim>{<41><12><75><42>}
<p>the dirt</p> {<31><27><64><90>}<delim>{<6><49><27><79>}
<p>one</p> {<41><12><75><42>}
<p>a ball</p> {<68><20><73><26>}
<p>its mouth</p> {<68><17><74><27>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman wearing gold boots and a gold hat imitates pantyhose models in a storefront window 
CaptionToObject answer <p>Woman</p> {<35><23><74><79>}
<p>gold boots</p> {<54><65><66><80>}<delim>{<40><64><51><79>}
<p>a gold hat</p> {<34><22><47><30>}
<p>pantyhose models</p> {<89><28><97><33>}
<p>a storefront window</p> {<1><1><100><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men both wearing jeans jumping in the air in front of a picnic table sitting in front of a stone wall that has a wire fence and trees behind it 
CaptionToObject answer <p>Two men</p> {<31><8><49><61>}<delim>{<50><0><83><78>}
<p>jeans</p> {<55><36><78><72>}<delim>{<33><36><49><57>}
<p>a picnic table</p> {<33><76><68><100>}
<p>a stone wall</p> {<1><70><100><100>}
<p>a wire fence</p> {<1><63><100><76>}
<p>trees</p> {<1><0><100><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with headphones holding a pen and paper while her feet are propped up on fence 
CaptionToObject answer <p>A woman</p> {<2><1><100><92>}
<p>headphones</p> {<23><16><29><35>}
<p>a pen</p> {<47><42><51><47>}
<p>paper</p> {<37><37><56><62>}
<p>her feet</p> {<83><24><100><57>}
<p>fence</p> {<2><1><100><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person on a sidewalk with a silver mask , playing a guitar , with sticks between their toes touching two smaller instruments 
CaptionToObject answer <p>A person</p> {<27><25><67><82>}
<p>a sidewalk</p> {<1><50><100><100>}
<p>a silver mask</p> {<51><25><62><35>}
<p>a guitar</p> {<39><40><66><57>}
<p>sticks</p> {<19><71><35><75>}<delim>{<40><80><45><86>}
<p>their toes</p> {<40><79><48><82>}<delim>{<28><72><31><76>}
<p>two smaller instruments</p> {<17><72><46><87>}<delim>{<37><82><45><86>}<delim>{<16><72><25><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a young woman dressed in black and a young man wearing jean shorts and a gray t-shirt are standing in front of a basketball carnival game on a blue and yellow checkered floor 
CaptionToObject answer <p>a young woman</p> {<19><25><43><83>}
<p>black and a young man</p> {<47><22><70><82>}<delim>{<19><25><43><83>}
<p>jean shorts</p> {<51><56><67><71>}
<p>a gray t-shirt</p> {<50><31><70><59>}
<p>a blue and yellow checkered floor</p> {<0><58><100><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A smiling female with nice teeth taking a bubble bath , two earrings in her right ear and a short haircut 
CaptionToObject answer <p>A smiling female</p> {<14><15><64><100>}
<p>nice teeth</p> {<38><58><59><70>}
<p>a bubble bath</p> {<0><52><100><100>}
<p>two earrings</p> {<22><73><25><78>}
<p>her right ear</p> {<17><59><27><76>}
<p>a short haircut</p> {<13><15><59><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A large , yellow-glowing ball is suspended above a crowd of people under tents in front of a building with sharp-lined architecture 
CaptionToObject answer <p>A large , yellow-glowing ball</p> {<56><3><82><44>}
<p>a crowd of people</p> {<1><70><100><100>}
<p>tents</p> {<55><57><91><71>}<delim>{<43><62><60><73>}<delim>{<73><61><100><75>}
<p>a building</p> {<74><34><89><56>}
<p>sharp-lined architecture</p> {<0><33><68><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Someone with a long pole that appears to have a spike on the end is pointing it at a red balloon on the other side of the wall from him 
CaptionToObject answer <p>Someone</p> {<17><0><37><27>}
<p>a long pole</p> {<25><0><40><69>}
<p>a spike</p> {<25><0><40><69>}
<p>the end</p> {<34><57><40><68>}
<p>a red balloon</p> {<35><66><44><78>}
<p>the other side of the wall</p> {<5><15><47><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man on rollerskates , in white shorts , part of a crowd watching a black man in a red shirt 
CaptionToObject answer <p>A young man</p> {<9><6><63><94>}
<p>rollerskates</p> {<28><89><61><99>}
<p>white shorts</p> {<24><45><55><61>}
<p>a black man</p> {<81><21><95><50>}
<p>a red shirt</p> {<81><24><94><31>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Onlookers watch a man with a black helmet leaning against a tree , playing a type of instrument 
CaptionToObject answer <p>Onlookers</p> {<77><3><98><50>}<delim>{<60><12><80><100>}<delim>{<33><27><42><66>}
<p>a man</p> {<3><2><38><100>}
<p>a black helmet</p> {<7><1><24><19>}
<p>a tree</p> {<0><0><12><100>}
<p>a type of instrument</p> {<17><23><33><75>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a black cowboy styled hat drawing his finger through sand 
CaptionToObject answer <p>A man</p> {<24><7><73><93>}
<p>a black cowboy</p> {<24><7><73><93>}
<p>hat</p> {<46><6><75><47>}
<p>his finger</p> {<43><92><46><100>}
<p>sand</p> {<0><4><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Smiling man with hat , standing in store reading magazine that says " I 'm Pregnant " on cover 
CaptionToObject answer <p>Smiling man</p> {<46><21><99><100>}
<p>hat</p> {<49><20><76><38>}
<p>store</p> {<0><1><100><100>}
<p>magazine</p> {<13><49><72><84>}
<p>cover</p> {<22><50><72><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a red soccer strip is holding his boots in his hand whilst stepping out of a car 
CaptionToObject answer <p>A boy</p> {<0><18><50><99>}
<p>a red soccer strip</p> {<27><57><42><99>}
<p>his boots</p> {<0><48><27><99>}
<p>his hand</p> {<8><41><22><58>}
<p>a car</p> {<0><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in all white and wearing a white hat stands on a sidewalk next to a building 
CaptionToObject answer <p>A man</p> {<46><24><60><77>}
<p>all white</p> {<47><23><60><73>}
<p>a white hat</p> {<50><24><56><32>}
<p>a sidewalk</p> {<0><72><100><100>}
<p>a building</p> {<0><0><100><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a white robe with a purple sash places his hand on the forehead of another man 
CaptionToObject answer <p>A man</p> {<42><17><80><66>}
<p>a white robe</p> {<48><28><81><67>}
<p>a purple sash</p> {<59><34><82><58>}
<p>his hand</p> {<43><17><50><29>}
<p>the forehead of another man</p> {<38><18><47><24>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A blond girl in a green dress and elaborate gold necklace stands in front of a few women and a man 
CaptionToObject answer <p>A blond girl</p> {<34><8><75><95>}
<p>a green dress</p> {<32><25><71><93>}
<p>elaborate gold necklace</p> {<46><19><60><26>}
<p>a few women</p> {<7><35><37><93>}
<p>a man</p> {<62><39><97><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a colorful clown outfit without clown makeup on but with a sequined bandit mask and sequined witch hat , is creating something from an orange balloon 
CaptionToObject answer <p>A person</p> {<1><1><100><98>}
<p>a colorful clown outfit</p> {<1><1><100><98>}
<p>clown makeup</p> {<33><37><60><63>}
<p>a sequined bandit mask</p> {<34><36><54><50>}
<p>witch hat</p> {<17><1><67><50>}
<p>something</p> {<32><82><58><100>}
<p>an orange balloon</p> {<34><80><57><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Group of people including a man and a woman playing instruments on a double-decker red Planet Hollywood sightseeing bus 
CaptionToObject answer <p>Group of people</p> {<17><13><34><50>}<delim>{<37><16><55><49>}<delim>{<51><8><68><45>}
<p>a man</p> {<37><16><55><49>}
<p>a woman</p> {<17><13><34><50>}
<p>instruments</p> {<28><12><34><22>}<delim>{<19><19><25><30>}<delim>{<37><24><45><29>}
<p>a double-decker red Planet Hollywood</p> {<3><20><100><100>}
<p>bus</p> {<3><20><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A group of people , including a barefoot woman with white shorts , a black jacket and backpack wait for a light rail train 
CaptionToObject answer <p>A group of people</p> {<0><3><99><99>}
<p>a barefoot woman</p> {<33><2><52><97>}
<p>white shorts</p> {<36><47><50><69>}
<p>a black jacket</p> {<29><13><50><52>}
<p>backpack</p> {<22><16><45><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A hockey player skating on ice with a black jersey and pants while wearing a black helmet 
CaptionToObject answer <p>A hockey player</p> {<8><8><75><92>}
<p>ice</p> {<1><64><100><100>}
<p>a black jersey</p> {<34><12><74><57>}
<p>pants</p> {<9><41><54><92>}
<p>a black helmet</p> {<62><8><75><18>}

Train: data epoch: [0]  [   0/1000]  eta: 0:37:06  lr: 0.000001  loss: 2.3123  time: 2.2260  data: 0.0000  max mem: 25455
CaptionToObject instruction <Img><ImageHere></Img> [detection] Two young girls and a boy sit at a table in a kitchen as a man in a gray sweater holds a white disk in front of them 
CaptionToObject answer <p>Two young girls</p> {<4><27><49><100>}<delim>{<1><14><41><88>}
<p>a boy</p> {<52><29><87><100>}
<p>a table</p> {<26><34><71><100>}
<p>a man</p> {<56><1><100><100>}
<p>a gray sweater</p> {<63><1><100><60>}
<p>a white disk</p> {<49><47><64><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The person with the black hat is eating some noodles with chopsticks out of a bowl 
CaptionToObject answer <p>The person</p> {<15><1><87><76>}
<p>the black hat</p> {<33><1><80><60>}
<p>some noodles</p> {<32><67><66><97>}
<p>chopsticks</p> {<16><49><42><57>}
<p>a bowl</p> {<34><70><64><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in c camouflage cap and jeans is sitting on a bench reading a book 
CaptionToObject answer <p>A man</p> {<4><16><77><100>}
<p>c camouflage cap</p> {<55><16><69><28>}
<p>jeans</p> {<13><56><57><100>}
<p>a bench</p> {<4><35><69><100>}
<p>a book</p> {<42><39><58><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young boy in a t-shirt , sweats and a red hat , skateboarding in a skateboard arena , with an audience on the side and blue skies above 
CaptionToObject answer <p>A young boy</p> {<24><25><59><74>}
<p>a t-shirt</p> {<40><35><52><50>}
<p>sweats</p> {<32><40><59><70>}
<p>a red hat</p> {<34><34><44><45>}
<p>an audience</p> {<2><46><15><78>}
<p>blue skies</p> {<0><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A red-haired person in a green shirt holds an ice cream cone up to the mouth of a man in a red shirt and yellow baseball cap , at the counter of an ice cream store 
CaptionToObject answer <p>A red-haired person</p> {<36><26><67><100>}
<p>a green shirt</p> {<37><52><67><100>}
<p>an ice cream cone</p> {<35><32><45><48>}
<p>the mouth of a man</p> {<35><32><39><40>}
<p>a red shirt</p> {<6><24><36><92>}
<p>yellow baseball cap</p> {<26><9><46><30>}
<p>the counter of an ice cream store</p> {<59><66><91><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a dark shirt is holding some kind of food with chopsticks , with a strange look on his face 
CaptionToObject answer <p>A man</p> {<0><0><100><100>}
<p>a dark shirt</p> {<11><37><100><100>}
<p>some kind of food</p> {<35><59><63><87>}
<p>chopsticks</p> {<17><57><64><69>}
<p>a strange look</p> {<40><3><100><59>}
<p>his face</p> {<40><3><100><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing red pants hides their head under a black jacket in front of a desk with many computers 
CaptionToObject answer <p>A person</p> {<23><21><76><100>}
<p>red pants hides</p> {<11><23><78><100>}
<p>their head</p> {<28><26><45><44>}
<p>a black jacket</p> {<14><23><63><97>}
<p>a desk</p> {<2><3><100><99>}
<p>many computers</p> {<53><21><75><56>}<delim>{<1><2><83><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt was arguing with a man in a green jacket and started to raise his fist in anger 
CaptionToObject answer <p>A man</p> {<40><39><78><90>}
<p>a blue shirt</p> {<56><45><77><67>}
<p>a man</p> {<6><31><34><92>}
<p>a green jacket</p> {<6><36><31><63>}
<p>his fist</p> {<55><47><59><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black shirt and a white hat is pulled on a trailer by a donkey 
CaptionToObject answer <p>A man</p> {<71><33><83><55>}
<p>a black shirt</p> {<72><40><82><54>}
<p>a white hat</p> {<73><34><78><39>}
<p>a trailer</p> {<72><53><100><77>}
<p>a donkey</p> {<34><34><73><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A red-haired girl making a peace sign is wearing neon green glasses and floaties and playing in the pool with other kids 
CaptionToObject answer <p>A red-haired girl</p> {<24><26><76><57>}
<p>a peace sign</p> {<32><39><39><47>}
<p>neon green glasses</p> {<43><36><57><43>}
<p>floaties</p> {<59><40><79><62>}<delim>{<44><9><54><26>}<delim>{<65><3><76><20>}
<p>the pool</p> {<1><16><100><100>}
<p>other kids</p> {<2><9><16><39>}<delim>{<72><3><100><39>}<delim>{<51><0><78><34>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A cowboy is on the ground in a rodeo ring , holding onto his horse by a rope , just missing a calf 
CaptionToObject answer <p>A cowboy</p> {<67><79><84><91>}
<p>a rodeo ring</p> {<1><44><100><100>}
<p>his horse</p> {<5><54><23><96>}
<p>a rope</p> {<15><62><70><90>}
<p>a calf</p> {<57><75><80><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and a woman are standing in the grass talking with the man 's arm around the woman 's shoulder 
CaptionToObject answer <p>A man</p> {<30><16><74><100>}
<p>a woman</p> {<47><26><76><100>}
<p>the grass</p> {<0><37><100><100>}
<p>the man 's arm</p> {<29><29><39><62>}<delim>{<63><30><74><49>}
<p>the woman 's shoulder</p> {<51><40><64><44>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man , wearing a cap , is pushing a cart , on which large display boards are kept , on a road 
CaptionToObject answer <p>A man</p> {<50><33><76><67>}
<p>a cap</p> {<57><33><64><38>}
<p>a cart</p> {<10><37><95><51>}
<p>large display boards</p> {<8><37><93><45>}
<p>a road</p> {<1><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person on a mountain bike who 's wearing a racer 's outfit with a full face helmet is jumping off of a dirt outcropping 
CaptionToObject answer <p>A person</p> {<25><40><50><77>}
<p>a mountain bike</p> {<26><47><68><94>}
<p>a racer 's outfit</p> {<25><39><50><77>}
<p>a full face helmet</p> {<33><39><42><48>}
<p>a dirt</p> {<1><45><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with multicolored hair , wearing a leopard print jacket and red glasses , shows a woman in a yellow-check scarf something on a camera 
CaptionToObject answer <p>A woman</p> {<1><3><77><100>}
<p>multicolored hair</p> {<13><2><52><67>}
<p>a leopard print jacket</p> {<0><54><59><100>}
<p>red glasses</p> {<33><30><52><48>}
<p>a woman</p> {<39><14><73><100>}
<p>a yellow-check scarf</p> {<42><47><62><85>}
<p>a camera</p> {<65><80><77><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with braided hair and a beard is standing in front of a building and is talking or singing into a microphone 
CaptionToObject answer <p>A man</p> {<43><16><78><100>}
<p>braided hair</p> {<46><17><59><42>}
<p>a beard</p> {<47><33><55><45>}
<p>a building</p> {<1><1><100><100>}
<p>a microphone</p> {<38><35><50><48>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A sunny street with a red building , parked cars , and a man walking down the road 
CaptionToObject answer <p>A sunny street</p> {<27><55><100><100>}
<p>a red building</p> {<57><0><89><61>}
<p>parked cars</p> {<53><57><67><71>}<delim>{<49><57><56><67>}<delim>{<28><54><35><64>}<delim>{<36><55><41><62>}
<p>a man</p> {<42><56><46><67>}
<p>the road</p> {<1><60><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a purple shirt and a blue headband is fixing their hair in a mirror 
CaptionToObject answer <p>A person</p> {<1><1><70><100>}
<p>a purple shirt</p> {<0><33><64><100>}
<p>a blue headband</p> {<1><1><56><100>}
<p>their hair</p> {<1><0><35><34>}<delim>{<58><5><81><28>}
<p>a mirror</p> {<32><1><89><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one wearing a yellow shirt and the other a blue shirt , are playing frisbee on a field 
CaptionToObject answer <p>Two men</p> {<44><35><80><98>}<delim>{<59><26><97><99>}
<p>one</p> {<44><35><80><98>}
<p>a yellow shirt</p> {<45><41><66><64>}
<p>the other a blue shirt</p> {<68><37><86><64>}
<p>frisbee</p> {<43><63><55><68>}
<p>a field</p> {<0><49><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with red eyes and green makeup on her face , holds up a beige colored , ornately designed fan to cover her mouth 
CaptionToObject answer <p>A woman</p> {<1><1><89><100>}
<p>red eyes</p> {<44><8><59><15>}<delim>{<65><6><76><12>}
<p>green makeup</p> {<25><1><79><34>}
<p>her face</p> {<25><1><79><34>}
<p>a beige colored</p> {<1><28><100><94>}
<p>fan</p> {<1><28><100><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A child in a coat and hat is standing in a yellow doorway , and a woman in a coat and hat is standing outside , holding a cup 
CaptionToObject answer <p>A child</p> {<0><32><13><98>}
<p>a coat</p> {<0><44><13><78>}<delim>{<83><38><98><87>}<delim>{<0><44><13><78>}
<p>hat</p> {<2><31><12><49>}<delim>{<88><31><96><39>}
<p>a yellow doorway</p> {<19><1><71><100>}
<p>a woman</p> {<83><31><99><94>}
<p>a cup</p> {<94><46><97><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person in black jacket and jeans is squatting next to a white terrier on a paved walkway , taking a photo of fish - and frog-shaped lawn ornaments 
CaptionToObject answer <p>A person</p> {<49><0><98><66>}
<p>black jacket</p> {<53><2><98><55>}
<p>jeans</p> {<61><36><91><63>}
<p>a white terrier</p> {<54><40><77><96>}
<p>a paved walkway</p> {<28><0><100><100>}
<p>frog-shaped lawn ornaments</p> {<22><14><32><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a white shirt overlooking an excavator digging a hole in the street 
CaptionToObject answer <p>A man</p> {<4><4><22><100>}
<p>a white shirt</p> {<4><18><23><69>}
<p>an excavator</p> {<37><2><83><98>}
<p>a hole</p> {<60><68><100><100>}
<p>the street</p> {<0><16><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing black and yellow shorts is standing on a wooden pole with his arms outstretched and his shirt pulled over his face 
CaptionToObject answer <p>A man</p> {<9><4><54><96>}
<p>black and yellow shorts</p> {<24><36><42><66>}
<p>a wooden pole</p> {<28><91><42><100>}
<p>his arms</p> {<13><11><28><25>}<delim>{<41><20><53><32>}
<p>his shirt</p> {<22><14><46><31>}
<p>his face</p> {<32><13><38><23>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two woman share a small round table in front of a Swedish flag as one reads and another uses a laptop 
CaptionToObject answer <p>Two woman</p> {<4><39><29><100>}
<p>a small round table</p> {<20><77><71><100>}
<p>a Swedish flag</p> {<60><41><72><88>}
<p>one</p> {<4><39><29><100>}
<p>a laptop</p> {<45><59><67><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men standing in dark clothing at a bus stop , one is reading the newspaper 
CaptionToObject answer <p>Two men</p> {<47><36><67><72>}<delim>{<66><37><73><66>}
<p>dark clothing</p> {<55><41><66><68>}
<p>a bus stop</p> {<15><11><100><84>}
<p>one</p> {<47><36><67><72>}
<p>the newspaper</p> {<46><41><55><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a uniform walking on a street with two cars and a tree 
CaptionToObject answer <p>A man</p> {<20><31><31><54>}
<p>a uniform</p> {<20><34><31><55>}
<p>a street</p> {<0><19><100><100>}
<p>two cars</p> {<1><45><25><77>}<delim>{<41><57><100><99>}
<p>a tree</p> {<0><0><100><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a uniform is standing just inside the back of a delivery truck , while two other men are standing on the ground near the truck 
CaptionToObject answer <p>A man</p> {<57><17><70><98>}
<p>a uniform</p> {<59><26><72><92>}
<p>the back of a delivery truck</p> {<24><1><100><99>}
<p>two other men</p> {<57><59><94><100>}<delim>{<18><72><42><100>}
<p>the truck</p> {<52><0><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a light blue shirt and a woman with a black and white blouse are sitting at a table , behind an ornate fence with some vines attached to it 
CaptionToObject answer <p>A man</p> {<58><28><83><68>}
<p>a light blue shirt</p> {<58><35><83><65>}
<p>a woman</p> {<20><29><40><66>}
<p>a black and white blouse</p> {<21><41><35><64>}
<p>a table</p> {<35><49><65><67>}
<p>an ornate fence</p> {<10><4><100><64>}
<p>some vines</p> {<49><0><69><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man is riding a half pipe on a skateboard as a another young man rides a bicycle in the background 
CaptionToObject answer <p>A young man</p> {<13><16><61><89>}<delim>{<65><25><88><79>}
<p>a half pipe</p> {<1><76><100><100>}
<p>a skateboard</p> {<36><70><59><88>}
<p>a another young man</p> {<65><25><88><79>}
<p>a bicycle</p> {<63><50><94><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soccer player , in a blue uniform , prepares to put the ball back in play , while keeping it away from a player in a red uniform 
CaptionToObject answer <p>A soccer player</p> {<34><28><56><99>}
<p>a blue uniform</p> {<35><44><55><83>}
<p>the ball</p> {<47><28><55><39>}
<p>a player</p> {<0><12><11><62>}
<p>a red uniform</p> {<1><21><4><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] On a gray bricked street , a man in a vest sits and paints among his other works while a woman and 3 men talk 
CaptionToObject answer <p>a gray bricked street</p> {<42><60><100><100>}
<p>a man</p> {<32><40><56><80>}
<p>a vest</p> {<35><49><50><66>}
<p>a woman</p> {<79><31><85><59>}
<p>3 men</p> {<71><30><79><62>}<delim>{<83><29><88><46>}<delim>{<67><39><73><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An old lady is sitting next to a Christmas tree with a lampshade on her head , opening another present 
CaptionToObject answer <p>An old lady</p> {<24><26><79><100>}
<p>a Christmas tree</p> {<78><36><100><100>}
<p>a lampshade</p> {<31><26><71><52>}
<p>her head</p> {<41><40><62><51>}
<p>another present</p> {<37><80><67><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a white shirt balances on water-filled tanks containing crabs and fish 
CaptionToObject answer <p>A man</p> {<54><17><87><89>}
<p>a white shirt</p> {<61><22><87><46>}
<p>water-filled tanks</p> {<70><81><100><100>}<delim>{<44><80><70><100>}<delim>{<21><80><46><100>}
<p>crabs</p> {<83><79><98><91>}<delim>{<47><85><68><100>}
<p>fish</p> {<48><60><60><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A blond woman watches a woman in wearing a pink flowery top holding her hand up as they both stand behind a bar 
CaptionToObject answer <p>A blond woman</p> {<16><23><36><54>}
<p>a woman</p> {<74><24><100><56>}
<p>a pink flowery top</p> {<75><38><99><54>}
<p>her hand</p> {<83><34><90><46>}<delim>{<84><33><89><47>}
<p>a bar</p> {<0><47><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in green camouflage holds a weapon and crouches down on a gray-green surface with debris to the right and the legs of other camouflaged people behind him 
CaptionToObject answer <p>A man</p> {<14><7><50><94>}
<p>green camouflage</p> {<15><7><50><87>}
<p>a weapon</p> {<22><23><66><64>}
<p>a gray-green surface</p> {<0><26><100><100>}
<p>debris</p> {<46><2><100><64>}
<p>the legs of other camouflaged people</p> {<44><1><53><24>}<delim>{<40><0><46><20>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a pink shirt carries two people in a rickshaw near the beach 
CaptionToObject answer <p>A man</p> {<38><38><53><93>}
<p>a pink shirt</p> {<43><44><53><64>}
<p>two people</p> {<60><27><83><65>}
<p>a rickshaw</p> {<37><19><90><93>}
<p>the beach</p> {<0><19><100><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy and a girl are seen , from below , inside a horizontally-suspended tire which attached by a three chains to a horizontal support 
CaptionToObject answer <p>A boy</p> {<43><30><89><66>}
<p>a girl</p> {<8><19><63><76>}
<p>a horizontally-suspended tire</p> {<1><2><100><90>}
<p>a three chains</p> {<29><27><68><55>}
<p>a horizontal support</p> {<37><36><78><43>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing glasses , a blue shirt with a black jacket and a smile 
CaptionToObject answer <p>A man</p> {<0><6><100><100>}<delim>{<39><6><81><47>}
<p>glasses</p> {<39><22><75><30>}
<p>a blue shirt</p> {<1><44><100><94>}
<p>a black jacket</p> {<1><44><100><94>}
<p>a smile</p> {<39><30><61><38>}<delim>{<42><32><59><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady putting her bike on the sidewalk as a guy carries his skateboard onto the same sidewalk 
CaptionToObject answer <p>A lady</p> {<39><4><61><89>}
<p>her bike</p> {<33><44><74><96>}
<p>the sidewalk</p> {<1><51><100><98>}
<p>a guy</p> {<58><5><79><94>}
<p>his skateboard</p> {<54><21><63><63>}
<p>the same sidewalk</p> {<1><51><100><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in white pants and floral top , a woman in dress with a brown jacket and another woman in a purple dress all hurry somewhere as the wind blows 
CaptionToObject answer <p>A woman</p> {<58><19><89><90>}
<p>white pants</p> {<64><59><85><89>}
<p>floral top</p> {<57><30><88><63>}
<p>a woman</p> {<12><19><33><72>}
<p>a brown jacket</p> {<12><26><32><42>}
<p>another woman</p> {<12><19><33><72>}
<p>a purple dress</p> {<5><31><16><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men in orange and blue safety gear stand on the dock guiding a boat inward 
CaptionToObject answer <p>Two men</p> {<28><41><38><85>}<delim>{<4><37><22><94>}
<p>orange</p> {<28><47><36><58>}<delim>{<4><42><17><59>}
<p>blue safety</p> {<5><60><15><94>}<delim>{<28><61><36><84>}
<p>the dock</p> {<1><66><51><100>}
<p>a boat</p> {<78><46><98><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian man in a jacket , glasses , and sandals is at a high altitude aiming a gun 
CaptionToObject answer <p>An Asian man</p> {<23><25><64><99>}
<p>a jacket</p> {<20><33><64><85>}
<p>glasses</p> {<37><33><44><39>}
<p>sandals</p> {<23><90><39><100>}
<p>a gun</p> {<5><37><40><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men wearing pink shirts and headscarves in an industrial kitchen prepare noodles on a griddle 
CaptionToObject answer <p>Two men</p> {<31><18><43><57>}<delim>{<55><10><85><78>}
<p>pink shirts</p> {<56><22><74><62>}
<p>headscarves</p> {<66><10><81><24>}
<p>noodles</p> {<77><70><93><79>}
<p>a griddle</p> {<59><56><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A mam is pulling up leaves and dirt from along side a building with a blower 
CaptionToObject answer <p>A mam</p> {<9><29><70><82>}
<p>leaves</p> {<46><76><86><100>}
<p>dirt</p> {<46><75><90><100>}
<p>a building</p> {<1><1><100><97>}
<p>a blower</p> {<8><50><71><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a black shirt and holding a red plastic cup sits on a bench in front of a Cigar Company while a man wearing sunglasses and black clothing sits in a wood chair next to her 
CaptionToObject answer <p>A woman</p> {<27><34><45><88>}
<p>a black shirt</p> {<28><43><46><68>}<delim>{<30><45><42><64>}
<p>a red plastic cup</p> {<26><53><30><60>}
<p>a bench</p> {<22><46><65><89>}
<p>a Cigar Company</p> {<17><2><63><44>}
<p>a man</p> {<61><29><85><92>}
<p>sunglasses</p> {<74><34><81><38>}<delim>{<74><33><80><37>}
<p>black clothing</p> {<61><40><84><87>}
<p>a wood chair</p> {<64><48><85><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in blue riding a bicycle past another woman and a man that are walking 
CaptionToObject answer <p>A woman</p> {<15><5><63><87>}
<p>blue</p> {<23><16><43><34>}
<p>a bicycle</p> {<5><39><67><96>}
<p>another woman</p> {<42><7><66><72>}<delim>{<43><7><59><72>}
<p>a man</p> {<2><1><22><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman in light blue knit hat and light blue zippered jacket kneels in front of a bowl of liquid and small bottle 
CaptionToObject answer <p>Woman</p> {<42><0><99><77>}
<p>light blue knit hat</p> {<56><0><82><15>}
<p>light blue zippered jacket</p> {<44><20><98><49>}
<p>a bowl of liquid</p> {<45><76><89><99>}
<p>small bottle</p> {<28><72><37><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man in a red quilted vest displays an assortment of silver pendants around his neck as he watches a woman in a yellow bikini top , a black jacket , and bright pink fingerless gloves go by 
CaptionToObject answer <p>A young man</p> {<25><21><50><100>}
<p>a red quilted vest</p> {<25><32><50><83>}
<p>an assortment of silver pendants</p> {<29><32><39><67>}
<p>his neck</p> {<28><33><40><66>}<delim>{<65><29><79><46>}
<p>a woman</p> {<51><1><89><100>}
<p>a yellow bikini top</p> {<65><51><83><70>}
<p>a black jacket</p> {<51><33><87><99>}
<p>bright pink fingerless gloves</p> {<64><37><78><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A male figure in a long-sleeve shirt and suspenders is standing in the entry to a black train 
CaptionToObject answer <p>A male figure</p> {<19><10><85><86>}
<p>a long-sleeve shirt</p> {<28><21><84><46>}
<p>suspenders</p> {<46><21><65><41>}
<p>the entry</p> {<22><0><70><90>}
<p>a black train</p> {<1><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Little girl wearing a zebra striped dress and a flower in her hair smiling while holding a stuffed animal 
CaptionToObject answer <p>Little girl</p> {<53><12><83><100>}
<p>a zebra striped dress</p> {<57><43><84><98>}
<p>a flower</p> {<60><12><66><20>}
<p>her hair</p> {<58><14><82><49>}
<p>a stuffed animal</p> {<41><38><68><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a black shirt carries a blue bucket while walking with men dressed in white 
CaptionToObject answer <p>A boy</p> {<18><27><73><100>}
<p>a black shirt</p> {<17><43><72><100>}
<p>a blue bucket</p> {<43><81><89><100>}
<p>men</p> {<46><1><88><83>}
<p>white</p> {<45><12><87><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , each wearing a white tee-shirt and headphones make adjustments to a machine while shaded by a dark umbrella-like contraption 
CaptionToObject answer <p>Two men</p> {<63><34><100><100>}<delim>{<2><39><79><100>}
<p>each</p> {<63><34><100><100>}<delim>{<2><39><79><100>}
<p>a white tee-shirt</p> {<3><46><49><94>}<delim>{<76><38><100><90>}
<p>headphones</p> {<62><31><88><58>}
<p>a dark umbrella-like contraption</p> {<17><1><100><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one younger than the other and wearing glasses , sit on the beach in shorts and read magazines 
CaptionToObject answer <p>Two men</p> {<1><4><74><70>}
<p>one</p> {<1><4><74><70>}
<p>the other</p> {<1><4><74><70>}
<p>glasses</p> {<32><13><49><20>}
<p>shorts</p> {<22><42><69><65>}
<p>read magazines</p> {<8><26><56><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Person in blue top and shorts wearing a cap standing on a road with mountain with trees in the background 
CaptionToObject answer <p>Person</p> {<40><32><68><90>}
<p>blue top</p> {<45><40><63><57>}
<p>shorts</p> {<43><55><66><67>}
<p>a cap</p> {<44><31><57><38>}
<p>mountain</p> {<0><8><100><67>}
<p>trees</p> {<0><3><100><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in black boots and a gray umbrella walks away from a group looking at a small dog 
CaptionToObject answer <p>A woman</p> {<8><9><34><88>}
<p>black boots</p> {<18><65><31><88>}
<p>a gray umbrella</p> {<8><11><33><43>}
<p>a group</p> {<73><28><96><81>}<delim>{<44><45><64><82>}<delim>{<64><27><79><78>}
<p>a small dog</p> {<58><68><68><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women standing beside a silver and blue car with a Redbull logo and a giant Redbull can on it 
CaptionToObject answer <p>Two women</p> {<80><25><96><99>}<delim>{<67><21><80><99>}
<p>a silver</p> {<2><34><97><94>}
<p>blue car</p> {<1><6><97><94>}
<p>a Redbull logo</p> {<28><55><69><80>}
<p>a giant Redbull</p> {<28><55><69><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and a woman , each carrying a backpack , are walking near the road 
CaptionToObject answer <p>A man</p> {<26><4><97><100>}
<p>a woman</p> {<19><24><68><100>}
<p>each</p> {<26><4><97><100>}<delim>{<19><24><68><100>}
<p>a backpack</p> {<47><20><95><100>}<delim>{<70><25><95><66>}
<p>the road</p> {<0><27><100><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in a blue shirt , tan shorts , and a red baseball cap is examining a red antique car with an U.S. flag attached in the rear 
CaptionToObject answer <p>A man</p> {<20><28><46><88>}
<p>a blue shirt</p> {<20><31><36><58>}
<p>tan shorts</p> {<21><53><35><71>}
<p>a red baseball cap</p> {<29><28><37><33>}
<p>a red antique car</p> {<38><20><66><42>}
<p>the rear</p> {<13><20><27><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a baseball player in white is sliding into the base while the player in gray is trying to tag him 
CaptionToObject answer <p>a baseball player</p> {<29><49><72><74>}
<p>white</p> {<37><56><62><74>}
<p>the base</p> {<14><66><25><73>}
<p>the player</p> {<29><49><72><74>}
<p>gray</p> {<13><32><36><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man with glasses in an orange jumpsuit holding something in his hand 
CaptionToObject answer <p>Man</p> {<43><12><100><100>}
<p>glasses</p> {<71><20><86><31>}
<p>an orange jumpsuit</p> {<57><24><100><90>}
<p>something</p> {<38><52><64><66>}
<p>his hand</p> {<52><56><69><66>}<delim>{<43><48><67><58>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A male in a black shirt and brown cargo pants holding a shovel above his head 
CaptionToObject answer <p>A male</p> {<42><10><76><90>}
<p>a black shirt</p> {<52><25><72><57>}
<p>brown cargo pants</p> {<56><53><70><89>}
<p>a shovel</p> {<38><7><86><18>}
<p>his head</p> {<58><16><65><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Other children look on as a boy in a yellow coat holds a red pot by the handle , tilting it towards a light orange tube 
CaptionToObject answer <p>Other children</p> {<0><1><16><29>}<delim>{<20><1><48><97>}
<p>a boy</p> {<43><2><83><100>}
<p>a yellow coat</p> {<41><16><83><73>}
<p>a red pot</p> {<51><26><87><58>}
<p>the handle</p> {<70><26><83><38>}
<p>a light orange tube</p> {<46><45><62><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older man in jeans and a sweater is lifting down a box from the top of a pile 
CaptionToObject answer <p>An older man</p> {<40><16><87><84>}
<p>jeans</p> {<44><56><63><81>}
<p>a sweater</p> {<42><23><80><57>}
<p>a box</p> {<61><11><91><26>}
<p>the top of a pile</p> {<7><79><81><99>}<delim>{<59><12><100><27>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with dirty blond-hair and sunglasses and a man with dark hair stand in front of a record store 
CaptionToObject answer <p>A woman</p> {<9><62><58><100>}
<p>dirty blond-hair</p> {<17><60><57><97>}
<p>sunglasses</p> {<10><63><56><99>}<delim>{<51><78><58><87>}
<p>a man</p> {<77><61><100><100>}
<p>dark hair</p> {<79><61><94><75>}
<p>a record store</p> {<0><0><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt and jeans feeding material into industrial machinery 
CaptionToObject answer <p>A man</p> {<68><16><100><100>}
<p>a blue shirt</p> {<76><26><100><52>}
<p>jeans</p> {<82><47><100><100>}
<p>material</p> {<68><45><100><51>}
<p>industrial machinery</p> {<0><30><82><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is playing guitar while young children dance around him and older children play soccer 
CaptionToObject answer <p>A man</p> {<25><1><100><100>}
<p>guitar</p> {<24><1><99><53>}
<p>young children</p> {<1><55><38><100>}<delim>{<33><30><53><62>}<delim>{<1><32><33><71>}<delim>{<65><51><78><78>}
<p>older children</p> {<33><30><53><62>}
<p>soccer</p> {<43><55><53><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman dressed in a light yellow tank top , white pants , and sunglasses looks to her right as she is drinking a bottle of water 
CaptionToObject answer <p>A woman</p> {<1><8><48><100>}
<p>a light yellow tank top</p> {<7><23><42><53>}
<p>white pants</p> {<8><50><40><100>}
<p>sunglasses</p> {<8><15><19><19>}
<p>a bottle of water</p> {<13><26><22><41>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a knit cap and a man in a peacoat sit on a subway , laden with bags 
CaptionToObject answer <p>A woman</p> {<2><8><55><99>}
<p>a knit cap</p> {<23><11><38><18>}
<p>a man</p> {<51><2><100><100>}
<p>a peacoat</p> {<50><20><100><93>}
<p>bags</p> {<65><31><99><57>}<delim>{<6><38><56><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a plaid shirt and brown pants walking around town with one hand in his pocket 
CaptionToObject answer <p>A man</p> {<43><18><69><100>}
<p>a plaid shirt</p> {<46><28><70><83>}
<p>brown pants</p> {<48><68><65><100>}
<p>one hand</p> {<51><66><60><79>}
<p>his pocket</p> {<52><68><59><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman and a little boy with a backpack walking with an umbrella in the city 
CaptionToObject answer <p>A woman</p> {<38><40><54><80>}
<p>a little boy</p> {<52><54><61><81>}
<p>a backpack</p> {<52><57><59><70>}
<p>an umbrella</p> {<56><56><70><72>}
<p>the city</p> {<0><62><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bearded white man in a beanie and yellow jacket stands next to a fallen tree while looking toward another man 
CaptionToObject answer <p>A bearded white man</p> {<5><19><40><98>}
<p>a beanie</p> {<16><18><25><29>}
<p>yellow jacket</p> {<5><28><36><65>}
<p>a fallen tree</p> {<24><1><100><99>}<delim>{<25><50><55><99>}
<p>another man</p> {<75><17><100><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a light red shirt is riding a bike and right behind him is a small child wearing a green shirt 
CaptionToObject answer <p>A man</p> {<1><8><23><78>}
<p>a light red shirt</p> {<6><19><22><43>}
<p>a bike</p> {<0><50><71><88>}
<p>a small child</p> {<42><30><57><82>}
<p>a green shirt</p> {<46><41><56><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A shirtless , bearded and mustached man peers through a home 's doorway while a cat sits on the bottom step of the entrance to the home 
CaptionToObject answer <p>A shirtless , bearded and mustached man</p> {<36><6><60><26>}
<p>a home 's doorway</p> {<28><1><64><49>}
<p>a cat</p> {<19><76><47><100>}
<p>the bottom step of the entrance</p> {<1><90><73><100>}
<p>the home</p> {<1><1><100><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The man and woman both wearing orange tops are down on the floor wiping at it with towels in their hands 
CaptionToObject answer <p>The man</p> {<1><0><28><53>}
<p>woman</p> {<39><0><85><54>}
<p>orange tops</p> {<50><9><76><43>}
<p>the floor</p> {<0><49><100><100>}
<p>towels</p> {<13><43><29><52>}
<p>their hands</p> {<5><42><84><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man playing basketball at an outdoor , fenced-in park , goes for the shot , while another man in gray pants tries to block him 
CaptionToObject answer <p>A man</p> {<64><42><91><91>}
<p>basketball</p> {<65><38><74><44>}
<p>the shot</p> {<65><38><77><47>}
<p>another man</p> {<64><42><91><91>}
<p>gray pants</p> {<57><69><76><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a white basketball uniform is dribbling a basketball past a girl in a black uniform 
CaptionToObject answer <p>A girl</p> {<52><18><98><88>}
<p>a white basketball uniform</p> {<4><27><38><71>}
<p>a basketball</p> {<23><70><40><84>}
<p>a girl</p> {<52><18><98><88>}
<p>a black uniform</p> {<71><27><97><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A small child on riding toy and a larger child on a small bicycle with training wheels 
CaptionToObject answer <p>A small child</p> {<16><30><40><100>}
<p>toy</p> {<11><58><51><100>}
<p>a larger child</p> {<37><2><62><90>}
<p>a small bicycle</p> {<11><58><51><100>}<delim>{<36><37><69><100>}
<p>training wheels</p> {<62><89><69><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person in a black winter coat and a scarf is carving a snow sculpture with a knife 
CaptionToObject answer <p>A person</p> {<35><5><92><100>}
<p>a black winter coat</p> {<40><6><92><100>}
<p>a scarf</p> {<43><25><76><65>}
<p>a snow sculpture</p> {<17><35><41><92>}<delim>{<74><0><100><63>}
<p>a knife</p> {<33><56><39><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman in a white dress standing with a tennis racket and two people in green behind her 
CaptionToObject answer <p>Woman</p> {<26><10><70><98>}
<p>a white dress</p> {<30><33><65><90>}
<p>a tennis racket</p> {<3><43><58><80>}
<p>two people</p> {<64><24><94><96>}<delim>{<45><26><70><95>}
<p>green</p> {<71><24><94><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older woman wearing a brown hat , a plaid shirt , and striped white pants is holding a blue bag while sitting in an orange seat on the subway 
CaptionToObject answer <p>An older woman</p> {<14><13><100><100>}
<p>a brown hat</p> {<14><14><55><34>}
<p>a plaid shirt</p> {<13><29><82><81>}
<p>striped white pants</p> {<31><71><100><100>}
<p>a blue bag</p> {<71><46><100><84>}
<p>an orange seat</p> {<0><43><89><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a white shirt with a shopping bag stops on the street to feed a puppy 
CaptionToObject answer <p>A girl</p> {<47><7><85><67>}
<p>a white shirt</p> {<59><16><85><46>}
<p>a shopping bag</p> {<62><42><89><71>}
<p>the street</p> {<0><50><100><100>}
<p>a puppy</p> {<33><51><52><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and woman , on a park trail , pose in front of a lake and distant mountain 
CaptionToObject answer <p>A man</p> {<2><25><91><90>}
<p>woman</p> {<47><29><79><94>}
<p>a park trail</p> {<2><53><93><100>}
<p>a lake</p> {<0><46><34><75>}
<p>distant mountain</p> {<2><26><39><42>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady with a green shirt and tan shorts is picking out strawberries and putting them in a plastic bag 
CaptionToObject answer <p>A lady</p> {<20><34><77><100>}
<p>a green shirt</p> {<34><44><74><73>}
<p>tan shorts</p> {<49><70><80><88>}
<p>strawberries</p> {<40><83><52><92>}<delim>{<0><67><27><79>}
<p>a plastic bag</p> {<33><65><53><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue-green shirt walking by a building with a poster of a woman in a black dress 
CaptionToObject answer <p>A man</p> {<79><71><87><98>}
<p>a blue-green shirt</p> {<79><73><85><83>}
<p>a building</p> {<1><1><100><97>}
<p>a poster of a woman</p> {<42><53><51><84>}
<p>a black dress</p> {<41><62><52><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A male in a green shirt and jeans is sitting on the floor while turned to look slightly up at a female with a blue shirt and jeans sitting in a green chair 
CaptionToObject answer <p>A male</p> {<6><15><61><100>}
<p>a green shirt</p> {<16><33><51><75>}
<p>jeans</p> {<15><62><61><100>}<delim>{<48><33><74><71>}
<p>the floor</p> {<1><55><91><100>}
<p>a female</p> {<41><7><85><85>}
<p>a blue shirt</p> {<42><21><60><35>}
<p>a green chair</p> {<34><21><73><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Blond man with chin-length hair is staring at the camera , while the man in the black cap is looking down and scooping something in a bowl 
CaptionToObject answer <p>Blond man</p> {<46><9><100><100>}
<p>chin-length hair</p> {<54><9><91><56>}
<p>the man</p> {<2><14><50><98>}
<p>the black cap</p> {<19><13><36><35>}
<p>a bowl</p> {<44><78><53><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women with aprons are dipping slices of bread in mixture and putting them on a pot while another one looks at the process 
CaptionToObject answer <p>Two women</p> {<4><11><52><100>}<delim>{<45><13><77><76>}
<p>aprons</p> {<4><36><46><100>}<delim>{<44><30><71><81>}
<p>slices of bread</p> {<31><82><51><99>}<delim>{<77><67><91><74>}
<p>mixture</p> {<63><72><77><81>}
<p>a pot</p> {<60><57><77><72>}
<p>another one</p> {<43><11><76><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a yellow shirt is doing a ballerina pose outside , you can see trees and the sky in the background 
CaptionToObject answer <p>A woman</p> {<25><35><52><91>}
<p>a yellow shirt</p> {<38><44><52><62>}
<p>a ballerina</p> {<25><35><52><91>}
<p>trees</p> {<1><60><100><81>}
<p>the sky</p> {<0><1><100><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a pink jacket is walking past a display window with a red dress in an urban setting 
CaptionToObject answer <p>A woman</p> {<77><47><93><100>}
<p>a pink jacket</p> {<78><52><90><75>}
<p>a display window</p> {<12><9><44><95>}
<p>a red dress</p> {<24><40><34><66>}
<p>an urban setting</p> {<21><20><41><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] 3 people in a car with rally decals , equipment on the roof and a mongolian flag flying 
CaptionToObject answer <p>3 people</p> {<18><34><94><79>}
<p>a car</p> {<18><18><94><78>}
<p>rally decals</p> {<50><54><60><62>}
<p>equipment</p> {<29><16><71><35>}
<p>the roof</p> {<29><16><71><40>}
<p>a mongolian flag</p> {<49><0><69><26>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man sits on a stool , plays a guitar and sings into a microphone next to a fountain 
CaptionToObject answer <p>A man</p> {<52><59><70><86>}
<p>a stool</p> {<62><77><76><88>}
<p>a guitar</p> {<55><66><65><79>}
<p>a microphone</p> {<49><63><61><68>}
<p>a fountain</p> {<1><63><22><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A group of people standing outside next to a tree and some chairs , there are cars and more trees in the background 
CaptionToObject answer <p>A group of people</p> {<80><29><90><90>}<delim>{<75><26><95><91>}
<p>a tree</p> {<1><0><83><81>}
<p>some chairs</p> {<0><57><33><89>}
<p>cars</p> {<80><32><100><54>}<delim>{<54><36><62><44>}
<p>more trees</p> {<78><1><98><43>}<delim>{<0><1><20><36>}<delim>{<19><1><61><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A rocky shore with two young girls walking and a lady pushing a man in a wheelchair 
CaptionToObject answer <p>A rocky shore</p> {<0><41><100><100>}<delim>{<1><0><100><43>}
<p>two young girls</p> {<78><62><96><100>}<delim>{<69><59><79><99>}
<p>a lady</p> {<1><2><20><42>}
<p>a man</p> {<1><2><20><42>}
<p>a wheelchair</p> {<15><14><34><43>}<delim>{<13><17><33><44>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman on a bicycle stops by a man who is sitting on a chair holding a typewriter on his lap 
CaptionToObject answer <p>A woman</p> {<1><3><25><93>}
<p>a bicycle</p> {<8><41><21><99>}
<p>a man</p> {<19><13><65><98>}
<p>a chair</p> {<47><63><62><96>}
<p>a typewriter</p> {<36><54><51><68>}
<p>his lap</p> {<40><53><54><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There is a man dressed in black and a woman wearing a colorful floral dress holding hands and expressing happiness at a party 
CaptionToObject answer <p>a man</p> {<15><12><56><100>}
<p>black</p> {<17><32><56><100>}
<p>a woman</p> {<51><24><83><100>}
<p>a colorful floral dress</p> {<54><58><80><100>}
<p>hands</p> {<50><47><59><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing tight green pants and no shirt is doing a handstand on a tiny platform on top of a pole 
CaptionToObject answer <p>A man</p> {<24><3><52><72>}
<p>tight green pants</p> {<24><9><51><40>}
<p>a handstand</p> {<24><3><52><72>}
<p>a tiny platform</p> {<33><68><45><73>}
<p>a pole</p> {<37><72><40><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red print skirt and black top throwing a green ball with long yellow tassels 
CaptionToObject answer <p>A woman</p> {<51><17><94><100>}
<p>a red print skirt</p> {<60><57><89><94>}
<p>black top</p> {<60><28><86><69>}
<p>a green ball</p> {<6><8><9><13>}
<p>long yellow tassels</p> {<7><7><35><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red shirt and blue jeans is walking outside while a man in a khaki jacket is right behind her 
CaptionToObject answer <p>A woman</p> {<46><2><93><100>}
<p>a red shirt</p> {<56><16><92><48>}
<p>blue jeans</p> {<56><41><89><94>}
<p>a man</p> {<2><1><40><47>}
<p>a khaki jacket</p> {<4><8><40><47>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a house wearing jeans and a sweater , is pour a drink into a glass 
CaptionToObject answer <p>A woman</p> {<38><4><69><95>}
<p>jeans</p> {<49><39><70><95>}
<p>a sweater</p> {<47><5><70><46>}
<p>a drink</p> {<35><29><42><37>}
<p>a glass</p> {<30><20><36><26>}

Train: data epoch: [0]  [  50/1000]  eta: 0:05:36  lr: 0.000001  loss: 1.8181  time: 0.3138  data: 0.0000  max mem: 29129
CaptionToObject instruction <Img><ImageHere></Img> [detection] Workers in front of a white cement mixing truck are laying new cement in front of a multistory brick building 
CaptionToObject answer <p>Workers</p> {<40><44><53><63>}<delim>{<63><20><88><76>}<delim>{<5><29><14><59>}
<p>a white cement</p> {<0><62><74><100>}<delim>{<1><0><53><58>}
<p>truck</p> {<1><0><53><58>}
<p>new cement</p> {<1><40><80><100>}
<p>a multistory brick building</p> {<1><0><88><41>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A straight-haired white woman wearing sunglasses and sporting an arm tattoo walks past a car , clutching bright pink wallet 
CaptionToObject answer <p>A straight-haired white woman</p> {<45><14><78><100>}
<p>sunglasses</p> {<53><22><60><31>}
<p>an arm tattoo</p> {<61><56><69><66>}
<p>a car</p> {<18><13><100><100>}
<p>bright pink wallet</p> {<44><64><54><84>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An overweight man in a white hat , white shirt , and black jeans is conversing with man in a black robe in a city while a little boy stares at them both 
CaptionToObject answer <p>An overweight man</p> {<13><6><34><100>}
<p>a white hat</p> {<19><7><32><16>}
<p>white shirt</p> {<17><19><30><52>}
<p>black jeans</p> {<14><49><34><100>}
<p>a black robe</p> {<31><21><57><100>}
<p>a little boy</p> {<82><41><97><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two little boys , from the waist up , in a martial arts match , one delivering a punch and the other blocking 
CaptionToObject answer <p>Two little boys</p> {<38><10><97><100>}<delim>{<10><9><55><100>}
<p>the waist</p> {<21><87><51><97>}
<p>one</p> {<36><10><98><100>}
<p>a punch</p> {<36><9><54><29>}
<p>the other blocking</p> {<10><9><55><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two people have their heads down on a table while a man in a brown jacket looks out the window at a group of bikes and motorcycles 
CaptionToObject answer <p>Two people</p> {<3><55><30><90>}<delim>{<31><50><47><98>}
<p>their heads</p> {<37><54><44><65>}<delim>{<22><56><30><69>}
<p>a table</p> {<10><65><49><83>}
<p>a man</p> {<57><53><93><100>}
<p>a brown jacket</p> {<66><66><92><99>}
<p>a group of bikes</p> {<10><29><22><59>}<delim>{<47><32><76><73>}
<p>motorcycles</p> {<10><25><22><59>}<delim>{<39><43><72><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and a woman both dressed completely in white share a kiss on a beach 
CaptionToObject answer <p>A man</p> {<33><44><72><98>}
<p>a woman</p> {<25><47><48><97>}
<p>white</p> {<39><48><72><96>}<delim>{<31><54><48><92>}
<p>a kiss</p> {<29><44><45><54>}
<p>a beach</p> {<0><66><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman in a black jacket skinny jeans and tall black boots walking down a sidewalk next to a man in khaki pants with a white shirt walking the opposite direction 
CaptionToObject answer <p>Woman</p> {<40><25><61><76>}
<p>a black jacket skinny jeans</p> {<38><28><61><49>}
<p>tall black boots</p> {<44><65><56><76>}<delim>{<45><65><51><76>}
<p>a sidewalk</p> {<0><39><100><100>}
<p>a man</p> {<0><29><23><78>}
<p>khaki pants</p> {<0><51><20><73>}
<p>a white shirt</p> {<1><36><22><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A female gymnast wearing a red leotard on a balance beam with arms raised over her head 
CaptionToObject answer <p>A female gymnast</p> {<4><20><70><100>}
<p>a red leotard</p> {<16><28><66><72>}
<p>a balance beam</p> {<0><96><58><100>}
<p>arms</p> {<18><35><38><49>}<delim>{<54><27><61><45>}
<p>her head</p> {<44><37><57><47>}<delim>{<42><37><57><48>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman in a green dress standing on a street with cars and bicycles behind her 
CaptionToObject answer <p>Woman</p> {<57><50><86><97>}
<p>a green dress</p> {<64><60><84><79>}
<p>a street</p> {<0><78><99><100>}
<p>cars</p> {<1><56><67><86>}<delim>{<23><52><59><58>}
<p>bicycles</p> {<22><50><59><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a mustache and beard is holding a frying pan that has flames rising from it 
CaptionToObject answer <p>A man</p> {<66><15><99><92>}
<p>a mustache</p> {<77><35><82><39>}
<p>beard</p> {<77><31><87><42>}
<p>a frying pan</p> {<12><52><66><79>}
<p>flames</p> {<4><1><50><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in knee-high black boots shows a guy how to dance while a man plays a lute-guitar on a small stage 
CaptionToObject answer <p>A woman</p> {<33><26><56><84>}
<p>knee-high black boots</p> {<40><64><46><79>}<delim>{<33><65><41><84>}
<p>a guy</p> {<46><18><77><89>}
<p>a man</p> {<46><18><77><89>}
<p>a lute-guitar</p> {<10><32><26><45>}
<p>a small stage</p> {<0><61><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a ponytail dressed in jean shorts and a black tank top sitting on the lap of a man with camo shorts and a white shirt on a subway 
CaptionToObject answer <p>A woman</p> {<39><9><99><99>}
<p>a ponytail</p> {<63><12><71><30>}
<p>jean shorts</p> {<63><79><95><86>}
<p>a black tank top</p> {<35><31><73><72>}
<p>the lap of a man</p> {<1><19><84><99>}
<p>camo shorts</p> {<27><77><86><100>}
<p>a white shirt</p> {<2><43><37><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a jean jacket and black sunglasses stands outside with two young boys by a kiosk , looking at a paper she is holding in her hand 
CaptionToObject answer <p>A woman</p> {<11><19><52><100>}
<p>black sunglasses</p> {<27><35><39><44>}
<p>two young boys</p> {<51><31><85><100>}<delim>{<34><47><65><100>}
<p>a kiosk</p> {<71><1><100><100>}
<p>a paper</p> {<44><72><64><85>}
<p>her hand</p> {<39><80><52><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A dog follows a woman in a black dress with orange hair down a road 
CaptionToObject answer <p>A dog</p> {<21><73><32><91>}
<p>a woman</p> {<29><53><38><79>}
<p>a black dress</p> {<30><59><36><78>}
<p>orange hair</p> {<31><55><34><59>}
<p>a road</p> {<1><46><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl with blond-hair , wearing a pink shirt , walks away from a topiary garden where a hedge has been cut to look like a ladybug 
CaptionToObject answer <p>A little girl</p> {<4><74><25><100>}
<p>blond-hair</p> {<7><75><25><96>}
<p>a pink shirt</p> {<4><91><25><100>}
<p>a topiary garden</p> {<37><56><73><86>}
<p>a hedge</p> {<45><86><100><100>}
<p>a ladybug</p> {<41><64><70><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman , talking on her cellphone , and a man are standing outside of a Sbarro pizza restaurant , next to the subway 
CaptionToObject answer <p>A woman</p> {<46><41><63><63>}
<p>her cellphone</p> {<53><46><55><50>}
<p>a man</p> {<71><31><99><100>}
<p>a Sbarro pizza restaurant</p> {<22><10><78><81>}
<p>the subway</p> {<0><55><72><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman in pink top riding a bicycle along side a man jogging along the waterfront 
CaptionToObject answer <p>Woman</p> {<44><3><83><100>}
<p>pink top</p> {<67><17><81><51>}
<p>a bicycle</p> {<15><44><100><100>}
<p>a man</p> {<75><1><100><100>}
<p>the waterfront</p> {<1><63><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man watching a woman perform on stage in a cream costume with black boots and feather headdress 
CaptionToObject answer <p>A young man</p> {<77><18><100><100>}
<p>a woman</p> {<0><1><28><100>}
<p>stage</p> {<0><92><52><100>}
<p>a cream costume</p> {<0><0><27><99>}
<p>black boots</p> {<9><77><22><100>}
<p>feather headdress</p> {<6><0><28><23>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with long hair and sunglasses is wearing blue clothing and paint while holding a blue guitar on a sidewalk 
CaptionToObject answer <p>A man</p> {<23><21><68><82>}
<p>long hair</p> {<41><19><59><33>}
<p>sunglasses</p> {<45><23><55><27>}
<p>blue clothing</p> {<29><30><93><83>}
<p>paint</p> {<23><21><68><82>}
<p>a blue guitar</p> {<31><31><84><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A singer with medium-short curly white hair , wearing a white sleeveless t-shirt , is accompanied by a guitarist who has long white hair and wears a black shirt 
CaptionToObject answer <p>A singer</p> {<29><10><49><99>}
<p>medium-short curly white hair</p> {<29><10><49><99>}<delim>{<33><10><44><25>}
<p>a white sleeveless t-shirt</p> {<30><27><45><63>}
<p>a guitarist</p> {<44><17><79><92>}
<p>long white hair</p> {<47><17><63><37>}
<p>a black shirt</p> {<44><32><57><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a blue hat and gray sweatshirt sits with a dark-haired female doctor while she has an IV in her hand 
CaptionToObject answer <p>A woman</p> {<36><1><100><100>}
<p>a blue hat</p> {<85><1><100><30>}
<p>gray sweatshirt</p> {<61><34><100><100>}
<p>a dark-haired female doctor</p> {<13><14><40><100>}
<p>an IV</p> {<43><52><55><63>}
<p>her hand</p> {<39><55><52><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black jacket and cap is talking to a woman with a blue scarf 
CaptionToObject answer <p>A man</p> {<42><12><100><100>}
<p>a black jacket</p> {<45><37><100><100>}
<p>cap</p> {<47><13><70><42>}
<p>a woman</p> {<1><30><39><100>}
<p>a blue scarf</p> {<6><55><35><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] women in white shirt sitting on a folding chair with three boys in black shirts standing behind her 
CaptionToObject answer <p>women</p> {<16><39><53><87>}
<p>white shirt</p> {<24><51><51><81>}
<p>a folding chair</p> {<22><65><55><100>}
<p>three boys</p> {<49><35><74><90>}
<p>black shirts</p> {<76><43><100><72>}<delim>{<49><44><75><64>}<delim>{<13><33><36><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] On a clear blue day , an ocean surfer catches a wave and delicately maintains his balance on the surfboard as he rides towards the shore 
CaptionToObject answer <p>a clear blue day</p> {<1><15><100><39>}
<p>an ocean surfer</p> {<48><41><54><52>}
<p>a wave</p> {<0><32><100><65>}
<p>his balance</p> {<45><41><54><54>}
<p>the surfboard</p> {<45><48><55><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a black shirt punches a yellow punching bag while a boy in a blue sweatshirt holds the bag 
CaptionToObject answer <p>A boy</p> {<50><14><87><99>}
<p>a black shirt</p> {<50><28><87><66>}
<p>a yellow punching bag</p> {<36><29><51><58>}
<p>a boy</p> {<7><1><43><100>}
<p>a blue sweatshirt</p> {<8><16><42><86>}
<p>the bag</p> {<39><29><51><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A white male wears a hat that features Jamaican colors , blue and white striped shirt , black jeans , and brown shoes sits in front of a microphone 
CaptionToObject answer <p>A white male</p> {<2><9><72><99>}
<p>a hat</p> {<27><8><53><26>}
<p>Jamaican colors</p> {<27><9><51><23>}
<p>blue and white striped shirt</p> {<2><31><73><100>}<delim>{<8><33><70><87>}
<p>black jeans</p> {<20><40><71><99>}
<p>brown shoes</p> {<1><83><50><100>}
<p>a microphone</p> {<84><29><92><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a white t-shirt and jeans is holding a mallet and chisel next to his abstract sculpture which stands on several bricks 
CaptionToObject answer <p>A man</p> {<26><10><53><97>}
<p>a white t-shirt</p> {<27><21><50><48>}
<p>jeans</p> {<29><44><40><94>}
<p>a mallet</p> {<38><27><44><35>}
<p>chisel</p> {<45><25><55><29>}
<p>his abstract sculpture</p> {<50><12><68><60>}
<p>several bricks</p> {<39><56><79><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a man with a black hat and jacket is loading two horses with cargo 
CaptionToObject answer <p>a man</p> {<51><36><68><100>}
<p>a black hat</p> {<57><36><67><49>}
<p>jacket</p> {<54><46><67><73>}
<p>two horses</p> {<26><23><53><100>}<delim>{<62><44><100><100>}
<p>cargo</p> {<13><34><37><79>}<delim>{<65><31><92><57>}<delim>{<37><27><63><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man , two women , and a child watch fireworks while the child sits on the shoulders of one woman 
CaptionToObject answer <p>A man</p> {<9><26><27><100>}
<p>two women</p> {<67><60><87><100>}<delim>{<40><45><59><100>}
<p>a child</p> {<68><24><87><63>}
<p>fireworks</p> {<45><24><61><43>}<delim>{<26><27><35><35>}
<p>the child</p> {<68><24><87><63>}
<p>the shoulders of one woman</p> {<69><57><89><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing blue jeans , a blue shirt , and a green hat is holding a loudspeaker on a city street 
CaptionToObject answer <p>A man</p> {<8><28><29><100>}
<p>blue jeans</p> {<11><71><26><100>}
<p>a blue shirt</p> {<9><41><28><75>}
<p>a green hat</p> {<8><28><20><38>}
<p>a loudspeaker</p> {<17><29><30><41>}
<p>a city street</p> {<0><41><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man with flag walking with other and man in wheelchair 
CaptionToObject answer <p>Man</p> {<49><48><73><100>}
<p>flag</p> {<23><13><58><57>}<delim>{<26><14><62><67>}
<p>other</p> {<60><54><85><97>}<delim>{<1><48><19><83>}
<p>man</p> {<49><48><73><100>}
<p>wheelchair</p> {<14><76><37><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The barefooted person has some type of contraption over his face and something in his hand with tools laying around 
CaptionToObject answer <p>The barefooted person</p> {<24><1><65><83>}
<p>some type of contraption</p> {<40><2><63><20>}
<p>his face</p> {<44><9><59><17>}
<p>something</p> {<42><39><54><51>}
<p>his hand</p> {<37><40><48><49>}<delim>{<38><41><47><48>}
<p>tools</p> {<44><39><54><51>}<delim>{<54><39><100><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A mother and daughter , help a young boy prepare the sale from the dock 
CaptionToObject answer <p>A mother</p> {<15><24><31><93>}
<p>daughter</p> {<28><32><54><95>}
<p>a young boy</p> {<65><24><92><88>}
<p>the sale</p> {<2><4><77><98>}
<p>the dock</p> {<61><55><99><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in an orange shirt , with a blue bookbag across his shoulder , talks with a man wearing a red kilt and holding bagpipes 
CaptionToObject answer <p>A boy</p> {<20><52><44><100>}
<p>an orange shirt</p> {<19><61><42><92>}
<p>a blue bookbag</p> {<27><66><48><95>}
<p>his shoulder</p> {<56><43><68><50>}
<p>a man</p> {<33><31><73><86>}
<p>a red kilt</p> {<46><67><77><100>}
<p>bagpipes</p> {<34><25><91><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a red poncho is talking on her cellphone while holding her daughter who is wearing a pink dress 
CaptionToObject answer <p>A woman</p> {<2><1><67><100>}
<p>a red poncho</p> {<0><34><69><100>}
<p>her cellphone</p> {<22><21><25><27>}
<p>her daughter</p> {<46><11><100><100>}
<p>a pink dress</p> {<46><36><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two Asian women in red bottoms , one in a blue top , one in a white top , leaning down over something while the woman in the blue top smiles 
CaptionToObject answer <p>Two Asian women</p> {<52><12><100><99>}<delim>{<9><1><58><100>}
<p>red bottoms</p> {<25><64><56><100>}
<p>one</p> {<52><12><100><99>}<delim>{<9><1><58><100>}
<p>a blue top</p> {<56><43><100><87>}
<p>a white top</p> {<8><11><49><80>}
<p>the woman</p> {<52><12><100><99>}
<p>the blue top</p> {<56><43><100><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in blue jeans uses his jacket as a pillow as he lies on a stone bench 
CaptionToObject answer <p>A man</p> {<18><36><84><67>}
<p>blue jeans</p> {<42><40><77><58>}
<p>his jacket</p> {<19><54><40><68>}
<p>a pillow</p> {<20><52><40><68>}
<p>a stone bench</p> {<18><47><74><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There is lady with the white apron has an utensil standing over a wok , a man in blue shorts and blue shirt sitting down , a person in a pink shirt and others are in the background all in one place 
CaptionToObject answer <p>lady</p> {<30><22><53><100>}
<p>the white apron</p> {<33><32><48><81>}
<p>an utensil</p> {<40><64><59><76>}
<p>a wok</p> {<40><63><60><76>}
<p>a man</p> {<23><26><35><73>}
<p>blue shorts</p> {<25><47><33><69>}
<p>blue shirt</p> {<24><32><35><52>}
<p>a person</p> {<73><31><80><51>}
<p>a pink shirt</p> {<75><31><80><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A couple is sitting on the sand with their feet in the water , and they are shaking hands 
CaptionToObject answer <p>A couple</p> {<51><0><100><87>}<delim>{<12><17><58><100>}
<p>the sand</p> {<1><69><100><100>}<delim>{<0><1><100><77>}
<p>their feet</p> {<19><93><39><100>}
<p>the water</p> {<1><69><100><100>}
<p>hands</p> {<47><50><60><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in blue coat , a red plaid shirt , and a sailor hat , sits on a park bench next to a bicycle 
CaptionToObject answer <p>A man</p> {<29><22><64><85>}
<p>blue coat</p> {<37><31><64><58>}
<p>a red plaid shirt</p> {<43><35><56><61>}
<p>a sailor hat</p> {<48><22><56><30>}
<p>a park bench</p> {<0><31><27><69>}
<p>a bicycle</p> {<58><42><81><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man playing with two small children in a park or field , both of whom have bright red-hair 
CaptionToObject answer <p>A young man</p> {<11><21><82><71>}
<p>two small children</p> {<11><5><71><46>}<delim>{<15><41><72><88>}
<p>a park or field</p> {<0><1><100><100>}
<p>both of whom</p> {<11><5><71><46>}<delim>{<15><41><72><88>}
<p>bright red-hair</p> {<26><5><48><18>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two soccer players , one in white , the other in maroon , are playing and the player in white is going for a header 
CaptionToObject answer <p>Two soccer players</p> {<5><17><46><89>}<delim>{<35><35><99><99>}
<p>white</p> {<11><26><45><62>}<delim>{<10><26><45><42>}
<p>the other</p> {<35><35><99><99>}
<p>maroon</p> {<35><35><99><99>}
<p>the player</p> {<5><17><46><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older Asian man wearing jeans , white shirt and baseball cap is carrying a bag leaving a building 
CaptionToObject answer <p>An older Asian man</p> {<1><20><32><100>}
<p>jeans</p> {<0><50><18><100>}
<p>white shirt</p> {<0><32><21><52>}
<p>baseball cap</p> {<5><19><23><25>}
<p>a bag</p> {<4><33><29><70>}
<p>a building</p> {<1><1><94><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person , dressed as " Santa Claus " , is wearing a red coat and standing in a crowded room of people while a few people take pictures 
CaptionToObject answer <p>A person</p> {<45><32><73><100>}
<p>Santa Claus</p> {<45><32><73><100>}
<p>a red coat</p> {<46><32><75><100>}
<p>a few people</p> {<0><29><16><78>}<delim>{<30><34><50><93>}
<p>pictures</p> {<8><39><14><47>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with his hands up in front of a table with bowls and ice cream 
CaptionToObject answer <p>A man</p> {<26><31><76><83>}
<p>his hands</p> {<65><32><76><47>}
<p>a table</p> {<30><79><100><100>}
<p>bowls</p> {<48><82><64><98>}
<p>ice cream</p> {<34><75><49><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men ; one in a blue shirt and ball cap , and the other in a white shirt playing frisbee on a field near an airport 
CaptionToObject answer <p>Two men</p> {<46><9><88><93>}<delim>{<42><15><70><90>}
<p>one</p> {<46><9><88><93>}
<p>a blue shirt</p> {<63><23><76><59>}
<p>ball cap</p> {<63><8><73><18>}
<p>the other</p> {<42><15><70><90>}
<p>a white shirt</p> {<42><23><60><54>}
<p>a field</p> {<0><19><100><99>}
<p>an airport</p> {<0><0><100><20>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women , one wearing a blue and white striped shirt and the other holding a brown coat , are standing in a field with two dogs 
CaptionToObject answer <p>Two women</p> {<35><23><44><67>}<delim>{<45><23><54><72>}
<p>one</p> {<33><23><44><69>}
<p>a blue and white striped shirt</p> {<36><29><44><47>}
<p>the other</p> {<44><22><57><74>}
<p>a brown coat</p> {<46><37><53><50>}
<p>two dogs</p> {<42><49><60><78>}<delim>{<53><45><65><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two shirtless little boys , one leaning on the other , standing on a large rock in front of some trees 
CaptionToObject answer <p>Two shirtless little boys</p> {<19><20><53><89>}<delim>{<41><23><89><91>}
<p>one</p> {<19><20><53><89>}<delim>{<41><23><89><91>}
<p>the other ,</p> {<19><20><53><89>}
<p>a large rock</p> {<0><85><100><100>}
<p>some trees</p> {<0><1><100><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Young lady wearing a black tank top and some white sunglasses carries a big black backpack and has a cold drink on a sunny day 
CaptionToObject answer <p>Young lady</p> {<45><10><81><100>}
<p>a black tank top</p> {<54><41><80><100>}
<p>some white sunglasses</p> {<50><22><65><32>}
<p>a big black backpack</p> {<55><41><99><100>}
<p>a cold drink</p> {<46><47><55><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young boy wearing a red shirt and jeans stands in the middle of a field and throws a toy plane in the air 
CaptionToObject answer <p>A young boy</p> {<38><28><51><71>}
<p>a red shirt</p> {<38><34><50><50>}
<p>jeans</p> {<42><45><51><68>}
<p>the middle of a field</p> {<1><57><100><100>}
<p>a toy plane</p> {<42><15><50><25>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women , one wearing a scarf and the other wearing a broad brim hat , pound what may be food , on a primitive table with wooden mallets 
CaptionToObject answer <p>Two women</p> {<17><8><61><62>}
<p>one</p> {<18><14><41><63>}
<p>a scarf</p> {<23><14><38><26>}
<p>the other</p> {<40><10><61><53>}
<p>a broad brim hat</p> {<41><8><59><22>}
<p>food</p> {<49><47><69><64>}<delim>{<14><57><49><88>}
<p>a primitive table</p> {<10><41><84><100>}
<p>wooden mallets</p> {<33><50><45><67>}<delim>{<52><37><59><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman is sitting next to her SUV which has the trunk door open while a man stand by another open door 
CaptionToObject answer <p>A woman</p> {<54><68><74><88>}
<p>her SUV</p> {<5><39><71><95>}
<p>the trunk door</p> {<44><51><69><71>}
<p>a man</p> {<64><51><77><86>}
<p>another open door</p> {<44><51><69><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and an elderly lady walking with two cars to one side of them and a wall with graffiti on the other 
CaptionToObject answer <p>A man</p> {<30><45><39><89>}
<p>an elderly lady</p> {<33><55><41><83>}
<p>two cars</p> {<31><61><100><99>}<delim>{<0><58><31><100>}
<p>a wall</p> {<1><1><100><76>}
<p>graffiti</p> {<47><45><72><60>}
<p>the other</p> {<30><46><40><83>}<delim>{<33><53><41><84>}<delim>{<47><45><67><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in orange and a man in a light blue top are walking down the street towards something 
CaptionToObject answer <p>A man</p> {<15><22><57><100>}
<p>orange</p> {<35><34><55><61>}
<p>a man</p> {<64><40><90><100>}
<p>a light blue top</p> {<70><52><87><86>}
<p>the street</p> {<0><0><64><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a petterned shirt is talking to a guy with a hat in a billiards room 
CaptionToObject answer <p>A girl</p> {<10><14><53><100>}
<p>a petterned shirt</p> {<9><44><54><100>}
<p>a guy</p> {<0><14><21><100>}
<p>a hat</p> {<2><14><17><39>}
<p>a billiards room</p> {<2><3><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman wearing jeans , a white t-shirt and a hat , performs a high flying trick on a bicycle at an outdoor bike park 
CaptionToObject answer <p>A young woman</p> {<14><13><86><57>}
<p>jeans</p> {<31><31><54><51>}
<p>a white t-shirt</p> {<31><21><63><33>}
<p>a hat</p> {<44><17><57><25>}
<p>a bicycle</p> {<22><28><71><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a man in black and a man in a red shirt and white shorts are jogging down the street 
CaptionToObject answer <p>a man</p> {<15><35><29><96>}<delim>{<26><39><43><97>}
<p>black</p> {<14><43><30><64>}
<p>a red shirt</p> {<28><46><43><70>}
<p>white shorts</p> {<29><67><39><78>}
<p>the street</p> {<1><66><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with no shirt on , holding a cup , watches a woman wearing a yellow bikini top in a crowd 
CaptionToObject answer <p>A man</p> {<46><25><100><100>}
<p>no shirt</p> {<60><50><100><100>}
<p>a cup</p> {<44><76><59><91>}
<p>a woman</p> {<6><25><54><100>}
<p>a yellow bikini top</p> {<20><41><44><66>}
<p>a crowd</p> {<46><25><100><100>}<delim>{<6><25><54><100>}<delim>{<1><34><23><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one wearing white trunks and the other wearing red boxing 
CaptionToObject answer <p>Two men</p> {<1><21><61><100>}<delim>{<42><4><98><100>}
<p>one</p> {<42><4><98><100>}
<p>white trunks</p> {<12><56><44><80>}
<p>the other</p> {<42><4><98><100>}
<p>red</p> {<53><47><88><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a colorful short-sleeved shirt and holding some sort of cloth raises both hands above his or her head 
CaptionToObject answer <p>A person</p> {<18><33><90><100>}
<p>a colorful short-sleeved shirt</p> {<37><70><82><100>}
<p>some sort of cloth</p> {<13><31><96><53>}
<p>both hands</p> {<18><31><89><50>}
<p>his or her head</p> {<49><53><70><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two young ballet dancers are performing with the boy on his knee and the girl standing on her toes 
CaptionToObject answer <p>Two young ballet dancers</p> {<31><15><68><80>}
<p>the boy</p> {<31><32><68><79>}
<p>his knee</p> {<44><60><49><67>}
<p>the girl</p> {<52><14><68><77>}
<p>her toes</p> {<51><15><67><77>}<delim>{<58><72><64><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a green blazer is shaking hands with a man in a suit in front of a large crowd of people 
CaptionToObject answer <p>A woman</p> {<54><22><89><100>}
<p>a green blazer</p> {<55><50><88><100>}
<p>hands</p> {<54><80><59><89>}
<p>a man</p> {<16><5><62><100>}
<p>a suit</p> {<17><30><56><100>}
<p>a large crowd of people</p> {<54><22><89><100>}<delim>{<1><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman is performing a martial arts move with her leg in the air in a gym with five teammates or competitors looking on 
CaptionToObject answer <p>A woman</p> {<34><18><66><89>}
<p>a martial arts</p> {<34><18><66><89>}
<p>her leg</p> {<33><18><50><48>}
<p>a gym</p> {<1><0><100><95>}
<p>five teammates or competitors</p> {<34><18><66><89>}<delim>{<9><12><17><45>}<delim>{<14><14><25><47>}<delim>{<5><12><12><43>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Actors in costumes rehearsing for a play , while a man with black hair and a white shirt sits on a stairway 
CaptionToObject answer <p>Actors</p> {<42><50><78><100>}<delim>{<4><5><62><100>}
<p>costumes</p> {<3><23><39><100>}<delim>{<42><3><57><83>}<delim>{<42><62><78><100>}<delim>{<23><26><43><85>}
<p>a man</p> {<61><29><79><68>}
<p>black hair</p> {<68><29><75><38>}
<p>a white shirt</p> {<60><37><76><54>}
<p>a stairway</p> {<54><22><100><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and woman are traveling on a moped on a brick lined street 
CaptionToObject answer <p>A man</p> {<53><39><65><77>}
<p>woman</p> {<30><42><36><72>}
<p>a moped</p> {<30><49><46><81>}
<p>a brick</p> {<1><49><100><100>}
<p>street</p> {<1><49><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The black dog waring a red collar is running through the water with a ball in its mouth 
CaptionToObject answer <p>The black dog</p> {<18><12><78><100>}
<p>a red collar</p> {<30><33><62><70>}
<p>the water</p> {<1><0><100><100>}
<p>a ball</p> {<26><35><34><45>}
<p>its mouth</p> {<25><27><40><48>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] One gentleman in a hat and off white shirt is chatting with another gentleman in a black shirt while they are sipping hot drinks 
CaptionToObject answer <p>One gentleman</p> {<1><13><68><100>}
<p>a hat</p> {<13><12><33><45>}
<p>white shirt</p> {<1><46><67><100>}
<p>another gentleman</p> {<46><18><97><99>}
<p>a black shirt</p> {<46><40><96><100>}
<p>hot drinks</p> {<46><64><63><83>}<delim>{<74><58><91><75>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red tank tee , black shorts , white and black socks , with white sneakers is playing tennis , but she is kneeing on the ground 
CaptionToObject answer <p>A woman</p> {<8><21><64><92>}
<p>a red tank tee</p> {<15><30><50><63>}
<p>black shorts</p> {<18><49><35><68>}
<p>white and black socks</p> {<32><60><48><84>}
<p>white sneakers</p> {<30><79><47><92>}<delim>{<8><64><18><84>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a blue jacket and a man in a black shirt are unrolling brown paper on hay 
CaptionToObject answer <p>A woman</p> {<45><16><76><85>}
<p>a blue jacket</p> {<45><28><77><50>}
<p>a man</p> {<8><28><38><64>}
<p>a black shirt</p> {<9><33><33><50>}
<p>brown paper</p> {<15><42><45><92>}<delim>{<6><41><100><92>}
<p>hay</p> {<1><76><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person driving by a gated and locked fence in a olive colored SUV with BRIGADA written on the driver side passenger door , with an emblem surrounded by green on the driver 's door , and red lights on the top 
CaptionToObject answer <p>A person</p> {<26><18><43><42>}
<p>a gated and locked fence</p> {<1><3><92><100>}
<p>a olive colored SUV</p> {<1><3><92><100>}
<p>BRIGADA</p> {<52><53><72><64>}
<p>the driver side passenger door</p> {<1><3><92><100>}
<p>an emblem</p> {<32><45><38><62>}
<p>green</p> {<31><43><39><64>}
<p>the driver 's door</p> {<16><11><53><87>}
<p>red lights</p> {<7><3><36><16>}
<p>the top</p> {<3><10><81><18>}<delim>{<20><8><79><17>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady in a cream blouse and black pants is posing in a photo with her hand extended toward a large beige and black grill 
CaptionToObject answer <p>A lady</p> {<61><22><86><81>}
<p>a cream blouse</p> {<70><31><86><53>}
<p>black pants</p> {<69><48><84><74>}
<p>her hand</p> {<61><40><66><47>}
<p>a large beige</p> {<8><2><69><100>}
<p>black grill</p> {<21><60><63><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl wearing an orange and white dress is being taught how to ride her green-colored bicycle by her father 
CaptionToObject answer <p>A little girl</p> {<63><46><93><92>}
<p>an orange</p> {<64><56><83><77>}<delim>{<63><63><86><78>}
<p>white dress</p> {<31><31><61><66>}<delim>{<62><55><83><63>}
<p>her green-colored bicycle</p> {<59><65><99><98>}
<p>her father</p> {<19><19><68><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Person in a blue shirt and tan shorts sits with their guitar between their legs while picking at their fingers 
CaptionToObject answer <p>Person</p> {<3><2><83><98>}
<p>a blue shirt</p> {<1><17><37><57>}
<p>tan shorts</p> {<17><44><62><73>}
<p>their guitar</p> {<50><35><90><92>}
<p>their legs</p> {<20><45><70><91>}
<p>their fingers</p> {<45><28><56><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a purple shirt with her hands on her hips dancing barefoot in the middle of two other women dancing on a dance floor 
CaptionToObject answer <p>A woman</p> {<35><13><69><79>}
<p>a purple shirt</p> {<43><24><69><45>}
<p>her hands</p> {<45><40><55><47>}
<p>her hips</p> {<46><38><56><45>}
<p>the middle of two other women</p> {<35><13><69><79>}<delim>{<17><12><40><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a yellow coat and neon green safety vest pushes janitorial equipment down a sidewalk 
CaptionToObject answer <p>A man</p> {<32><1><64><84>}
<p>a yellow coat</p> {<32><0><63><75>}
<p>neon green safety vest</p> {<32><0><63><75>}
<p>janitorial equipment</p> {<50><26><74><74>}
<p>a sidewalk</p> {<6><27><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A guy wearing a white shirt and khaki pants is sitting on steps made of stone 
CaptionToObject answer <p>A guy</p> {<36><38><63><93>}
<p>a white shirt</p> {<37><49><59><72>}
<p>khaki pants</p> {<36><68><62><89>}
<p>steps</p> {<22><70><66><100>}
<p>stone</p> {<22><70><66><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brown-skinned child with an orange shirt and sandals places his hand on his head and looks into the distance against a backdrop of green vegetation 
CaptionToObject answer <p>A brown-skinned child</p> {<30><8><79><100>}
<p>an orange shirt</p> {<34><43><77><100>}
<p>sandals places</p> {<38><67><45><100>}<delim>{<30><70><40><100>}
<p>his hand</p> {<43><9><63><28>}
<p>his head</p> {<42><9><65><44>}
<p>a backdrop of green vegetation</p> {<0><1><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman wearing brown sandals and blue jeans , in a white shirt , holding a baby under a tall tree 
CaptionToObject answer <p>Woman</p> {<50><35><70><89>}
<p>brown sandals</p> {<59><85><66><90>}<delim>{<50><87><59><92>}
<p>blue jeans</p> {<52><66><67><87>}
<p>a white shirt</p> {<51><45><70><69>}
<p>a baby</p> {<29><28><47><87>}
<p>a tall tree</p> {<29><0><60><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A tanned male surf instructor wearing a black long-sleeved rash guard and surf shift holding a board and teaching a young white redheaded female wearing a red rash guard and surf shirt 
CaptionToObject answer <p>A tanned male surf instructor</p> {<35><17><100><100>}
<p>a black long-sleeved rash guard</p> {<41><56><100><100>}
<p>surf shift</p> {<76><57><100><100>}
<p>a board</p> {<0><0><56><98>}
<p>a young white redheaded female</p> {<47><9><80><100>}
<p>a red rash guard</p> {<49><36><79><100>}
<p>surf shirt</p> {<49><37><79><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Girl wearing black shirt and purple shorts swings on rope on boat 
CaptionToObject answer <p>Girl</p> {<38><9><65><64>}
<p>black shirt</p> {<38><18><61><44>}
<p>purple shorts</p> {<37><40><61><54>}
<p>rope</p> {<31><0><64><100>}
<p>boat</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two kids in snow hats and blue and green coats are swinging on a tire swing out in the snow 
CaptionToObject answer <p>Two kids</p> {<16><39><80><86>}<delim>{<13><25><64><56>}
<p>snow hats</p> {<45><38><67><55>}<delim>{<25><25><48><42>}
<p>blue and green coats</p> {<17><39><80><87>}
<p>a tire</p> {<7><49><73><87>}
<p>the snow</p> {<0><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl 's hands , another person 's feet , and a boy playing bongo drums sit on a picnic table 
CaptionToObject answer <p>A girl 's hands</p> {<11><52><31><91>}
<p>another person 's feet</p> {<23><30><59><54>}
<p>a boy</p> {<66><0><100><92>}
<p>bongo drums</p> {<86><17><100><89>}
<p>a picnic table</p> {<1><18><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl jumping off a concrete block , with her arms and hands in the air , above her head 
CaptionToObject answer <p>A young girl</p> {<24><12><67><100>}
<p>a concrete block</p> {<25><75><90><100>}
<p>her arms</p> {<25><22><36><42>}<delim>{<45><18><56><40>}
<p>hands</p> {<25><15><36><23>}<delim>{<39><14><50><23>}
<p>her head</p> {<32><29><48><42>}<delim>{<35><30><46><42>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Person in black shirt and black tutu waterskiing with hands over head and people in the background 
CaptionToObject answer <p>Person</p> {<19><21><58><78>}
<p>black shirt</p> {<19><24><58><53>}
<p>black tutu</p> {<18><34><52><64>}
<p>hands</p> {<37><21><47><26>}<delim>{<29><20><49><27>}
<p>head</p> {<31><26><47><37>}
<p>people</p> {<0><1><100><35>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An old man wearing a hat and green sandals stands in front of a counter inside a store 
CaptionToObject answer <p>An old man</p> {<63><45><92><100>}
<p>a hat</p> {<63><45><76><51>}
<p>green sandals</p> {<69><96><83><100>}
<p>a counter</p> {<0><51><52><63>}<delim>{<1><38><53><73>}
<p>a store</p> {<1><1><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There is a little boy in a swimming pool area everything around the boy and the pool are wet however the boy is not swimming but instead he is jumping into the water with blue swimming trunks on and his arms out 
CaptionToObject answer <p>a little boy</p> {<46><34><77><99>}
<p>the boy</p> {<46><34><77><99>}<delim>{<46><34><77><99>}
<p>the pool</p> {<9><56><100><100>}
<p>the water</p> {<9><56><100><100>}
<p>blue swimming trunks</p> {<50><52><63><73>}
<p>his arms</p> {<58><34><69><47>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three skateboarders in helmets round a bend in the road wearing bodysuits 
CaptionToObject answer <p>Three skateboarders</p> {<8><44><28><76>}
<p>helmets</p> {<11><43><18><55>}<delim>{<38><37><44><48>}<delim>{<83><37><89><47>}
<p>a bend</p> {<23><37><100><100>}
<p>the road</p> {<0><34><100><100>}
<p>bodysuits</p> {<36><46><49><62>}<delim>{<81><43><100><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman carrying a bag over her shoulder holds hands with a person wearing loose jeans while walking along side a row of trees towards a red sign 
CaptionToObject answer <p>A woman</p> {<23><45><52><93>}
<p>a bag</p> {<23><52><38><70>}
<p>her shoulder</p> {<54><54><71><59>}
<p>hands</p> {<44><53><58><73>}
<p>a person</p> {<51><47><74><93>}
<p>loose jeans</p> {<55><70><70><90>}
<p>a row of trees</p> {<0><0><67><85>}
<p>a red sign</p> {<46><46><56><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] People walking down the street in costumes , including one of a hospital gown that exposes the buttocks 
CaptionToObject answer <p>People</p> {<5><2><32><96>}<delim>{<38><12><66><97>}<delim>{<67><22><93><97>}
<p>the street</p> {<0><47><100><100>}
<p>costumes</p> {<67><34><92><92>}<delim>{<4><2><32><96>}<delim>{<36><29><66><92>}
<p>one of a hospital gown</p> {<67><34><92><92>}
<p>the buttocks</p> {<74><54><85><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A guy , wearing a blue striped polo shirt , holding a book in his hand is asleep in a library lounge 
CaptionToObject answer <p>A guy</p> {<7><14><85><100>}
<p>a blue striped polo shirt</p> {<23><35><77><89>}
<p>a book</p> {<43><63><66><79>}
<p>his hand</p> {<53><64><67><79>}
<p>a library lounge</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bull rider in a red shirt , black vest , and jeans rides a brown and white bull while onlookers watch from behind a green fence 
CaptionToObject answer <p>A bull rider</p> {<30><4><51><63>}
<p>a red shirt</p> {<38><12><51><33>}
<p>black vest</p> {<42><14><49><28>}
<p>jeans</p> {<32><31><48><55>}
<p>a brown and white bull</p> {<4><31><70><97>}
<p>onlookers</p> {<8><35><17><61>}<delim>{<18><37><24><59>}<delim>{<1><28><8><37>}<delim>{<57><31><65><78>}
<p>a green fence</p> {<1><34><100><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a lone hiker on a dirt hiking trail with a hat and sunglasses on with trees in the background 
CaptionToObject answer <p>a lone hiker</p> {<51><30><73><100>}
<p>trail</p> {<1><56><100><100>}
<p>a hat</p> {<58><31><68><39>}
<p>sunglasses</p> {<60><34><66><39>}
<p>trees</p> {<0><0><47><67>}<delim>{<48><27><100><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl in a blue jacket and black pants holds out her arm with a small bird in her hand 
CaptionToObject answer <p>A young girl</p> {<30><21><95><100>}
<p>a blue jacket</p> {<40><32><83><66>}
<p>black pants</p> {<58><65><93><100>}
<p>her arm</p> {<30><32><42><37>}
<p>a small bird</p> {<25><28><37><40>}
<p>her hand</p> {<32><32><42><37>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red sweater is resting her head on the shoulder of a man sitting next to her with a beard , blue jacket and jeans while riding public transportation 
CaptionToObject answer <p>A woman</p> {<0><24><47><97>}
<p>a red sweater</p> {<8><40><38><66>}
<p>her head</p> {<32><25><47><44>}
<p>the shoulder of a man</p> {<39><34><47><44>}
<p>a beard , blue jacket</p> {<41><18><51><29>}<delim>{<16><25><74><83>}
<p>jeans</p> {<0><74><66><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a plaid shirt and black hat sits on top of a white horse talking with another man wearing a black shirt and white cowboy hat sitting on a brown horse 
CaptionToObject answer <p>A man</p> {<36><7><54><86>}
<p>a plaid shirt</p> {<35><20><54><43>}
<p>black hat</p> {<41><8><52><19>}
<p>a white horse</p> {<9><39><69><100>}
<p>another man</p> {<63><13><94><88>}
<p>a black shirt</p> {<67><20><85><47>}
<p>white cowboy hat</p> {<63><13><74><30>}
<p>a brown horse</p> {<64><33><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl is playing the violin in the street while her band mate on the guitar is talking on her cellphone with a confused look 
CaptionToObject answer <p>A girl</p> {<62><6><83><94>}
<p>the violin</p> {<66><18><87><48>}
<p>the street</p> {<0><59><100><100>}
<p>her band mate</p> {<2><18><33><53>}
<p>the guitar</p> {<3><25><33><55>}
<p>her cellphone</p> {<13><10><17><21>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women dressed in ceremonial apparel are standing on the grass looking at bridge that leads to a building with a mountain in the background 
CaptionToObject answer <p>Two women</p> {<17><50><32><97>}<delim>{<7><48><17><95>}
<p>ceremonial apparel</p> {<18><57><31><97>}
<p>the grass</p> {<0><46><100><100>}
<p>bridge</p> {<14><45><100><73>}
<p>a building</p> {<36><16><100><53>}
<p>a mountain</p> {<0><18><32><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a white shirt with glasses stirring food on the stove 
CaptionToObject answer <p>A man</p> {<5><10><84><100>}
<p>a white shirt</p> {<5><23><50><90>}
<p>glasses</p> {<60><20><70><31>}
<p>food</p> {<66><69><91><78>}
<p>the stove</p> {<45><68><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a brown coat and pants is arranging dead chickens on a mat 
CaptionToObject answer <p>A man</p> {<28><17><63><63>}
<p>a brown coat</p> {<27><22><60><59>}
<p>pants</p> {<29><35><51><59>}
<p>dead chickens</p> {<64><55><81><68>}<delim>{<63><42><69><58>}<delim>{<51><56><65><80>}
<p>a mat</p> {<42><53><86><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a blue shirt and a woman with a red shirt , the woman smiles 
CaptionToObject answer <p>A man</p> {<25><20><72><100>}
<p>a blue shirt</p> {<25><43><73><100>}
<p>a woman</p> {<62><20><100><98>}
<p>a red shirt</p> {<64><50><100><100>}
<p>the woman</p> {<62><20><100><98>}

Train: data epoch: [0]  [ 100/1000]  eta: 0:05:01  lr: 0.000002  loss: 1.5969  time: 0.3103  data: 0.0000  max mem: 29129
CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a helmet , vest , and rubber boots sits with their feet in some shallow water 
CaptionToObject answer <p>A person</p> {<19><15><73><90>}
<p>a helmet</p> {<29><12><48><30>}
<p>vest</p> {<19><27><45><65>}
<p>rubber boots</p> {<48><71><66><89>}<delim>{<55><68><74><84>}
<p>their feet</p> {<55><68><74><84>}<delim>{<53><81><66><88>}
<p>some shallow water</p> {<45><64><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wakeboards on a bright yellow board wearing pink shirts a white vest and black helmet 
CaptionToObject answer <p>A person</p> {<8><65><30><81>}
<p>a bright yellow board</p> {<8><65><28><78>}
<p>pink shirts</p> {<13><41><21><60>}
<p>a white vest</p> {<11><28><21><43>}
<p>black helmet</p> {<12><15><17><28>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man dressed in black suit and tie reads a book while waiting on the subway 
CaptionToObject answer <p>Man</p> {<30><11><86><75>}
<p>black suit</p> {<24><30><87><76>}
<p>tie reads</p> {<49><33><62><56>}
<p>a book</p> {<25><49><58><67>}
<p>the subway</p> {<3><0><99><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a yellow suit kneels at the rear of a boat with many fish along the deck 
CaptionToObject answer <p>A man</p> {<34><28><60><91>}
<p>a yellow suit</p> {<34><35><59><90>}
<p>the rear of a boat</p> {<17><13><100><72>}
<p>many fish</p> {<8><66><100><100>}
<p>the deck</p> {<0><45><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with bright red lips and a striped shirt is straining in front of a microphone on a stand , while another person is in the background holding a microphone 
CaptionToObject answer <p>A woman</p> {<47><1><99><100>}
<p>bright red lips</p> {<63><35><68><42>}
<p>a striped shirt</p> {<49><68><67><100>}
<p>a microphone</p> {<46><34><66><42>}<delim>{<46><34><66><42>}
<p>a stand</p> {<28><35><58><100>}
<p>another person</p> {<1><8><21><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A male guitarist with close-cropped hair is concentrating on playing a tune on a six-string , electric guitar , standing in a spotlight on stage with band members in shadow behind him 
CaptionToObject answer <p>A male guitarist</p> {<28><7><66><100>}
<p>close-cropped hair</p> {<42><6><54><19>}<delim>{<41><5><54><18>}
<p>a six-string , electric guitar</p> {<25><49><66><96>}
<p>stage</p> {<1><2><100><100>}
<p>band members</p> {<28><7><66><100>}
<p>shadow</p> {<47><17><51><32>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A city street performer with long gray hair sits on a green bucket , two woman look on behind the man 
CaptionToObject answer <p>A city street performer</p> {<64><57><96><94>}
<p>long gray hair</p> {<69><57><81><70>}
<p>a green bucket</p> {<68><81><82><93>}
<p>two woman</p> {<18><59><33><86>}<delim>{<0><59><9><85>}
<p>the man</p> {<64><57><96><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a backpack is walking while another man pushes a cart on the street 
CaptionToObject answer <p>A man</p> {<60><47><76><98>}
<p>a backpack</p> {<19><30><40><75>}
<p>another man</p> {<18><15><45><100>}
<p>a cart</p> {<63><58><83><100>}
<p>the street</p> {<56><91><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl in red at the beach while a adult points a camera 
CaptionToObject answer <p>A little girl</p> {<50><7><85><100>}
<p>red</p> {<50><37><84><100>}
<p>the beach</p> {<1><33><100><100>}
<p>a adult</p> {<81><6><98><97>}
<p>a camera</p> {<80><13><86><27>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with headphones has his mouth wide open while a woman stands next to him 
CaptionToObject answer <p>A man</p> {<36><6><100><100>}
<p>headphones</p> {<76><21><100><53>}
<p>his mouth</p> {<61><31><67><39>}
<p>open</p> {<60><30><68><39>}
<p>a woman</p> {<0><7><60><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a red shirt with stripes standing near a blue , brick wall with handicap signs 
CaptionToObject answer <p>A boy</p> {<10><17><39><100>}
<p>a red shirt</p> {<12><46><38><100>}
<p>stripes</p> {<18><66><24><100>}
<p>a blue</p> {<20><0><100><100>}
<p>brick wall</p> {<20><0><100><100>}
<p>handicap signs</p> {<61><14><68><45>}<delim>{<43><16><47><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man in uniform is standing with his back to a museum case that has a classical bust on the top shelf 
CaptionToObject answer <p>A young man</p> {<30><15><77><89>}
<p>uniform</p> {<31><25><77><89>}
<p>a museum case</p> {<78><0><100><45>}
<p>a classical bust</p> {<84><10><96><24>}
<p>the top shelf</p> {<32><0><99><58>}<delim>{<79><23><100><25>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A happy looking , long-haired man , wearing goggles over his eyes and very colorful clothing and a hat , is standing in front of a stairway 
CaptionToObject answer <p>A happy looking , long-haired man</p> {<36><16><78><100>}
<p>goggles</p> {<52><22><64><33>}
<p>his eyes</p> {<56><26><59><31>}<delim>{<56><26><60><30>}
<p>very colorful clothing</p> {<36><43><77><100>}
<p>a hat</p> {<54><16><69><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two small children in snow clothes are walking through the snow while one carries a red sled 
CaptionToObject answer <p>Two small children</p> {<1><11><47><90>}<delim>{<29><10><93><89>}
<p>snow clothes</p> {<1><12><47><83>}<delim>{<33><23><81><88>}
<p>the snow</p> {<0><56><100><100>}
<p>one</p> {<29><10><93><89>}
<p>a red sled</p> {<27><1><100><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A tall gray pole behind which a person wearing an orange shirt is perched on the wall and hiding his or her face with one hand 
CaptionToObject answer <p>A tall gray pole</p> {<43><0><50><84>}
<p>a person</p> {<33><42><74><51>}
<p>an orange shirt</p> {<49><41><70><49>}
<p>the wall</p> {<0><30><75><88>}
<p>his or her face</p> {<57><45><64><49>}
<p>one hand</p> {<56><45><63><49>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl with ice skate sits on a fence checking her cellphone while her friend looks on 
CaptionToObject answer <p>A girl</p> {<23><7><57><91>}
<p>ice skate</p> {<32><76><42><92>}<delim>{<45><73><57><88>}
<p>a fence</p> {<1><52><100><100>}
<p>her cellphone</p> {<42><17><47><26>}
<p>her friend</p> {<65><11><85><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a t-shirt and jean shorts is standing beside a man with a gray shirt and jeans with their backs to the camera 
CaptionToObject answer <p>A woman</p> {<31><30><58><99>}
<p>a t-shirt</p> {<58><36><88><61>}
<p>jean shorts</p> {<34><61><58><72>}
<p>a man</p> {<56><26><93><98>}
<p>a gray shirt</p> {<58><36><88><61>}
<p>jeans</p> {<61><58><88><98>}
<p>their backs</p> {<31><30><58><99>}<delim>{<56><26><93><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brown horse with a white mane pulls a ploy with a man sitting on it in a field 
CaptionToObject answer <p>A brown horse</p> {<9><6><74><99>}
<p>a white mane</p> {<12><4><43><30>}
<p>a ploy</p> {<65><35><93><67>}
<p>a man</p> {<71><22><79><54>}
<p>a field</p> {<1><37><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Some female children are outside watching a man in red and a hat make large soap bubbles with some wands 
CaptionToObject answer <p>Some female children</p> {<41><59><67><100>}<delim>{<87><57><100><98>}<delim>{<28><55><39><100>}<delim>{<13><55><25><100>}<delim>{<74><48><86><95>}
<p>a man</p> {<1><43><23><100>}
<p>red</p> {<0><52><16><83>}
<p>a hat</p> {<6><42><16><50>}
<p>large soap bubbles</p> {<63><39><84><71>}
<p>some wands</p> {<15><28><36><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A small child in an orange shirt and red baseball cap plays with some leaves in his backyard 
CaptionToObject answer <p>A small child</p> {<46><17><70><99>}
<p>an orange shirt</p> {<41><37><68><67>}
<p>red baseball cap</p> {<49><18><62><33>}
<p>some leaves</p> {<0><73><100><100>}
<p>his backyard</p> {<1><8><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a straw hat and a blue shirt is standing in the water at a beach and is dragging out a red net 
CaptionToObject answer <p>A man</p> {<34><15><95><55>}
<p>a straw hat</p> {<44><14><62><25>}
<p>a blue shirt</p> {<36><15><96><49>}
<p>the water</p> {<0><30><100><100>}
<p>a beach</p> {<1><0><100><35>}
<p>a red net</p> {<0><36><72><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A mother wearing a blue shirt and white shorts carrying her two children in a crowd of people 
CaptionToObject answer <p>A mother</p> {<25><26><74><100>}
<p>a blue shirt</p> {<31><41><74><81>}
<p>white shorts</p> {<25><78><63><98>}
<p>her two children</p> {<15><3><80><82>}<delim>{<0><17><13><81>}<delim>{<14><28><60><87>}
<p>a crowd of people</p> {<72><2><100><100>}<delim>{<3><15><27><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a gray sweater and brown shorts cutting grass with a lawn mower 
CaptionToObject answer <p>A man</p> {<27><15><51><84>}
<p>a gray sweater</p> {<31><20><52><53>}
<p>brown shorts</p> {<31><46><44><62>}
<p>grass</p> {<0><77><100><100>}
<p>a lawn mower</p> {<46><40><95><84>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with blue hair and ripped pantyhose sits against a blue wall while playing her guitar 
CaptionToObject answer <p>A woman</p> {<28><31><75><71>}
<p>blue hair</p> {<43><30><62><40>}
<p>pantyhose sits</p> {<28><58><61><70>}
<p>a blue wall</p> {<1><1><100><73>}
<p>her guitar</p> {<38><43><64><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A smiling man wearing blue jeans and a blue shirt plays a guitar in front of several other people 
CaptionToObject answer <p>A smiling man</p> {<10><2><59><56>}
<p>blue jeans</p> {<20><24><54><50>}
<p>a blue shirt</p> {<10><11><37><33>}
<p>a guitar</p> {<21><13><48><31>}
<p>several other people</p> {<40><0><58><29>}<delim>{<34><3><45><15>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a suit displaying food that he is stretching from above his head down to the pot 
CaptionToObject answer <p>A man</p> {<4><0><95><100>}
<p>a suit</p> {<5><7><92><78>}
<p>food</p> {<15><0><49><98>}
<p>his head</p> {<54><16><83><33>}
<p>the pot</p> {<17><85><57><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a brown shirt talks on her phone while a girl and guy play guitar 
CaptionToObject answer <p>A girl</p> {<47><23><100><100>}
<p>a brown shirt</p> {<60><59><100><100>}
<p>her phone</p> {<69><50><75><65>}
<p>a girl</p> {<21><13><60><100>}
<p>guy</p> {<27><2><71><99>}
<p>guitar</p> {<4><15><35><100>}<delim>{<32><40><69><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two competitors , one with number thirteen on his headgear , are at battle in a large swimming pool 
CaptionToObject answer <p>Two competitors</p> {<20><48><89><82>}<delim>{<61><35><76><64>}
<p>one</p> {<20><48><89><82>}
<p>number thirteen</p> {<26><49><34><60>}
<p>his headgear</p> {<21><48><38><74>}
<p>a large swimming pool</p> {<0><12><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing an orange cap , white shirt , cargo pants , and hiking boots stands on a rock 
CaptionToObject answer <p>A man</p> {<38><10><59><96>}
<p>an orange cap</p> {<44><11><52><19>}
<p>white shirt</p> {<39><22><52><46>}
<p>cargo pants</p> {<41><45><56><90>}
<p>hiking boots</p> {<44><85><54><95>}
<p>a rock</p> {<35><92><60><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A small girl in pink and blue , on the beach , shows something to two black dogs 
CaptionToObject answer <p>A small girl</p> {<54><7><76><100>}<delim>{<57><8><75><94>}
<p>pink and blue</p> {<62><26><76><75>}
<p>the beach</p> {<11><31><99><98>}
<p>something</p> {<52><50><58><57>}
<p>two black dogs</p> {<1><32><54><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl wearing a white sweatshirt and jean shorts has a big smile on her face as she walks along 
CaptionToObject answer <p>A girl</p> {<19><20><57><100>}
<p>a white sweatshirt</p> {<19><36><58><86>}
<p>jean shorts</p> {<28><78><49><98>}
<p>a big smile</p> {<47><33><52><36>}<delim>{<47><33><52><37>}
<p>her face</p> {<41><23><54><40>}<delim>{<45><23><54><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian man in a green uniform shirt with a white speckled headband is using a torch to cook food in a restaurant 
CaptionToObject answer <p>An Asian man</p> {<5><15><63><100>}
<p>a green uniform shirt</p> {<4><35><49><83>}
<p>a white speckled headband</p> {<24><23><52><31>}
<p>a torch</p> {<43><53><74><69>}
<p>food</p> {<68><70><91><77>}
<p>a restaurant</p> {<1><1><100><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy holding a ball falls down in front of another boy who has his arms reaching out while an older man in a green shirt smiles and watches 
CaptionToObject answer <p>A boy</p> {<3><38><76><94>}
<p>a ball</p> {<73><1><81><59>}
<p>another boy</p> {<43><34><100><95>}
<p>his arms</p> {<54><43><74><58>}
<p>an older man</p> {<26><2><62><87>}
<p>a green shirt</p> {<26><12><62><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a cross and white beard is carrying food and a napkin 
CaptionToObject answer <p>A man</p> {<8><8><75><100>}
<p>a cross</p> {<37><64><48><77>}
<p>white beard</p> {<25><21><59><64>}<delim>{<28><32><58><65>}
<p>food</p> {<62><73><73><81>}
<p>a napkin</p> {<45><74><64><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a pink shirt showing a man with a striped sweater how to do some work with yarn 
CaptionToObject answer <p>A woman</p> {<3><3><54><93>}
<p>a pink shirt</p> {<3><27><57><81>}
<p>a man</p> {<26><3><97><100>}
<p>a striped sweater</p> {<39><36><96><100>}
<p>yarn</p> {<17><77><23><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two girls are eating cake and one has blue icing on her face 
CaptionToObject answer <p>Two girls</p> {<38><7><99><100>}<delim>{<17><21><59><100>}
<p>cake</p> {<54><46><61><53>}<delim>{<29><51><36><59>}
<p>one</p> {<38><7><99><100>}
<p>blue</p> {<59><39><63><44>}
<p>her face</p> {<50><13><74><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A female singer on stage with a tambourine with two men playing guitar and drums 
CaptionToObject answer <p>A female singer</p> {<18><21><77><100>}
<p>a tambourine</p> {<62><55><78><74>}
<p>two men</p> {<35><20><62><100>}<delim>{<0><46><19><91>}
<p>guitar</p> {<39><40><70><88>}
<p>drums</p> {<0><86><16><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The young girl with two red dots on her face is wearing purple beads while another girl is blurred in front of her 
CaptionToObject answer <p>The young girl</p> {<25><48><100><100>}
<p>two red dots</p> {<25><23><32><27>}<delim>{<24><20><48><27>}
<p>her face</p> {<36><47><83><84>}<delim>{<26><11><53><36>}
<p>purple beads</p> {<35><30><64><53>}
<p>another girl</p> {<1><2><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is sitting in a chair with his foot propped up on a cabinet , talking into a microphone 
CaptionToObject answer <p>A man</p> {<5><11><100><95>}
<p>a chair</p> {<45><23><100><92>}
<p>his foot</p> {<6><37><75><66>}
<p>a cabinet</p> {<1><57><47><95>}
<p>a microphone</p> {<69><22><78><36>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a purple , blue , and green dress is carrying two bags 
CaptionToObject answer <p>A woman</p> {<12><9><63><100>}
<p>a purple</p> {<13><9><61><100>}
<p>blue</p> {<13><9><61><100>}
<p>green dress</p> {<13><33><49><100>}
<p>two bags</p> {<39><57><68><100>}<delim>{<1><29><43><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a suit and dirty dress-shoes is lying on the street on pieces of cardboard with his eyes closed 
CaptionToObject answer <p>A man</p> {<27><28><77><86>}
<p>a suit</p> {<33><32><75><78>}
<p>dirty dress-shoes</p> {<46><67><63><79>}<delim>{<56><71><75><84>}
<p>the street</p> {<0><46><89><100>}
<p>pieces of cardboard</p> {<0><48><45><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady in green shorts on a beach clapping her hands above her head while observing a band 
CaptionToObject answer <p>A lady</p> {<68><14><89><100>}
<p>green shorts</p> {<67><70><84><83>}
<p>her hands</p> {<74><12><80><27>}<delim>{<79><14><84><28>}
<p>her head</p> {<78><30><90><46>}
<p>a band</p> {<19><5><49><29>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men in baseball uniforms are playing baseball , one is on the ground with a helmet , and the other is crouching 
CaptionToObject answer <p>Two men</p> {<63><51><100><82>}<delim>{<5><23><48><82>}
<p>baseball uniforms</p> {<5><23><48><82>}<delim>{<77><50><100><79>}
<p>one</p> {<63><51><100><82>}
<p>a helmet</p> {<77><52><88><66>}
<p>the other</p> {<5><23><48><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with long dark hair is carrying a bag over her shoulder which says " hot " in metallic pink letters 
CaptionToObject answer <p>A woman</p> {<8><3><69><96>}
<p>long dark hair</p> {<26><3><59><31>}
<p>a bag</p> {<19><29><69><66>}
<p>her shoulder</p> {<25><20><53><31>}
<p>hot</p> {<26><45><64><63>}
<p>metallic pink letters</p> {<26><45><64><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a London 2012 jersey is running in front of a brick building and past a crowd carrying a torch 
CaptionToObject answer <p>A man</p> {<46><59><82><92>}
<p>a London 2012 jersey</p> {<58><65><82><86>}
<p>a brick building</p> {<1><1><100><64>}
<p>a crowd</p> {<0><41><100><100>}
<p>a torch</p> {<38><38><51><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a white shirt prepares to hit a ball thrown by a boy in a green shirt in an empty parking lot 
CaptionToObject answer <p>A boy</p> {<7><35><23><76>}
<p>a white shirt</p> {<8><40><19><57>}<delim>{<9><40><18><55>}
<p>a ball</p> {<45><25><49><33>}
<p>a boy</p> {<77><38><91><78>}
<p>a green shirt</p> {<77><42><89><60>}<delim>{<78><37><89><60>}
<p>an empty parking lot</p> {<0><59><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is playing a guitar , while someone else is sitting at a drum set , and there is a baby sitting on the floor next to a keyboard 
CaptionToObject answer <p>A man</p> {<15><25><37><100>}
<p>a guitar</p> {<20><37><41><71>}
<p>someone</p> {<45><43><59><88>}
<p>a drum set</p> {<29><53><57><97>}
<p>a baby</p> {<71><89><83><100>}
<p>the floor</p> {<1><70><81><100>}
<p>a keyboard</p> {<76><69><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A smiling young female soccer fan wears a red and white shirt with a soccer logo , a red vinyl cape , and a hat that looks like a soccer ball with a small Swiss flag attached 
CaptionToObject answer <p>A smiling young female soccer fan</p> {<19><17><99><100>}
<p>a red and white shirt</p> {<25><44><100><100>}
<p>a soccer logo</p> {<54><65><68><74>}
<p>a red vinyl cape</p> {<25><44><100><100>}
<p>a hat</p> {<33><17><82><44>}
<p>a soccer ball</p> {<42><17><74><33>}
<p>a small Swiss flag</p> {<34><17><84><43>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A blond woman in a dress looks at papers by a table covered in laptops being used by workers 
CaptionToObject answer <p>A blond woman</p> {<20><31><42><98>}
<p>a dress</p> {<20><40><40><85>}
<p>papers</p> {<29><47><45><71>}
<p>a table</p> {<59><84><81><100>}<delim>{<37><55><72><88>}
<p>laptops</p> {<50><69><65><84>}
<p>workers</p> {<69><56><100><100>}<delim>{<39><31><58><58>}<delim>{<57><39><73><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A pitcher standing on the mound wearing a blue shirt , white pants , striped socks , a blue hat and a glove 
CaptionToObject answer <p>A pitcher</p> {<14><4><83><93>}
<p>the mound</p> {<0><87><100><100>}
<p>a blue shirt</p> {<49><16><83><44>}
<p>white pants</p> {<48><43><83><86>}
<p>striped socks</p> {<67><70><82><86>}<delim>{<53><71><69><86>}
<p>a blue hat</p> {<44><5><72><12>}
<p>a glove</p> {<13><12><33><28>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt and glasses typing at a desk with two computers on it 
CaptionToObject answer <p>A man</p> {<36><16><85><80>}
<p>a blue shirt</p> {<56><29><85><70>}
<p>glasses</p> {<56><23><67><32>}
<p>a desk</p> {<5><47><84><100>}
<p>two computers</p> {<1><35><35><82>}<delim>{<0><15><33><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a red shirt with a flag on the sleeve looking through a telescope 
CaptionToObject answer <p>A boy</p> {<0><18><44><100>}
<p>a red shirt</p> {<0><45><24><100>}
<p>a flag</p> {<1><52><8><69>}
<p>the sleeve</p> {<1><49><9><75>}
<p>a telescope</p> {<35><37><83><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Rock band Def Leppard , pictured counterclockwise include Rick Savage , Vivian Campbell , Joe Elliot , and Phil Collen , looking up to drummer Rick Allen on an elevated stage platform during a concert performance 
CaptionToObject answer <p>Rock band Def Leppard</p> {<22><12><51><48>}
<p>Vivian Campbell</p> {<67><33><80><74>}
<p>Joe Elliot</p> {<66><32><80><76>}
<p>Phil Collen</p> {<41><51><64><96>}
<p>Rick Allen</p> {<25><16><36><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brown-haired man with a red shirt drinking at a bar with a woman in a white jacket 
CaptionToObject answer <p>A brown-haired man</p> {<38><37><71><100>}
<p>a red shirt</p> {<50><52><71><92>}
<p>a bar</p> {<0><66><35><100>}
<p>a woman</p> {<27><43><54><100>}
<p>a white jacket</p> {<41><53><54><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man pointing into the ear wearing a striped shirt in a small boat filled with many people 
CaptionToObject answer <p>A man</p> {<41><13><81><61>}
<p>the ear</p> {<29><38><31><43>}<delim>{<31><55><32><59>}
<p>a striped shirt</p> {<40><26><67><63>}
<p>a small boat</p> {<1><35><100><100>}
<p>many people</p> {<40><14><81><71>}<delim>{<59><47><84><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a camouflage jacket is driving a four wheeler while pulling a little girl wearing a purple coat and pink hat on a sled 
CaptionToObject answer <p>A man</p> {<17><3><41><78>}
<p>a camouflage jacket</p> {<19><11><41><45>}
<p>a four wheeler</p> {<3><33><54><90>}
<p>a little girl</p> {<84><36><94><61>}
<p>a purple coat</p> {<85><39><92><62>}
<p>pink hat</p> {<86><38><91><46>}
<p>a sled</p> {<82><55><96><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soccer player in blue and red just kicked the ball , and two opposing players wearing black and white uniforms watch to see where it will go 
CaptionToObject answer <p>A soccer player</p> {<45><29><79><100>}
<p>blue and red</p> {<14><18><50><93>}<delim>{<14><18><26><71>}
<p>the ball</p> {<55><1><62><14>}
<p>two opposing players</p> {<45><29><79><100>}<delim>{<75><25><93><93>}<delim>{<12><17><29><72>}
<p>black and white uniforms</p> {<49><35><66><75>}<delim>{<76><34><90><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young toddler plays with his plastic toys on the sidewalk , while a woman with a shopping bag leans against a green metal bar 
CaptionToObject answer <p>A young toddler</p> {<64><37><88><69>}
<p>his plastic toys</p> {<63><58><85><68>}
<p>the sidewalk</p> {<0><48><100><100>}
<p>a woman</p> {<31><1><68><63>}
<p>a shopping bag</p> {<33><12><48><32>}
<p>a green metal bar</p> {<46><25><100><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in sunglasses , a cap , dark jeans , and a denim jacket walks by an arch 
CaptionToObject answer <p>A man</p> {<37><61><62><97>}
<p>sunglasses</p> {<50><62><57><65>}
<p>a cap</p> {<48><61><58><65>}
<p>dark jeans</p> {<39><76><59><95>}
<p>a denim jacket</p> {<41><66><57><79>}
<p>an arch</p> {<25><1><100><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Policewoman , with person streaked with colors and with red cloth in mouth 
CaptionToObject answer <p>Policewoman</p> {<0><0><61><100>}
<p>person</p> {<62><2><100><100>}
<p>colors</p> {<67><53><100><100>}<delim>{<66><16><88><52>}
<p>red cloth</p> {<60><42><73><100>}
<p>mouth</p> {<65><39><70><47>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A white horse and a rider wearing a ale blue shirt , white pants , and a black helmet are jumping a hurdle 
CaptionToObject answer <p>A white horse</p> {<4><20><89><68>}
<p>a rider</p> {<24><23><53><49>}
<p>a ale blue shirt</p> {<34><27><47><34>}
<p>white pants</p> {<39><31><50><43>}
<p>a black helmet</p> {<28><23><36><30>}
<p>a hurdle</p> {<40><47><67><90>}<delim>{<68><42><94><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two african americans one female and the other male , the female appears to be topless with jewelry and the male has an orange shirt with tan colored pants they are in the middle of a hot plain area 
CaptionToObject answer <p>Two african americans</p> {<25><11><45><91>}<delim>{<15><13><29><89>}
<p>one female</p> {<14><16><31><90>}
<p>the other male</p> {<25><11><45><91>}
<p>the female</p> {<14><16><31><90>}
<p>jewelry</p> {<18><26><26><31>}<delim>{<18><27><25><32>}
<p>the male</p> {<25><11><45><91>}
<p>an orange shirt</p> {<25><23><43><55>}
<p>tan colored pants</p> {<29><54><41><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in an orange sleeveless shirt is walking outside next to a woman in a red top with a headscarf 
CaptionToObject answer <p>A boy</p> {<38><55><55><100>}
<p>an orange sleeveless shirt</p> {<42><67><52><94>}
<p>a woman</p> {<51><50><68><94>}
<p>a red top</p> {<23><53><38><93>}
<p>a headscarf</p> {<24><44><34><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women , one wearing a purple shirt and the other a green shirt , are climbing their way up an electrical pole with safety equipment with onlookers 
CaptionToObject answer <p>Two women</p> {<19><17><51><100>}<delim>{<58><10><77><91>}
<p>one</p> {<19><17><51><100>}
<p>a purple shirt</p> {<18><29><41><64>}
<p>the other a green shirt</p> {<59><23><77><48>}
<p>an electrical pole</p> {<48><1><61><100>}
<p>safety equipment</p> {<22><51><61><89>}<delim>{<48><38><77><64>}
<p>onlookers</p> {<72><65><83><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women jogging down a sidewalk in front of a person leaning on a bench in front of a lake with another person 
CaptionToObject answer <p>Two women</p> {<56><21><74><89>}<delim>{<66><25><82><88>}
<p>a sidewalk</p> {<1><78><100><95>}
<p>a person</p> {<15><21><23><53>}
<p>a bench</p> {<6><22><56><53>}
<p>a lake</p> {<1><33><100><53>}
<p>another person</p> {<15><21><23><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl wearing a red shirt and cap smiling and holding a small toy is standing in front of a group of children playing behind her 
CaptionToObject answer <p>A young girl</p> {<25><8><71><100>}
<p>a red shirt</p> {<26><36><72><100>}
<p>cap</p> {<38><6><58><22>}
<p>a small toy</p> {<35><70><55><85>}
<p>a group of children</p> {<69><35><87><86>}<delim>{<7><47><34><100>}<delim>{<2><50><23><100>}<delim>{<84><44><94><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a hooded sweatshirt and a black hat with the words 'probuilt ' stitched across is using a handsaw on wood for a construction project 
CaptionToObject answer <p>A man</p> {<27><3><79><100>}
<p>a hooded sweatshirt</p> {<59><7><75><32>}
<p>a black hat</p> {<64><2><78><22>}
<p>the words</p> {<67><14><76><21>}
<p>a handsaw</p> {<51><47><67><72>}
<p>wood</p> {<57><46><100><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three basketball players in white are defending against the attacking player with the ball in orange 
CaptionToObject answer <p>Three basketball players</p> {<0><34><37><100>}<delim>{<57><32><98><77>}<delim>{<8><3><55><78>}
<p>white</p> {<13><26><44><59>}<delim>{<1><43><25><82>}<delim>{<62><38><85><66>}
<p>the attacking player</p> {<40><8><86><84>}
<p>the ball</p> {<45><1><60><11>}
<p>orange</p> {<45><28><73><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian lady wearing a blue blouse and an umbrella in her right hand waiting for somebody to come and pick her up because she has a lot of baggage with her 
CaptionToObject answer <p>An Asian lady</p> {<34><36><54><65>}
<p>a blue blouse</p> {<42><43><54><64>}
<p>an umbrella</p> {<24><14><61><31>}
<p>her right hand</p> {<37><46><40><51>}
<p>a lot of baggage</p> {<29><60><60><98>}<delim>{<13><63><34><90>}<delim>{<24><51><39><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl wearing a blue short and yellow shirt uniform throws a yellow softball while a girl in a black and red short uniform and red helmet runs 
CaptionToObject answer <p>A girl</p> {<8><1><59><99>}<delim>{<1><16><24><71>}
<p>a blue short and yellow shirt uniform</p> {<4><16><19><50>}
<p>a yellow softball</p> {<95><1><98><6>}
<p>a girl</p> {<8><1><59><99>}
<p>a black and red short uniform</p> {<29><15><47><67>}
<p>red helmet</p> {<35><1><47><20>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bald , black man wearing safety glasses and a long-sleeved black shirt is using a pick and hammer to sculpt a sizable rock into art 
CaptionToObject answer <p>A bald , black man</p> {<33><3><100><82>}
<p>safety glasses</p> {<48><13><73><33>}
<p>a long-sleeved black shirt</p> {<54><10><100><76>}
<p>a pick</p> {<32><49><38><54>}
<p>hammer</p> {<2><48><100><100>}
<p>a sizable rock</p> {<2><48><100><100>}
<p>art</p> {<2><48><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a bathrobe holding a plate of food stands next to a boy holding utensils and a red cup 
CaptionToObject answer <p>A girl</p> {<1><18><47><100>}
<p>a bathrobe</p> {<1><41><47><100>}
<p>a plate of food</p> {<16><79><42><98>}
<p>a boy</p> {<37><0><87><100>}
<p>utensils</p> {<50><44><63><70>}
<p>a red cup</p> {<68><50><79><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red shoulder shrug and brown boots walking down a street passed a painted I Love New York wall sign with a doctor 
CaptionToObject answer <p>A woman</p> {<65><25><85><100>}
<p>a red shoulder shrug</p> {<67><34><80><79>}
<p>brown boots</p> {<65><84><73><100>}<delim>{<78><84><85><96>}
<p>a painted I Love New York wall sign</p> {<45><29><61><54>}
<p>a doctor</p> {<54><21><74><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young women wearing a red shirt , black leggings , Nike running shoes , and black framed glasses has her hand out to grab the hand of a young boy who is wearing orange pants and a gray shirt and is skipping towards her , at a London Metro station 
CaptionToObject answer <p>A young women</p> {<35><29><45><85>}
<p>a red shirt</p> {<35><36><43><55>}
<p>black leggings</p> {<35><53><45><83>}
<p>Nike running shoes</p> {<36><77><45><85>}
<p>black framed glasses</p> {<38><31><42><35>}
<p>her hand</p> {<39><50><44><57>}
<p>the hand of a young boy</p> {<56><60><59><68>}
<p>orange pants</p> {<50><66><57><88>}
<p>a gray shirt</p> {<49><52><59><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little boy wearing a vest , floaties and goggles , swims to the side of a pool 
CaptionToObject answer <p>A little boy</p> {<23><30><72><100>}
<p>a vest</p> {<24><59><61><100>}
<p>floaties</p> {<36><71><55><98>}
<p>goggles</p> {<37><36><60><61>}
<p>the side of a pool</p> {<81><19><100><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soldier letting a child hold a gun while the child wears his helmet and vest 
CaptionToObject answer <p>A soldier</p> {<11><1><59><85>}
<p>a child</p> {<37><34><95><100>}
<p>a gun</p> {<0><40><74><61>}
<p>the child</p> {<37><34><95><100>}
<p>his helmet</p> {<59><34><85><48>}
<p>vest</p> {<64><46><94><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Children running in a football field in full uniform with a gate and cars in the background 
CaptionToObject answer <p>Children</p> {<47><23><64><75>}
<p>a football field</p> {<0><41><100><100>}
<p>full uniform</p> {<47><23><64><75>}<delim>{<19><26><31><73>}
<p>a gate</p> {<0><13><100><42>}
<p>cars</p> {<2><16><38><39>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a white dress with a purple shrug and a purse on her shoulder is walking outside 
CaptionToObject answer <p>A woman</p> {<28><10><76><100>}
<p>a white dress</p> {<30><61><76><98>}
<p>a purple shrug</p> {<32><27><60><50>}
<p>a purse</p> {<29><30><70><61>}
<p>her shoulder</p> {<51><29><59><35>}<delim>{<33><27><59><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person is a shiny hat , a shiny coat , and jeans has his head facing down 
CaptionToObject answer <p>A person</p> {<6><4><60><85>}
<p>a shiny hat</p> {<28><5><49><19>}
<p>a shiny coat</p> {<1><4><59><85>}
<p>jeans</p> {<12><38><58><76>}
<p>his head</p> {<29><5><49><24>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a clown nose on rollerskates holding a small crying child in a wizard outfit 
CaptionToObject answer <p>A man</p> {<38><7><66><81>}
<p>a clown nose</p> {<46><20><49><26>}<delim>{<46><21><49><26>}
<p>rollerskates</p> {<50><73><60><86>}<delim>{<40><65><50><81>}
<p>a small crying child</p> {<27><15><49><75>}
<p>a wizard outfit</p> {<27><15><49><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Older woman with a microphone in her right hand and a piece of paper in her left standing in front of a younger female cellist 
CaptionToObject answer <p>Older woman</p> {<34><10><84><100>}
<p>a microphone</p> {<43><37><58><67>}
<p>her right hand</p> {<46><40><57><63>}<delim>{<46><40><56><60>}
<p>a piece of paper</p> {<49><80><72><92>}
<p>a younger female cellist</p> {<3><27><34><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is paddling a boat while four women are standing on a rock in a body of water 
CaptionToObject answer <p>A man</p> {<75><38><91><62>}
<p>a boat</p> {<52><49><100><82>}
<p>four women</p> {<30><24><34><39>}<delim>{<35><25><38><41>}<delim>{<41><23><45><36>}
<p>a rock</p> {<26><25><54><51>}
<p>a body of water</p> {<0><27><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy is riding his skateboard down a handrail while a woman and two children watch 
CaptionToObject answer <p>A boy</p> {<38><33><72><62>}
<p>his skateboard</p> {<54><50><73><62>}
<p>a handrail</p> {<45><47><80><85>}
<p>a woman</p> {<6><43><17><66>}
<p>two children</p> {<13><49><20><66>}<delim>{<18><55><28><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A female in blue jeans , a florescent yellow shirt and a hard hat is climbing a tree using a piece of orange , yellow and red equipment 
CaptionToObject answer <p>A female</p> {<32><29><71><80>}
<p>blue jeans</p> {<36><62><71><81>}
<p>a florescent yellow shirt</p> {<35><40><57><65>}
<p>a hard hat</p> {<36><30><50><37>}
<p>a tree</p> {<0><1><100><100>}
<p>a piece of orange , yellow and red equipment</p> {<0><75><78><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A band with three members , guitarist , bassist and drummer , is playing a concert outside 
CaptionToObject answer <p>A band</p> {<40><60><69><91>}<delim>{<19><35><52><100>}<delim>{<76><55><96><97>}
<p>three members</p> {<23><37><45><100>}<delim>{<77><55><92><94>}<delim>{<52><60><62><91>}
<p>guitarist</p> {<23><37><45><100>}
<p>bassist</p> {<77><55><92><94>}
<p>drummer</p> {<52><60><62><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three men , 2 playing guitars and one playing the drums , performs in front of a Lite Beer curtain 
CaptionToObject answer <p>Three men</p> {<76><39><100><100>}<delim>{<31><29><61><100>}<delim>{<7><71><25><100>}
<p>2</p> {<76><39><100><100>}<delim>{<31><29><61><100>}
<p>guitars</p> {<33><27><77><100>}<delim>{<77><82><100><100>}
<p>one</p> {<7><71><25><100>}
<p>a Lite Beer curtain</p> {<1><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women in identical dresses and shoes with different colored hats sit on a bench with a hedge in the background 
CaptionToObject answer <p>Two women</p> {<32><5><72><96>}<delim>{<1><3><51><95>}
<p>identical dresses</p> {<11><22><50><74>}<delim>{<37><20><72><77>}
<p>shoes</p> {<1><66><11><76>}<delim>{<11><80><21><92>}
<p>different colored hats</p> {<32><4><52><24>}<delim>{<53><4><71><21>}
<p>a bench</p> {<2><33><79><95>}
<p>a hedge</p> {<1><0><100><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in hat and apron flipping over his pancake by tossing it in the air back to the pan 
CaptionToObject answer <p>A man</p> {<1><2><36><100>}
<p>hat</p> {<5><3><21><17>}
<p>apron</p> {<4><24><24><86>}
<p>his pancake</p> {<32><31><54><57>}
<p>the pan</p> {<30><58><65><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black sweatshirt and white sunglasses sits on a bench and talks on a cellphone 
CaptionToObject answer <p>A man</p> {<4><2><61><100>}
<p>a black sweatshirt</p> {<3><38><58><99>}
<p>white sunglasses</p> {<40><25><58><44>}
<p>a bench</p> {<0><79><45><100>}
<p>a cellphone</p> {<49><49><56><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men are playing guitars and one man is singing into a microphone on a stage with the spotlight on them 
CaptionToObject answer <p>Two men</p> {<60><4><80><99>}<delim>{<31><46><41><84>}
<p>guitars</p> {<31><63><41><75>}<delim>{<61><43><64><85>}
<p>one man</p> {<46><28><62><100>}<delim>{<60><4><80><99>}
<p>a microphone</p> {<48><36><55><40>}
<p>the spotlight</p> {<12><7><17><14>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There are two women smiling , one with a red jacket and blond-hair and another wearing a black pantsuit 
CaptionToObject answer <p>two women</p> {<41><20><61><100>}<delim>{<57><28><74><100>}
<p>one</p> {<57><28><74><100>}
<p>a red jacket</p> {<58><43><75><73>}
<p>blond-hair</p> {<43><19><54><33>}<delim>{<60><28><70><45>}
<p>a black pantsuit</p> {<40><32><61><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian woman in a bikini top and black skirt holds a popsicle and a set of keys 
CaptionToObject answer <p>An Asian woman</p> {<35><3><85><100>}
<p>a bikini top</p> {<50><25><81><52>}
<p>black skirt</p> {<42><57><77><85>}
<p>a popsicle</p> {<32><23><46><50>}
<p>a set of keys</p> {<32><30><46><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older woman wearing a straw hat , a pink shirt , and rain boots is standing in water 
CaptionToObject answer <p>An older woman</p> {<9><0><76><65>}
<p>a straw hat</p> {<21><2><65><16>}
<p>a pink shirt</p> {<11><20><76><49>}
<p>boots</p> {<24><48><52><63>}
<p>water</p> {<1><44><98><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a brown shirt , green hat , and black headphones handles audio equipment in a white room with two black boxes in the foreground 
CaptionToObject answer <p>A man</p> {<32><30><68><88>}
<p>a brown shirt</p> {<32><38><68><85>}
<p>green hat</p> {<46><30><57><53>}<delim>{<45><28><60><55>}
<p>black headphones</p> {<44><29><60><50>}
<p>audio equipment</p> {<39><63><61><98>}
<p>two black boxes</p> {<53><75><95><97>}<delim>{<1><64><34><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian man wearing silver armor over tan clothes underneath , holding a weapon aloft in his right hand mounted on a horse which is also adorned with silver armor 
CaptionToObject answer <p>An Asian man</p> {<7><18><53><73>}
<p>silver armor</p> {<4><3><61><72>}<delim>{<27><19><49><49>}
<p>tan clothes</p> {<9><23><51><51>}
<p>a weapon</p> {<2><2><17><37>}
<p>his right hand</p> {<7><20><18><34>}
<p>a horse</p> {<1><33><89><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man kneeling on the ground outside is wearing a respirator and spray painting red anarchy signs on top of a blue background featuring a drawing of a person 
CaptionToObject answer <p>A man</p> {<49><5><100><50>}
<p>the ground outside</p> {<1><16><100><100>}
<p>a respirator</p> {<51><7><68><23>}
<p>spray painting red anarchy signs</p> {<58><42><83><54>}<delim>{<35><63><62><78>}
<p>a drawing of a person</p> {<49><5><100><50>}<delim>{<6><38><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a T-shirt and shorts walks with a racket on a tennis field 
CaptionToObject answer <p>A woman</p> {<0><0><68><100>}
<p>a T-shirt</p> {<13><14><59><53>}
<p>shorts</p> {<15><50><57><72>}
<p>a racket</p> {<1><59><22><93>}
<p>a tennis field</p> {<2><19><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a grass skirt , is standing in the grass among a group of pigs on their backs near the coast 
CaptionToObject answer <p>A man</p> {<12><42><29><69>}
<p>a grass skirt</p> {<11><53><25><63>}
<p>the grass</p> {<1><58><100><80>}
<p>a group of pigs</p> {<3><59><100><88>}
<p>their backs</p> {<87><83><100><87>}<delim>{<52><68><80><72>}<delim>{<65><66><100><80>}<delim>{<19><80><58><86>}<delim>{<38><60><55><66>}
<p>the coast</p> {<0><37><100><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in black wedged sandals is wearing white pants and a sleeveless black shirt while standing in front of a building 
CaptionToObject answer <p>A woman</p> {<12><48><28><99>}
<p>black wedged sandals</p> {<22><96><27><99>}<delim>{<15><94><22><100>}
<p>white pants</p> {<15><74><27><97>}
<p>a sleeveless black shirt</p> {<16><56><28><76>}
<p>a building</p> {<1><1><100><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in black swim trunks is in the middle of diving off of a diving board into a swimming pool 
CaptionToObject answer <p>A man</p> {<33><31><73><70>}
<p>black swim trunks</p> {<51><31><65><42>}
<p>the middle</p> {<49><49><68><74>}
<p>a diving board</p> {<70><54><100><68>}
<p>a swimming pool</p> {<0><55><100><99>}

Train: data epoch: [0]  [ 150/1000]  eta: 0:04:39  lr: 0.000002  loss: 1.3328  time: 0.3214  data: 0.0000  max mem: 29214
CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one dressed in black with a white hat and the other dressed in gray sweep a set of steps 
CaptionToObject answer <p>Two men</p> {<17><20><34><92>}<delim>{<40><23><51><64>}
<p>one</p> {<40><23><51><64>}
<p>black</p> {<41><28><51><61>}
<p>a white hat</p> {<45><23><50><30>}
<p>the other</p> {<17><20><34><92>}
<p>gray</p> {<18><26><33><83>}
<p>a set of steps</p> {<9><65><72><99>}<delim>{<77><85><97><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black hat , sunglasses and sweatshirt is playing the harmonica 
CaptionToObject answer <p>A man</p> {<17><22><65><100>}
<p>a black hat</p> {<20><23><38><45>}
<p>sunglasses</p> {<24><31><38><45>}
<p>sweatshirt</p> {<18><47><64><100>}
<p>the harmonica</p> {<34><40><42><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl in white has pinned down another girl wearing blue that is lying face down on the ground 
CaptionToObject answer <p>A young girl</p> {<54><5><75><61>}<delim>{<22><42><81><61>}
<p>white</p> {<54><5><75><61>}
<p>another girl</p> {<22><42><81><61>}
<p>blue</p> {<26><42><70><60>}
<p>face</p> {<68><44><77><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Four people are standing next to a brick wall and the man is holding a sign that reads " Prayer booth " 
CaptionToObject answer <p>Four people</p> {<74><27><88><72>}<delim>{<86><30><97><70>}<delim>{<66><29><78><72>}
<p>a brick wall</p> {<64><2><100><66>}
<p>the man</p> {<74><27><88><72>}
<p>a sign</p> {<76><51><92><68>}
<p>Prayer booth</p> {<73><49><93><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Several people stand outside of a theater , while there is an advertisement sign with a man and woman in the foreground 
CaptionToObject answer <p>Several people</p> {<75><46><83><71>}<delim>{<90><46><98><75>}
<p>a theater</p> {<0><0><100><100>}
<p>an advertisement sign</p> {<21><29><41><69>}
<p>a man</p> {<22><31><36><57>}
<p>woman</p> {<84><50><90><76>}<delim>{<24><40><40><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one wearing a white shirt , one wearing a red shirt are fighting for a yellow soccer ball 
CaptionToObject answer <p>Two men</p> {<42><18><85><86>}<delim>{<13><17><57><85>}
<p>one</p> {<13><17><57><85>}<delim>{<42><18><85><86>}
<p>a white shirt</p> {<18><27><55><54>}
<p>a red shirt</p> {<52><29><83><56>}
<p>a yellow soccer ball</p> {<56><79><72><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man in a blue button down shirt walking with two ice cream cones in his hands 
CaptionToObject answer <p>Man</p> {<38><17><63><72>}
<p>a blue button</p> {<50><32><53><34>}
<p>shirt</p> {<37><24><63><47>}
<p>two ice cream cones</p> {<51><28><55><36>}<delim>{<39><28><44><37>}
<p>his hands</p> {<37><33><43><38>}<delim>{<52><32><59><36>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a beard in a Dr. Pepper t-shirt is laying on a blue blanket with a baby 
CaptionToObject answer <p>A man</p> {<0><33><50><100>}
<p>a beard</p> {<8><49><35><71>}
<p>a Dr. Pepper t-shirt</p> {<0><66><53><100>}
<p>a blue blanket</p> {<0><6><100><100>}
<p>a baby</p> {<43><46><84><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men playing ball in a gym , with the player in the green shirt getting ready to pass the ball while the red shirted players is trying to overtake him 
CaptionToObject answer <p>Two men</p> {<1><16><100><94>}<delim>{<27><49><82><100>}
<p>the player</p> {<1><16><100><94>}
<p>the green shirt</p> {<46><30><91><64>}
<p>the ball</p> {<37><15><55><26>}
<p>the red shirted players</p> {<55><54><83><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black man dressed in orange and blue jumping through the air , throwing a red , white and blue ball through a hoop , with a white man in sunglasses dressed similarly looking on 
CaptionToObject answer <p>A black man</p> {<49><2><100><98>}
<p>orange</p> {<61><14><82><45>}
<p>a red , white and blue ball</p> {<1><27><12><38>}
<p>a hoop</p> {<14><20><49><45>}
<p>a white man</p> {<80><8><100><76>}
<p>sunglasses</p> {<86><12><94><16>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman is walking down the street with headphones in her ears next to a man in a business suit 
CaptionToObject answer <p>A woman</p> {<37><15><66><100>}
<p>the street</p> {<0><36><100><93>}
<p>headphones</p> {<41><26><52><73>}
<p>her ears</p> {<49><25><52><30>}
<p>a man</p> {<52><1><100><100>}
<p>a business suit</p> {<30><28><53><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An old man wearing glasses and gray suit riding a bicycle next to a bus with a picture of the movie Iron man 
CaptionToObject answer <p>An old man</p> {<31><32><67><99>}
<p>glasses</p> {<43><39><51><44>}
<p>gray suit</p> {<35><43><67><97>}
<p>a bicycle</p> {<15><73><74><100>}
<p>a bus</p> {<1><1><100><96>}
<p>a picture of the movie Iron man</p> {<1><1><100><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The man on the ground in the blue , white , and red jacket is going something to the bike while the other man standing up in the red , white , and blue outfit holds it up 
CaptionToObject answer <p>The man</p> {<50><40><95><89>}
<p>the blue , white , and red jacket</p> {<50><45><94><73>}
<p>the bike</p> {<16><42><69><100>}
<p>the other man</p> {<16><7><56><90>}
<p>the red , white , and blue outfit</p> {<15><7><55><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two young children , a girl and a boy , eat Cheerios with spoons 
CaptionToObject answer <p>Two young children</p> {<56><3><100><77>}<delim>{<1><12><48><82>}
<p>a girl</p> {<1><12><48><82>}
<p>a boy</p> {<56><3><100><77>}
<p>Cheerios</p> {<87><77><100><87>}<delim>{<19><73><37><89>}
<p>spoons</p> {<7><39><24><51>}<delim>{<80><36><87><39>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black jacket in jeans takes a photograph of a man posing on the street in a silver suit 
CaptionToObject answer <p>A man</p> {<10><35><34><81>}
<p>a black jacket</p> {<10><40><33><58>}
<p>jeans</p> {<14><53><33><76>}
<p>a man</p> {<46><21><84><86>}
<p>the street</p> {<1><69><100><100>}
<p>a silver suit</p> {<46><22><82><86>}<delim>{<50><23><84><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An Asian man is riding his bike down the street , where flowers and other vehicles are 
CaptionToObject answer <p>An Asian man</p> {<51><2><82><86>}
<p>his bike</p> {<0><40><96><100>}
<p>the street</p> {<0><59><100><100>}
<p>flowers</p> {<1><16><56><68>}<delim>{<38><17><56><39>}
<p>other vehicles</p> {<50><16><100><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two boys with mouthguards and one is holding a football while the other reaches for him 
CaptionToObject answer <p>Two boys</p> {<45><21><100><100>}<delim>{<1><3><54><100>}
<p>mouthguards</p> {<60><45><65><53>}<delim>{<31><34><35><39>}
<p>one</p> {<1><3><54><100>}
<p>a football</p> {<6><49><22><72>}
<p>the other</p> {<45><21><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young boy in swimming trunks holds a blue pail and a bright green shovel on a sandy beach 
CaptionToObject answer <p>A young boy</p> {<44><10><61><97>}
<p>swimming trunks</p> {<48><50><60><80>}<delim>{<58><34><73><61>}
<p>a blue pail</p> {<39><60><53><90>}
<p>a bright green shovel</p> {<59><36><72><58>}
<p>a sandy beach</p> {<1><78><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Old man with black shirt throws hands up while sitting next to white woman and white man 
CaptionToObject answer <p>Old man</p> {<20><1><100><100>}
<p>black shirt</p> {<44><54><78><100>}
<p>hands</p> {<76><49><99><73>}<delim>{<19><1><29><19>}
<p>white woman</p> {<1><43><33><100>}
<p>white man</p> {<73><31><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A child wearing pink penguin pajamas is standing on a step stool in front of a kitchen counter , using a cut to cut rounds out of a sheet of dough 
CaptionToObject answer <p>A child</p> {<27><7><67><78>}
<p>pink penguin pajamas</p> {<35><24><64><78>}
<p>a step stool</p> {<35><67><73><100>}
<p>a cut</p> {<28><25><39><34>}
<p>rounds</p> {<10><31><19><35>}
<p>a sheet of dough</p> {<23><30><38><35>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and two girls show off a fish while holding fishing poles in front of a body of water 
CaptionToObject answer <p>A man</p> {<32><14><74><100>}
<p>two girls</p> {<4><39><34><100>}<delim>{<67><35><89><100>}
<p>a fish</p> {<53><55><69><64>}
<p>fishing poles</p> {<52><56><69><64>}<delim>{<0><69><35><82>}<delim>{<65><69><79><87>}
<p>a body of water</p> {<1><4><100><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A tattooed man in overalls , no shirt and a baseball cap is holding a microphone in front of a crowd and giving the " peace " sign with his other hand 
CaptionToObject answer <p>A tattooed man</p> {<36><15><63><100>}
<p>overalls</p> {<37><51><57><100>}
<p>no shirt</p> {<34><46><54><70>}
<p>a baseball cap</p> {<37><34><48><50>}
<p>a microphone</p> {<46><44><52><58>}
<p>a crowd</p> {<0><65><34><100>}
<p>the " peace " sign</p> {<57><15><63><27>}
<p>his other hand</p> {<57><15><64><27>}<delim>{<57><15><63><31>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The football player in white is defending against the player in red who is running with the ball 
CaptionToObject answer <p>The football player</p> {<4><27><52><100>}<delim>{<27><20><64><100>}
<p>white</p> {<4><27><52><100>}
<p>the player</p> {<27><20><64><100>}
<p>red</p> {<26><19><64><100>}
<p>the ball</p> {<50><46><59><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a young child wearing a red hat and scarf playing in the street in a little snow 
CaptionToObject answer <p>a young child</p> {<15><20><43><74>}
<p>a red hat</p> {<27><20><36><31>}
<p>scarf</p> {<25><29><40><47>}
<p>the street</p> {<1><36><61><99>}
<p>a little snow</p> {<36><39><100><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An athletic woman jogs on a beach holding a water bottle , wearing a bikini and white running shoes 
CaptionToObject answer <p>An athletic woman</p> {<25><38><43><75>}
<p>a beach</p> {<0><0><100><100>}
<p>a water bottle</p> {<37><46><41><51>}
<p>a bikini</p> {<31><44><38><52>}
<p>white running shoes</p> {<36><68><43><74>}<delim>{<25><61><30><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two nuns dressed in white habits and holding blue papers stand in the background while a mime wearing white clothing and a white mask performs in the foreground 
CaptionToObject answer <p>Two nuns</p> {<68><55><82><100>}<delim>{<83><53><97><100>}
<p>white habits</p> {<86><52><97><68>}<delim>{<68><54><82><100>}<delim>{<84><61><98><100>}
<p>blue papers</p> {<70><73><76><78>}
<p>a mime</p> {<5><8><55><100>}
<p>white clothing</p> {<5><8><55><100>}
<p>a white mask</p> {<5><8><55><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt and black pants relaxes with his glasses resting on his forehead 
CaptionToObject answer <p>A man</p> {<23><23><100><66>}
<p>a blue shirt</p> {<47><33><98><63>}
<p>black pants</p> {<96><35><100><61>}
<p>his glasses</p> {<27><36><34><54>}
<p>his forehead</p> {<27><38><36><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bearded man , wearing a hat and vest , is standing next to an open fire from a stove 
CaptionToObject answer <p>A bearded man</p> {<35><19><96><85>}
<p>a hat</p> {<35><20><48><34>}
<p>vest</p> {<47><19><95><49>}
<p>an open fire</p> {<35><40><52><53>}
<p>a stove</p> {<33><37><58><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women , one walking her dog the other pushing a stroller 
CaptionToObject answer <p>Two women</p> {<60><7><80><80>}<delim>{<89><6><100><39>}
<p>one</p> {<60><7><80><80>}
<p>her dog</p> {<27><57><37><83>}
<p>the other</p> {<89><6><100><39>}
<p>a stroller</p> {<81><37><100><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] This is a beach scene consisting of a child by the shoreline holding a shovel full of sand and looking out at a group of people in the water 
CaptionToObject answer <p>a child</p> {<3><29><24><97>}
<p>the shoreline</p> {<0><84><37><100>}
<p>a shovel</p> {<16><64><24><71>}
<p>sand</p> {<20><66><24><69>}
<p>a group of people</p> {<33><29><42><46>}<delim>{<51><33><60><46>}<delim>{<69><35><89><44>}<delim>{<49><32><55><43>}<delim>{<42><37><48><46>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with tattoos and ripped stockings is unlocking her bicycle from a pole 
CaptionToObject answer <p>A woman</p> {<52><22><81><100>}
<p>tattoos</p> {<65><35><72><50>}
<p>stockings</p> {<69><74><78><100>}
<p>her bicycle</p> {<40><54><65><100>}
<p>a pole</p> {<50><1><60><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in short-sleeved shirt and jeans is trying to fix a headlight with duct tape 
CaptionToObject answer <p>A man</p> {<23><3><98><100>}
<p>short-sleeved shirt</p> {<54><23><98><99>}
<p>jeans</p> {<33><62><82><100>}
<p>a headlight</p> {<9><39><33><74>}
<p>duct tape</p> {<1><35><13><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a white shirt , black jacket and blue and black striped shirt stands next to a man in a checked shirt and blue jeans looking through a camera focused on whoever took this picture 
CaptionToObject answer <p>A woman</p> {<16><34><33><97>}
<p>a white shirt</p> {<18><45><30><82>}
<p>black jacket and blue and black striped shirt</p> {<16><49><33><91>}
<p>a man</p> {<35><20><59><98>}
<p>a checked shirt</p> {<37><29><59><69>}
<p>blue jeans</p> {<35><62><56><97>}
<p>a camera</p> {<44><27><50><36>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A white man in a white and black t-shirt , white khaki pants , and black shades is waving his arms and standing in front of a white fence of what looks like an Asian property with pointy roofs , a red flag on a tall pole , and pink flowers 
CaptionToObject answer <p>A white man</p> {<13><55><49><100>}
<p>a white and black t-shirt</p> {<26><65><47><89>}
<p>white khaki pants</p> {<34><85><49><100>}
<p>black shades</p> {<35><61><45><64>}
<p>his arms</p> {<12><55><47><78>}
<p>an Asian property</p> {<0><22><99><67>}
<p>pointy roofs</p> {<12><22><89><32>}
<p>a red flag</p> {<44><10><51><64>}
<p>a tall pole</p> {<46><9><48><62>}
<p>pink flowers</p> {<28><61><30><64>}<delim>{<23><63><25><65>}<delim>{<53><60><58><67>}<delim>{<4><62><9><67>}<delim>{<6><61><14><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An elderly male , wearing a beige coat lined with fur , carrying a piece of metal furniture , two garbage bags and a walking cane 
CaptionToObject answer <p>An elderly male</p> {<44><17><69><95>}
<p>a beige coat</p> {<44><26><69><73>}
<p>a piece of metal furniture</p> {<38><56><51><88>}
<p>two garbage bags</p> {<62><58><75><80>}
<p>a walking cane</p> {<62><53><70><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] One little boy is standing inside a house on one side of a window while another boy is outside squirting the window with a hose 
CaptionToObject answer <p>One little boy</p> {<41><28><89><100>}
<p>one side of a window</p> {<1><0><95><91>}
<p>another boy</p> {<41><28><89><100>}
<p>the window</p> {<1><0><95><91>}
<p>a hose</p> {<38><67><46><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a red button up shirt play a guitar and standing next to a microphone 
CaptionToObject answer <p>A man</p> {<36><16><67><100>}
<p>a red button</p> {<36><34><67><94>}
<p>shirt</p> {<36><34><67><94>}
<p>a guitar</p> {<37><48><76><99>}
<p>a microphone</p> {<0><17><38><34>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man entering into a building as another man sits on a street on a cold day 
CaptionToObject answer <p>A man</p> {<44><39><63><72>}
<p>a building</p> {<52><1><100><98>}
<p>another man</p> {<33><69><83><96>}
<p>a street</p> {<0><56><83><100>}
<p>a cold day</p> {<33><69><83><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women sitting on a bench , their faces obscured , with one woman carrying an inflatable tiger and the other woman in a Disney snow white costume 
CaptionToObject answer <p>Two women</p> {<64><2><100><99>}<delim>{<29><4><68><98>}
<p>a bench</p> {<3><31><86><97>}
<p>their faces</p> {<36><7><49><29>}<delim>{<83><4><93><26>}
<p>one woman</p> {<64><2><100><99>}
<p>an inflatable tiger</p> {<42><39><69><73>}
<p>the other woman</p> {<64><2><100><99>}
<p>a Disney snow white costume</p> {<62><18><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a brown hat and beige shirt is sitting on a rock by the ocean 
CaptionToObject answer <p>A man</p> {<16><40><31><72>}
<p>a brown hat</p> {<22><40><28><46>}
<p>beige shirt</p> {<15><44><26><62>}
<p>a rock</p> {<1><65><53><100>}<delim>{<5><57><25><68>}
<p>the ocean</p> {<66><51><100><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with glasses , a coat and scarf stands in front of a blue wall with an open book 
CaptionToObject answer <p>A man</p> {<13><33><75><100>}
<p>glasses</p> {<40><38><53><44>}
<p>a coat</p> {<14><49><58><100>}
<p>scarf</p> {<28><45><58><90>}
<p>a blue wall</p> {<1><6><100><100>}
<p>an open book</p> {<28><64><77><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Indoors , a woman wearing a surgical mask , gown and gloves works on a reclining person 
CaptionToObject answer <p>a woman</p> {<0><0><69><100>}
<p>a surgical mask</p> {<35><9><58><38>}
<p>gown</p> {<1><7><40><100>}
<p>gloves works</p> {<34><47><60><71>}<delim>{<52><31><64><48>}
<p>a reclining person</p> {<33><39><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a hard hat and road safety vest using a jackhammer on some large boulders 
CaptionToObject answer <p>A man</p> {<37><27><59><72>}
<p>a hard hat</p> {<47><26><54><34>}
<p>road safety vest</p> {<39><31><52><54>}
<p>a jackhammer</p> {<55><41><59><58>}
<p>some large boulders</p> {<37><27><59><72>}<delim>{<10><51><83><100>}<delim>{<81><1><100><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] One boy who has a funny expression on his face has his hands up by his head and is looking through a hole 
CaptionToObject answer <p>One boy</p> {<29><7><61><71>}
<p>his face</p> {<43><36><61><68>}
<p>his hands</p> {<30><14><45><48>}<delim>{<50><10><60><43>}
<p>his head</p> {<39><13><59><48>}
<p>a hole</p> {<27><2><64><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Male wearing a helmet and backpack holding his bike up in front of a store 
CaptionToObject answer <p>Male</p> {<21><45><32><78>}
<p>a helmet</p> {<23><44><29><51>}<delim>{<23><44><29><48>}
<p>backpack</p> {<29><50><33><60>}
<p>his bike</p> {<12><58><39><82>}
<p>a store</p> {<0><0><100><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a jacket and red shirt sits at a park bench as a dog with a plaid jacket stands near 
CaptionToObject answer <p>A man</p> {<64><39><81><83>}
<p>a jacket</p> {<65><45><82><69>}
<p>red shirt</p> {<69><48><74><63>}
<p>a park bench</p> {<45><50><95><84>}
<p>a dog</p> {<10><60><23><77>}
<p>a plaid jacket</p> {<11><62><19><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a red jacket driving a horse drawn carriage with a couple riding in the cabin 
CaptionToObject answer <p>A man</p> {<54><34><66><59>}
<p>a red jacket</p> {<58><37><66><49>}
<p>a horse drawn carriage</p> {<8><42><88><94>}
<p>a couple</p> {<70><49><79><62>}
<p>the cabin</p> {<69><50><83><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a red blouse holding stitch in her one hand and a bottle 
CaptionToObject answer <p>A woman</p> {<13><6><100><100>}
<p>a red blouse</p> {<43><37><100><100>}
<p>stitch</p> {<0><48><49><100>}
<p>her one hand</p> {<13><69><27><95>}
<p>a bottle</p> {<33><61><46><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young person wearing a helmet is riding a BMX bike with the numbers 060 through the mud , and there is a Dobos Sport logo banner in the background 
CaptionToObject answer <p>A young person</p> {<29><2><68><83>}
<p>a helmet</p> {<30><3><42><23>}
<p>a BMX bike</p> {<38><25><81><94>}
<p>the numbers</p> {<50><39><56><48>}
<p>the mud</p> {<11><36><100><100>}
<p>a Dobos Sport logo banner</p> {<19><52><49><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl wearing a hat , playing surrounded by a wheelbarrow with wood in the background and a building 
CaptionToObject answer <p>A little girl</p> {<25><24><67><100>}
<p>a hat</p> {<41><24><57><39>}
<p>a wheelbarrow</p> {<59><9><98><100>}
<p>wood</p> {<1><1><38><100>}
<p>a building</p> {<40><0><100><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a long , sparkling white dress dances with a young man wearing a black shirt and black pants on the dance floor alone 
CaptionToObject answer <p>A woman</p> {<3><14><69><97>}
<p>a long , sparkling white dress</p> {<27><34><65><92>}
<p>a young man</p> {<52><27><89><90>}
<p>a black shirt</p> {<49><37><85><65>}
<p>black pants</p> {<53><55><85><84>}
<p>the dance floor</p> {<1><85><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person wearing a hat stands in a bright greenish-yellow field , holding reins which are attached to an ox 's bridle 
CaptionToObject answer <p>A person</p> {<28><40><35><62>}
<p>a hat</p> {<29><40><34><45>}
<p>a bright greenish-yellow field</p> {<1><31><100><100>}
<p>reins</p> {<31><50><42><61>}
<p>an ox 's bridle</p> {<37><48><41><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little boy in the air above another boy on the ground where a soccer ball lies at his feet with the soccer net behind them 
CaptionToObject answer <p>A little boy</p> {<42><1><84><66>}
<p>another boy</p> {<16><50><66><83>}
<p>a soccer ball</p> {<60><66><69><79>}
<p>his feet</p> {<59><62><66><74>}<delim>{<58><74><64><81>}
<p>the soccer net</p> {<1><5><100><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a white hat and a large knife prepares food from a slaughtered animal 
CaptionToObject answer <p>A man</p> {<1><4><63><100>}
<p>a white hat</p> {<14><4><36><12>}
<p>a large knife</p> {<30><37><74><48>}
<p>food</p> {<74><42><85><50>}<delim>{<85><44><99><52>}
<p>a slaughtered animal</p> {<38><39><100><72>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A blond baby in a yellow top and flowered pants holds a white hat and sits on a paisley blanket under a tree in a grassy park 
CaptionToObject answer <p>A blond baby</p> {<45><1><94><100>}
<p>a yellow top</p> {<47><35><83><91>}
<p>flowered pants</p> {<68><67><89><98>}
<p>a white hat</p> {<38><60><72><100>}
<p>a paisley blanket</p> {<0><55><100><100>}
<p>a tree</p> {<15><0><57><44>}
<p>a grassy park</p> {<1><4><100><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An adult male and a young boy are mixing together a yellow mixture in a large pyrex mixing bowl 
CaptionToObject answer <p>An adult male</p> {<0><0><55><34>}
<p>a young boy</p> {<45><7><99><100>}
<p>a yellow mixture</p> {<25><48><64><98>}
<p>a large pyrex</p> {<18><21><72><96>}
<p>bowl</p> {<18><21><72><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl with long brown hair and a hat made out of newspaper is opening a gift while other people watch 
CaptionToObject answer <p>A little girl</p> {<25><6><95><85>}
<p>long brown hair</p> {<33><26><74><61>}
<p>a hat</p> {<39><7><74><29>}
<p>newspaper</p> {<39><17><74><29>}
<p>a gift</p> {<10><67><85><100>}
<p>other people</p> {<0><1><37><70>}<delim>{<75><0><100><52>}<delim>{<83><16><100><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There are four US military soldiers in this photo , only two have their faces in the picture , there is a pack of cigarettes by one of their boots , they appear to be fixing a motorcycle 
CaptionToObject answer <p>four US military soldiers</p> {<6><1><89><75>}<delim>{<55><4><100><76>}<delim>{<2><1><32><70>}
<p>only two</p> {<6><1><89><75>}<delim>{<55><4><100><76>}
<p>their faces</p> {<25><12><35><24>}<delim>{<64><33><71><41>}
<p>a pack of cigarettes</p> {<20><71><31><76>}
<p>one of their boots</p> {<20><38><50><75>}
<p>a motorcycle</p> {<16><22><76><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young thin man with a backpack wearing striped t-shirt and glasses is walking on the street and looking at something on his right 
CaptionToObject answer <p>A young thin man</p> {<45><16><71><100>}
<p>a backpack</p> {<47><27><66><80>}
<p>striped t-shirt</p> {<45><28><64><58>}
<p>glasses</p> {<49><21><56><26>}
<p>the street</p> {<0><67><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a blue shirt , two men and someone else with orange shorts are playing volleyball 
CaptionToObject answer <p>A woman</p> {<3><35><23><100>}
<p>a blue shirt</p> {<3><48><19><78>}
<p>two men</p> {<54><21><76><100>}<delim>{<29><40><47><100>}
<p>someone</p> {<86><34><100><100>}
<p>orange shorts</p> {<85><62><100><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a boy in shorts and white shirt is jumping whilst holding a pink stick in front of a large tree surrounded by sacks 
CaptionToObject answer <p>a boy</p> {<11><12><70><72>}
<p>shorts</p> {<24><41><45><57>}
<p>white shirt</p> {<19><21><55><42>}
<p>a pink stick</p> {<7><14><16><33>}
<p>a large tree</p> {<40><0><100><31>}
<p>sacks</p> {<70><29><97><53>}<delim>{<45><29><75><53>}<delim>{<17><31><29><46>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a brown jacket passes by a column with an advertisement pasted on it , featuring red lettering and a person 's face 
CaptionToObject answer <p>A woman</p> {<4><70><24><100>}
<p>a brown jacket</p> {<4><82><24><100>}
<p>a column</p> {<73><1><100><100>}
<p>an advertisement</p> {<73><1><100><100>}
<p>red lettering</p> {<82><17><97><29>}
<p>a person 's face</p> {<74><50><94><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] People , including one in a wheelchair , are crossing a city street in a crosswalk 
CaptionToObject answer <p>People</p> {<43><52><65><92>}<delim>{<0><52><23><100>}<delim>{<18><65><40><94>}<delim>{<31><57><43><83>}
<p>one</p> {<18><65><40><94>}
<p>a wheelchair</p> {<19><72><39><94>}
<p>a city street</p> {<0><62><100><100>}
<p>a crosswalk</p> {<0><73><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman in a black blouse , blue jeans , and sandals is standing behind another young woman who is seated with a red poncho draped around her as the first young lady cuts her hair 
CaptionToObject answer <p>A young woman</p> {<43><1><100><95>}
<p>a black blouse</p> {<55><15><100><59>}
<p>blue jeans</p> {<59><49><98><87>}
<p>sandals</p> {<80><85><89><94>}
<p>another young woman</p> {<1><46><80><100>}
<p>a red poncho</p> {<11><73><79><100>}
<p>the first young lady</p> {<43><1><100><95>}
<p>her hair</p> {<19><47><65><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman with corn-rows and bikini swimming in the sea with a school of fish 
CaptionToObject answer <p>Woman</p> {<20><7><78><64>}
<p>corn-rows</p> {<32><7><71><41>}
<p>bikini</p> {<39><32><62><59>}
<p>the sea</p> {<1><0><100><100>}
<p>a school of fish</p> {<1><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A heavyset woman in a red shirt and black shoulder straps balances a blue container filled with goods on top of her head 
CaptionToObject answer <p>A heavyset woman</p> {<28><32><75><100>}
<p>a red shirt</p> {<29><55><68><100>}
<p>black shoulder straps</p> {<36><54><64><79>}
<p>a blue container</p> {<29><6><69><33>}
<p>goods</p> {<29><6><69><33>}
<p>her head</p> {<41><32><56><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A dog jumping up for a ball held by a woman in black skirt , beige vest and blue shirt 
CaptionToObject answer <p>A dog</p> {<54><28><77><85>}
<p>a ball</p> {<60><28><66><31>}
<p>a woman</p> {<20><6><64><84>}
<p>black skirt</p> {<20><38><42><60>}
<p>beige vest</p> {<19><12><44><46>}
<p>blue shirt</p> {<35><15><50><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A person with a helmet is riding a bike i the grass and dirt 
CaptionToObject answer <p>A person</p> {<25><46><53><62>}
<p>a helmet</p> {<44><46><51><51>}
<p>a bike</p> {<18><50><55><76>}
<p>the grass</p> {<1><47><100><69>}
<p>dirt</p> {<0><68><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and women walking down the street holding bags in their hands and smiling both wearing black and white clothes 
CaptionToObject answer <p>A man</p> {<37><39><69><100>}
<p>women</p> {<63><48><87><100>}
<p>the street</p> {<0><58><100><100>}
<p>bags</p> {<33><70><45><82>}<delim>{<64><66><77><72>}
<p>their hands</p> {<40><69><44><72>}<delim>{<59><66><65><75>}<delim>{<76><65><83><70>}<delim>{<65><65><70><71>}
<p>black and white clothes</p> {<64><48><86><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Male lead singer of a rock band on stage singing with microphone in hand as guitarist and drummer look on 
CaptionToObject answer <p>Male lead singer of a rock band</p> {<32><13><80><85>}
<p>microphone</p> {<56><15><60><20>}
<p>hand</p> {<54><19><64><30>}
<p>guitarist</p> {<1><40><26><99>}
<p>drummer</p> {<84><51><100><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing glasses is sitting down at a table with glasses , a bottle , and a bird on it 
CaptionToObject answer <p>A woman</p> {<0><0><60><73>}
<p>glasses</p> {<8><12><41><24>}<delim>{<46><62><65><88>}<delim>{<0><50><16><69>}<delim>{<50><47><69><63>}<delim>{<1><69><17><98>}
<p>a table</p> {<3><59><100><100>}
<p>a bottle</p> {<19><32><42><99>}
<p>a bird</p> {<78><64><99><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl wearing a blue shirt and carrying an orange lunchbox is walking up the sidewalk with a group of other children behind her 
CaptionToObject answer <p>A little girl</p> {<29><35><71><93>}
<p>a blue shirt</p> {<37><48><63><65>}
<p>an orange lunchbox</p> {<26><63><51><80>}
<p>the sidewalk</p> {<1><23><90><100>}
<p>a group of other children</p> {<59><21><75><52>}<delim>{<47><26><61><37>}<delim>{<23><25><46><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A biker wearing a helmet and a red coat is raising his bike above his head with both hands 
CaptionToObject answer <p>A biker</p> {<42><20><83><100>}
<p>a helmet</p> {<56><41><71><52>}
<p>a red coat</p> {<40><30><85><92>}
<p>his bike</p> {<7><1><100><70>}
<p>his head</p> {<55><41><73><61>}
<p>both hands</p> {<65><19><76><31>}<delim>{<66><19><75><33>}<delim>{<45><24><52><31>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with sunglasses and earphones is on a city street holding an mp3 player in his hand 
CaptionToObject answer <p>A man</p> {<35><24><100><99>}
<p>sunglasses</p> {<46><34><67><41>}
<p>earphones</p> {<34><35><67><90>}
<p>a city street</p> {<0><92><100><100>}<delim>{<1><88><100><100>}
<p>an mp3 player</p> {<37><76><50><82>}
<p>his hand</p> {<36><74><53><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Guy with something in his mouth in rushing water holding red and white striped rope 
CaptionToObject answer <p>Guy</p> {<26><29><69><83>}
<p>something</p> {<57><53><61><62>}
<p>his mouth</p> {<55><49><61><56>}
<p>water</p> {<0><1><100><100>}
<p>red and white striped rope</p> {<1><58><100><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a gray hat , red hooded sweatshirt and a gray jacket over it holds some tool that looks like a welding torch over a fire in a wall notch in his white gloved hands 
CaptionToObject answer <p>A man</p> {<10><3><95><84>}
<p>a gray hat</p> {<63><6><85><20>}
<p>red hooded sweatshirt</p> {<37><12><88><57>}
<p>a gray jacket</p> {<18><5><91><61>}
<p>some tool</p> {<1><16><50><62>}
<p>a welding torch</p> {<36><42><52><62>}
<p>a fire</p> {<27><76><47><88>}<delim>{<67><76><84><87>}
<p>a wall notch</p> {<0><61><100><100>}
<p>his white gloved hands</p> {<42><47><55><55>}<delim>{<19><19><32><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman is standing in front of a line of other women wearing a white dress and a white veil while a man is heading towards her 
CaptionToObject answer <p>A woman</p> {<41><24><63><92>}
<p>a line of other women</p> {<41><24><63><92>}<delim>{<51><27><74><81>}
<p>a white dress</p> {<41><25><72><94>}
<p>a white veil</p> {<41><23><58><53>}
<p>a man</p> {<9><14><54><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A male in a black shirt , and black pants , working on the engine of an old , green antique automobile , with a yellow gas canister sitting on the grass 
CaptionToObject answer <p>A male</p> {<57><47><96><87>}
<p>a black shirt</p> {<59><50><81><62>}
<p>black pants</p> {<68><57><96><89>}
<p>the engine of an old , green antique automobile</p> {<8><26><85><83>}
<p>a yellow gas canister</p> {<24><82><36><99>}
<p>the grass</p> {<0><41><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a ponytail sitting at the dge of a wooden bench , grass and flowers before her 
CaptionToObject answer <p>A girl</p> {<42><37><67><82>}
<p>a ponytail</p> {<48><40><57><51>}
<p>the dge of a wooden bench</p> {<5><58><49><86>}
<p>grass</p> {<1><6><100><100>}
<p>flowers</p> {<45><59><61><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a kid that is wearing a mickey mouse shirt is jumping with his arms extended to the sides and a happy expression on his face 
CaptionToObject answer <p>a kid</p> {<1><1><100><100>}
<p>a mickey mouse shirt</p> {<2><10><91><69>}
<p>his arms</p> {<1><0><31><43>}<delim>{<60><33><100><44>}
<p>a happy expression</p> {<33><18><69><42>}
<p>his face</p> {<39><20><60><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a backwards baseball cap , black shirt and blue shorts behind the steering wheel of a boat with a flag behind him 
CaptionToObject answer <p>A man</p> {<39><5><57><100>}
<p>a backwards baseball cap</p> {<44><5><53><17>}
<p>black shirt</p> {<41><18><58><59>}
<p>blue shorts</p> {<44><55><57><79>}
<p>the steering wheel of a boat</p> {<33><26><46><84>}
<p>a flag</p> {<68><14><89><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A team of a man and woman performing water gymnastics , with the man holding the female partner high above his head in an inverted pose 
CaptionToObject answer <p>A team of a man</p> {<9><42><51><79>}
<p>woman</p> {<1><23><77><70>}
<p>the man</p> {<9><42><51><79>}
<p>his head</p> {<37><55><51><65>}
<p>an inverted pose</p> {<0><23><83><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a blue sparkly dress with a slit up the leg holding a microphone 
CaptionToObject answer <p>A woman</p> {<20><8><53><86>}
<p>a blue sparkly dress</p> {<31><31><52><85>}
<p>a slit</p> {<38><51><47><84>}
<p>the leg</p> {<36><48><49><87>}
<p>a microphone</p> {<16><26><30><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a cigarette in his mouth , with no shirt , wearing shorts 
CaptionToObject answer <p>A man</p> {<22><26><60><92>}
<p>a cigarette</p> {<46><33><49><35>}
<p>his mouth</p> {<44><33><49><35>}
<p>no shirt</p> {<22><36><55><57>}
<p>shorts</p> {<34><52><57><75>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a child on her shoulders who is holding a drum like toy and another child in her lap are sitting on a brick walkway in a crowd 
CaptionToObject answer <p>A woman</p> {<8><46><63><100>}
<p>a child</p> {<45><65><97><100>}
<p>a drum</p> {<57><30><100><66>}
<p>toy</p> {<57><30><100><66>}
<p>another child</p> {<45><65><97><100>}
<p>a brick walkway</p> {<61><33><99><64>}
<p>a crowd</p> {<71><0><100><58>}<delim>{<0><0><14><50>}<delim>{<31><1><67><19>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two guys playing in a band , one playing a guitar , and one playing the keyboard 
CaptionToObject answer <p>Two guys</p> {<26><53><48><100>}<delim>{<59><11><92><100>}
<p>a band</p> {<26><53><48><100>}<delim>{<59><11><92><100>}
<p>one</p> {<59><11><92><100>}<delim>{<26><53><48><100>}
<p>a guitar</p> {<62><37><87><99>}
<p>the keyboard</p> {<0><83><39><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A solitary woman uses a large primitive mortar and pestle to crush plant material as she stands in a stubble field 
CaptionToObject answer <p>A solitary woman</p> {<19><28><49><69>}
<p>a large primitive mortar</p> {<41><28><61><71>}
<p>pestle</p> {<40><27><54><61>}
<p>plant material</p> {<42><58><59><64>}
<p>a stubble field</p> {<1><19><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a cap and brown shirt is standing on a grassy incline by a pile of hay or grass on some kind of wooden sled attached to a horse with chains 
CaptionToObject answer <p>A man</p> {<2><23><17><67>}
<p>a cap</p> {<6><21><12><30>}
<p>brown shirt</p> {<3><28><17><47>}
<p>a grassy incline</p> {<0><42><100><100>}
<p>a pile of hay or grass</p> {<14><26><57><66>}
<p>some kind of wooden sled</p> {<35><50><100><69>}
<p>a horse</p> {<56><24><94><80>}
<p>chains</p> {<53><33><72><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a hat , white shirt and gold chain with a cross 
CaptionToObject answer <p>A man</p> {<0><39><73><100>}
<p>a hat</p> {<23><39><56><61>}
<p>white shirt</p> {<4><60><71><100>}
<p>gold chain</p> {<24><61><46><88>}
<p>a cross</p> {<22><63><46><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a hat carrying several baskets and a child wearing a blue hat by her back 
CaptionToObject answer <p>A woman</p> {<56><19><82><97>}
<p>a hat</p> {<60><19><76><38>}
<p>several baskets</p> {<40><69><65><99>}<delim>{<57><52><80><82>}<delim>{<57><83><81><100>}
<p>a child</p> {<47><25><60><74>}
<p>a blue hat</p> {<47><24><60><43>}
<p>her back</p> {<51><40><71><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The people seem to be dancing , a man in a black hat in the back of the image is pointing his finger , and there is a picture of a woman on the left side 
CaptionToObject answer <p>The people</p> {<37><24><99><96>}<delim>{<2><33><74><68>}
<p>a man</p> {<37><24><99><96>}<delim>{<57><10><100><92>}
<p>a black hat</p> {<70><8><78><22>}
<p>his finger</p> {<59><21><61><27>}
<p>a picture of a woman</p> {<0><64><11><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in blue dress in crossing the street while a person in bright yellow is riding their bike down it 
CaptionToObject answer <p>A woman</p> {<66><27><83><97>}
<p>blue dress</p> {<70><37><81><76>}
<p>the street</p> {<6><25><100><100>}
<p>a person</p> {<34><25><45><51>}
<p>bright yellow</p> {<37><29><44><41>}
<p>their bike</p> {<34><35><46><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing brown shorts and a tan shirt stands in the grass holding 2 nerf jousting toys watching his son crawl in the grass toward another nerf joust toy 
CaptionToObject answer <p>A man</p> {<29><1><45><81>}
<p>brown shorts</p> {<29><34><42><62>}
<p>a tan shirt</p> {<29><4><43><39>}
<p>the grass</p> {<0><62><100><100>}<delim>{<0><62><100><100>}
<p>2 nerf</p> {<23><32><54><78>}
<p>toys</p> {<23><32><54><78>}<delim>{<79><67><89><76>}
<p>his son crawl</p> {<58><52><79><80>}
<p>another nerf joust toy</p> {<79><67><89><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in a yellow sports uniform and another man dressed in a red and white sports uniform holding sticks with a ball floating between them 
CaptionToObject answer <p>A man</p> {<48><12><98><92>}
<p>a yellow sports uniform</p> {<3><25><53><92>}
<p>another man</p> {<48><12><98><92>}
<p>a red and white sports uniform</p> {<59><18><86><58>}
<p>sticks</p> {<18><48><52><76>}<delim>{<17><22><56><49>}
<p>a ball</p> {<33><23><37><29>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a hat has his eyes closed , as another man in a red shirt is licking his face 
CaptionToObject answer <p>A man</p> {<44><18><95><100>}
<p>a hat</p> {<51><17><79><55>}
<p>his eyes</p> {<52><29><63><37>}
<p>another man</p> {<4><18><77><100>}
<p>a red shirt</p> {<5><81><43><100>}
<p>his face</p> {<50><24><68><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a red jacket looks at a paper while another man in a black jacket looks at the camera in a snow-covered field 
CaptionToObject answer <p>A man</p> {<49><0><100><100>}
<p>a red jacket</p> {<68><7><100><100>}
<p>a paper</p> {<20><46><72><73>}
<p>another man</p> {<29><1><89><95>}
<p>a black jacket</p> {<37><7><77><48>}
<p>a snow-covered field</p> {<0><19><97><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with a bottle of champagne and a man with wild hair standing in front of a crowd of people in the street 
CaptionToObject answer <p>A woman</p> {<17><30><43><100>}
<p>a bottle of champagne</p> {<35><47><46><75>}
<p>a man</p> {<46><22><92><100>}
<p>wild hair</p> {<46><22><73><45>}
<p>a crowd of people</p> {<0><35><100><100>}
<p>the street</p> {<1><66><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a dark green apron standing with his hands on his waist with a grill in the background 
CaptionToObject answer <p>A man</p> {<5><7><37><100>}
<p>a dark green apron</p> {<8><20><27><74>}
<p>his hands</p> {<22><40><28><49>}<delim>{<8><42><13><49>}
<p>his waist</p> {<10><41><25><51>}
<p>a grill</p> {<51><44><100><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Skylights in a art gallery illuminate large pieces of art while a young adult sits on the floor before one seeming to sketch in a pad 
CaptionToObject answer <p>Skylights</p> {<0><1><100><29>}
<p>art</p> {<70><47><94><77>}
<p>a young adult</p> {<58><74><69><89>}
<p>the floor</p> {<0><77><100><100>}
<p>one</p> {<58><74><69><89>}
<p>a pad</p> {<64><82><67><84>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a scarf and head covering walks on a sidewalk past a house 
CaptionToObject answer <p>A woman</p> {<45><41><58><91>}
<p>a scarf</p> {<47><41><57><71>}
<p>head</p> {<50><41><55><48>}
<p>a sidewalk</p> {<0><76><100><99>}
<p>a house</p> {<57><0><100><36>}

Train: data epoch: [0]  [ 200/1000]  eta: 0:04:20  lr: 0.000003  loss: 1.3287  time: 0.3156  data: 0.0000  max mem: 29214
CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man in a white shirt holding cotton candy next to a young woman in a white tank top 
CaptionToObject answer <p>A young man</p> {<58><19><100><99>}
<p>a white shirt</p> {<72><42><100><100>}
<p>cotton candy</p> {<57><56><66><88>}
<p>a young woman</p> {<32><31><57><100>}
<p>a white tank top</p> {<34><48><54><89>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with long black hair wearing a black shirt and multi-color tie is using a electronic board with lights on it 
CaptionToObject answer <p>A man</p> {<3><2><45><90>}
<p>long black hair</p> {<20><1><42><22>}
<p>a black shirt</p> {<9><14><36><65>}<delim>{<1><13><35><85>}
<p>multi-color tie</p> {<20><13><29><52>}<delim>{<21><14><28><50>}
<p>a electronic board</p> {<16><67><53><91>}<delim>{<55><55><90><85>}
<p>lights</p> {<17><65><55><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a red-haired woman with glass sitting at a craft booth , displaying the items to the audience 
CaptionToObject answer <p>a red-haired woman</p> {<67><79><82><100>}
<p>glass</p> {<46><39><53><43>}
<p>a craft booth</p> {<11><67><98><100>}
<p>the items</p> {<40><63><43><68>}<delim>{<50><60><81><73>}<delim>{<46><65><51><68>}
<p>the audience</p> {<40><33><58><70>}<delim>{<10><78><30><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bearded man is sitting on a bench wearing a fur lined jacket and hat 
CaptionToObject answer <p>A bearded man</p> {<14><16><100><100>}
<p>a bench</p> {<1><59><31><89>}
<p>a fur</p> {<22><23><100><88>}
<p>jacket</p> {<22><23><100><88>}
<p>hat</p> {<28><16><74><36>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man in red shirt and gray pants with a bag standing on white and gray pavement 
CaptionToObject answer <p>Man</p> {<44><16><69><64>}
<p>red shirt</p> {<52><21><63><37>}
<p>gray pants</p> {<51><34><64><62>}
<p>a bag</p> {<46><21><56><47>}
<p>white and gray pavement</p> {<0><51><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a suit walking down the sidewalk with his arm in a sling 
CaptionToObject answer <p>A man</p> {<28><24><46><96>}
<p>a suit</p> {<27><35><47><92>}
<p>the sidewalk</p> {<0><50><100><100>}
<p>his arm</p> {<41><34><45><50>}<delim>{<39><37><45><54>}
<p>a sling</p> {<35><34><46><54>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl with purple pants , a striped jacket , and a white hat is climbing up a ladder made of logs 
CaptionToObject answer <p>A young girl</p> {<48><30><80><97>}
<p>purple pants</p> {<51><41><79><92>}
<p>a striped jacket</p> {<51><41><78><72>}
<p>a white hat</p> {<59><30><68><44>}
<p>a ladder</p> {<9><9><80><99>}
<p>logs</p> {<6><13><82><99>}<delim>{<0><0><14><83>}<delim>{<20><33><50><55>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Black and white bird with orange beak in water with rocks around 
CaptionToObject answer <p>Black</p> {<33><50><58><84>}
<p>white bird</p> {<33><51><58><82>}
<p>orange beak</p> {<52><56><59><62>}
<p>water</p> {<0><57><100><100>}
<p>rocks</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The basketball player in white is defending the basket against the player wearing blue 
CaptionToObject answer <p>The basketball player</p> {<13><31><91><100>}
<p>white</p> {<7><85><43><100>}
<p>the basket</p> {<3><3><44><28>}
<p>the player</p> {<13><31><91><100>}
<p>blue</p> {<27><66><59><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a cowboy hat , Texan boots , and a blue shirt bucks violently on a black horse with a white spot on its ' forehead 
CaptionToObject answer <p>A man</p> {<23><17><66><54>}
<p>a cowboy hat</p> {<44><20><58><26>}
<p>Texan boots</p> {<22><49><34><57>}<delim>{<47><43><54><50>}
<p>a blue shirt</p> {<42><18><67><36>}
<p>a black horse</p> {<27><29><84><87>}
<p>a white spot</p> {<34><68><40><74>}
<p>' forehead</p> {<34><67><40><73>}<delim>{<33><66><42><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two construction men walk in front of a big wall with a mannequin with a construction shirt near two boots 
CaptionToObject answer <p>Two construction men</p> {<51><61><64><98>}<delim>{<52><54><67><100>}
<p>a big wall</p> {<1><1><96><96>}
<p>a mannequin</p> {<1><1><96><96>}
<p>a construction shirt</p> {<10><29><38><100>}
<p>two boots</p> {<29><57><54><100>}<delim>{<65><63><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soccer player in blue is striking the ball whilst being pursued by a player in green 
CaptionToObject answer <p>A soccer player</p> {<18><10><51><100>}
<p>blue</p> {<27><20><52><77>}<delim>{<19><79><30><99>}
<p>the ball</p> {<24><4><34><19>}
<p>a player</p> {<53><1><76><95>}
<p>green</p> {<54><13><75><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a brown jacket with a large crown on her head talks on a cellphone 
CaptionToObject answer <p>A woman</p> {<0><42><100><100>}
<p>a brown jacket</p> {<1><66><100><100>}
<p>a large crown</p> {<29><25><83><45>}
<p>her head</p> {<25><40><82><66>}
<p>a cellphone</p> {<25><52><38><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] At an outdoor event on a large table , several workers form an assembly line in which they prepare food , with many squeeze bottles and dispensers visible and a woman wearing plastic gloves in the foreground 
CaptionToObject answer <p>a large table</p> {<1><37><100><100>}
<p>several workers</p> {<27><13><94><67>}
<p>many squeeze bottles</p> {<0><35><17><61>}
<p>dispensers</p> {<2><34><17><61>}<delim>{<0><31><15><44>}<delim>{<0><56><18><92>}<delim>{<30><55><42><80>}
<p>a woman</p> {<27><13><94><67>}
<p>plastic gloves</p> {<29><24><52><44>}<delim>{<26><34><40><48>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] After the wedding bride in beautiful gown and groom walking across the street holding hands 
CaptionToObject answer <p>the wedding bride</p> {<47><21><85><97>}
<p>beautiful gown</p> {<47><40><84><96>}
<p>groom</p> {<25><19><53><94>}
<p>the street</p> {<1><39><100><100>}
<p>hands</p> {<49><46><54><53>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing white shorts and a black tank top next to a man with red shorts and a black shirt walking on the sidewalk 
CaptionToObject answer <p>A man</p> {<56><16><85><98>}<delim>{<61><16><84><97>}
<p>white shorts</p> {<59><60><81><90>}
<p>a black tank top</p> {<68><28><82><70>}
<p>a man</p> {<56><16><85><98>}<delim>{<52><0><70><71>}
<p>red shorts</p> {<51><41><70><54>}
<p>a black shirt</p> {<56><5><69><44>}
<p>the sidewalk</p> {<1><7><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man , woman , and child are crouched down and the man is holding a gun 
CaptionToObject answer <p>A man</p> {<44><22><85><100>}
<p>woman</p> {<32><28><53><81>}
<p>child</p> {<53><37><64><67>}
<p>the man</p> {<44><22><85><100>}
<p>a gun</p> {<38><54><60><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a tropical shirt with leis around his neck is holding a microphone 
CaptionToObject answer <p>A man</p> {<0><4><100><100>}
<p>a tropical shirt</p> {<0><42><100><100>}
<p>leis</p> {<9><40><74><100>}
<p>his neck</p> {<32><50><52><62>}<delim>{<31><49><54><61>}
<p>a microphone</p> {<49><43><75><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A contestant riding a pony in a rodeo setting is being thrown by the horse , while another cowboy looks on in the arena and spectators watch from behind a fence 
CaptionToObject answer <p>A contestant</p> {<5><16><23><62>}
<p>a pony</p> {<33><32><74><80>}
<p>the horse</p> {<33><32><74><80>}
<p>another cowboy</p> {<6><16><20><61>}
<p>spectators</p> {<58><0><82><28>}
<p>a fence</p> {<0><7><100><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little boy in black shorts and no shirt is holding on to handles as he flies down a rope 
CaptionToObject answer <p>A little boy</p> {<16><29><78><70>}
<p>black shorts</p> {<35><54><62><65>}<delim>{<39><54><62><64>}
<p>no shirt</p> {<44><37><63><57>}
<p>handles</p> {<44><21><60><32>}
<p>a rope</p> {<44><20><62><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man on a motorbike is leading the horse with another man on its back 
CaptionToObject answer <p>A man</p> {<24><32><44><70>}
<p>a motorbike</p> {<19><47><41><77>}
<p>the horse</p> {<43><25><95><88>}
<p>another man</p> {<56><22><65><58>}
<p>its back</p> {<54><34><74><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy wearing shorts and a t-shirt shades his eyes from the sun while resting on a boulder and cooling his feet in the slowly-moving , rocky , shallow river 
CaptionToObject answer <p>A boy</p> {<28><41><63><61>}
<p>shorts</p> {<38><46><46><58>}<delim>{<38><47><47><57>}
<p>a t-shirt</p> {<46><45><56><54>}<delim>{<45><44><57><55>}
<p>his eyes</p> {<58><47><60><53>}
<p>a boulder</p> {<41><51><71><60>}
<p>his feet</p> {<28><54><35><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black dog and a brown dog with a stick in his mouth are running in the field 
CaptionToObject answer <p>A black dog</p> {<1><5><58><60>}
<p>a brown dog</p> {<23><22><81><100>}
<p>a stick</p> {<55><40><88><62>}
<p>his mouth</p> {<63><42><76><55>}
<p>the field</p> {<1><14><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in jeans resting on a striped bench with his feet on a luggage cart 
CaptionToObject answer <p>A man</p> {<49><40><79><96>}
<p>jeans</p> {<55><66><72><86>}
<p>a striped bench</p> {<45><50><82><93>}
<p>his feet</p> {<49><80><58><96>}
<p>a luggage cart</p> {<33><48><72><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in blue tank top and black biker pants with a red stripe on them riding a bike on the sidewalk 
CaptionToObject answer <p>A woman</p> {<39><24><65><94>}
<p>blue tank top</p> {<39><32><53><53>}
<p>black biker pants</p> {<38><49><59><72>}
<p>a red stripe</p> {<38><49><45><71>}
<p>a bike</p> {<36><51><74><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup 
CaptionToObject answer <p>A shirtless man</p> {<67><48><91><100>}
<p>a white hat</p> {<78><49><86><55>}
<p>no shoes</p> {<71><94><80><100>}<delim>{<67><91><71><99>}<delim>{<68><92><72><97>}
<p>his back</p> {<84><62><91><88>}
<p>the wall</p> {<89><2><100><100>}
<p>a white plastic cup</p> {<70><56><75><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman washing her laundry in the river , beating her clothes on a rock 
CaptionToObject answer <p>A woman</p> {<26><18><56><76>}
<p>her laundry</p> {<40><0><53><33>}
<p>the river</p> {<0><55><100><100>}
<p>her clothes</p> {<40><0><53><33>}
<p>a rock</p> {<45><58><71><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A kid in a white shirt and white hat and jeans skateboards down a ramp 
CaptionToObject answer <p>A kid</p> {<37><2><82><56>}
<p>a white shirt</p> {<43><13><73><34>}<delim>{<48><16><74><35>}
<p>white hat</p> {<48><13><57><17>}
<p>jeans</p> {<57><30><81><51>}<delim>{<58><29><78><49>}
<p>a ramp</p> {<12><51><100><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older man in gray khakis walks with a young boy in a green shirt along the edge of a fountain in a park 
CaptionToObject answer <p>An older man</p> {<24><1><59><99>}
<p>gray khakis</p> {<31><42><51><70>}
<p>a young boy</p> {<53><23><71><85>}
<p>a green shirt</p> {<54><35><71><63>}
<p>the edge of a fountain</p> {<23><67><100><100>}
<p>a park</p> {<1><11><100><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An african-american women wearing a striped scarf on her head is in the foreground of a busy market scene which includes a bearded man wearing a blue turban and a young lady wearing a braided headband 
CaptionToObject answer <p>An african-american women</p> {<8><26><75><100>}
<p>a striped scarf</p> {<41><27><76><59>}
<p>her head</p> {<41><27><76><59>}<delim>{<42><27><75><87>}
<p>a bearded man</p> {<71><5><100><95>}
<p>a blue turban</p> {<72><6><95><23>}
<p>a young lady</p> {<10><3><35><56>}
<p>a braided headband</p> {<20><8><37><18>}<delim>{<19><10><35><15>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a jack wearing a red baseball hat with NYC written in black on it is looking at something off picture while holding up a sign with the word CYCLE in red on it and the rest cut out of the picture 
CaptionToObject answer <p>A man</p> {<20><2><100><100>}
<p>a red baseball hat</p> {<39><2><75><31>}
<p>NYC</p> {<52><10><67><19>}
<p>black</p> {<20><52><100><100>}
<p>picture</p> {<1><75><48><100>}
<p>a sign</p> {<1><75><48><100>}
<p>the word CYCLE</p> {<0><81><40><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a black shirt puts his hands under the foot of a girl in a white shirt who holds his neck 
CaptionToObject answer <p>A boy</p> {<44><26><93><100>}
<p>a black shirt</p> {<54><35><92><72>}
<p>his hands</p> {<57><72><64><77>}
<p>the foot of a girl</p> {<53><69><63><76>}
<p>a white shirt</p> {<25><32><50><57>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl with a tattoo on her wrist that reads " no regrets " has her hand outstretched 
CaptionToObject answer <p>A girl</p> {<0><0><100><91>}
<p>a tattoo</p> {<36><37><70><45>}
<p>her wrist</p> {<33><36><71><55>}
<p>no regrets</p> {<35><38><71><46>}
<p>her hand</p> {<28><51><78><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two older women , one on a bicycle talking in front of a sign in a city with an older gentleman looking on 
CaptionToObject answer <p>Two older women</p> {<42><66><62><100>}<delim>{<65><68><86><100>}
<p>one</p> {<65><68><86><100>}
<p>a bicycle</p> {<61><84><100><100>}
<p>a sign</p> {<15><33><64><53>}<delim>{<14><51><64><66>}<delim>{<15><68><64><81>}
<p>an older gentleman</p> {<2><66><22><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a Rastafarian hat and Fred locks leans forward with his arms outstretched and his hands together 
CaptionToObject answer <p>A man</p> {<4><4><93><100>}
<p>a Rastafarian hat</p> {<34><4><68><16>}
<p>Fred locks</p> {<31><13><67><29>}
<p>his arms</p> {<6><24><76><41>}
<p>outstretched</p> {<4><24><47><44>}
<p>his hands</p> {<6><24><76><41>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man sitting on a blanket with his kid while eating a waffle with whip cream and fruit 
CaptionToObject answer <p>A man</p> {<0><1><54><100>}
<p>a blanket</p> {<0><43><100><100>}
<p>his kid</p> {<52><59><87><100>}
<p>a waffle</p> {<25><60><38><72>}
<p>whip cream</p> {<28><61><36><68>}
<p>fruit</p> {<27><62><35><69>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two ladies one with her fingers in her pocket and the other with a drink in her hand at a party 
CaptionToObject answer <p>Two ladies</p> {<26><27><72><100>}<delim>{<9><26><35><96>}
<p>one</p> {<26><27><72><100>}
<p>her fingers</p> {<32><75><36><80>}<delim>{<48><86><60><91>}<delim>{<52><81><59><84>}
<p>her pocket</p> {<48><80><62><89>}
<p>the other</p> {<9><26><35><96>}
<p>a drink</p> {<6><45><14><52>}
<p>her hand</p> {<6><46><14><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young women wearing a green shirt and hat is sitting down , using a mehndi cone to paint a flower design on the back of one of her hands 
CaptionToObject answer <p>A young women</p> {<0><1><100><100>}
<p>a green shirt</p> {<1><2><100><65>}
<p>hat</p> {<36><1><100><21>}
<p>a mehndi cone</p> {<19><54><46><70>}
<p>a flower design</p> {<40><68><52><75>}
<p>her hands</p> {<8><54><61><95>}<delim>{<8><63><61><96>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a green shirt and khaki pants and sandals is looking at a row of meat hanging on ropes 
CaptionToObject answer <p>A man</p> {<8><39><17><91>}
<p>a green shirt</p> {<8><46><17><64>}
<p>khaki pants</p> {<9><61><17><88>}<delim>{<9><63><16><89>}
<p>sandals</p> {<10><87><16><91>}
<p>a row of meat</p> {<27><36><68><77>}
<p>ropes</p> {<26><27><33><69>}<delim>{<15><23><65><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing shorts but no shirt works on a sand sculpture at the beach while two people buried in the sand watch underneath a blue umbrella 
CaptionToObject answer <p>A man</p> {<40><6><59><49>}
<p>shorts</p> {<48><25><58><43>}
<p>no shirt</p> {<43><9><58><28>}
<p>a sand sculpture</p> {<1><21><100><74>}
<p>the beach</p> {<0><13><100><100>}
<p>two people</p> {<43><64><60><98>}<delim>{<12><58><34><82>}
<p>the sand</p> {<0><13><100><100>}
<p>a blue umbrella</p> {<1><17><43><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A glasses wearing woman dressed in a white dress shirt and khaki shorts has a finger across her mouth while she is carrying two books in her left hand 
CaptionToObject answer <p>A glasses</p> {<17><18><33><23>}
<p>woman</p> {<4><5><47><100>}
<p>a white dress shirt</p> {<3><24><38><82>}
<p>khaki shorts</p> {<10><70><40><95>}
<p>a finger</p> {<24><22><27><31>}
<p>her mouth</p> {<22><24><28><27>}
<p>two books</p> {<29><38><49><62>}
<p>her left hand</p> {<36><51><48><59>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men , one wearing a teal shirt and shin guards lay horizontally on logs with their backpacks in sight 
CaptionToObject answer <p>Two men</p> {<26><14><84><63>}
<p>one</p> {<26><14><84><63>}
<p>a teal shirt</p> {<33><28><50><44>}
<p>shin guards</p> {<48><23><63><39>}<delim>{<71><21><79><31>}<delim>{<70><18><80><26>}
<p>logs</p> {<0><40><53><100>}<delim>{<52><40><100><100>}
<p>their backpacks</p> {<1><56><35><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and a woman are sitting on a bench while the woman is holding the man 's arm 
CaptionToObject answer <p>A man</p> {<40><27><96><98>}
<p>a woman</p> {<12><28><59><100>}
<p>a bench</p> {<0><71><100><98>}
<p>the woman</p> {<12><28><59><100>}
<p>the man 's arm</p> {<39><42><79><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black dog is running along the beach beside a brown dog in midair catching a stick in its mouth 
CaptionToObject answer <p>A black dog</p> {<18><56><34><93>}
<p>the beach</p> {<0><54><100><100>}
<p>a brown dog</p> {<40><25><62><67>}
<p>a stick</p> {<52><35><57><42>}
<p>its mouth</p> {<52><33><56><38>}<delim>{<51><32><56><39>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl is on her tip toes standing on a stool at the sink brushing her teeth 
CaptionToObject answer <p>A little girl</p> {<55><25><84><87>}
<p>her tip toes</p> {<68><80><79><87>}
<p>a stool</p> {<53><76><95><100>}
<p>the sink</p> {<9><51><61><100>}
<p>her teeth</p> {<62><31><66><34>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black man stands behind a garbage can with his hand raised in front of a sign urging people to repent of various sins as boy in a school blazer holds the hand of a man in shorts 
CaptionToObject answer <p>A black man</p> {<54><6><83><70>}
<p>his hand</p> {<58><6><65><12>}
<p>a sign</p> {<13><6><64><70>}
<p>people</p> {<1><0><46><92>}
<p>boy</p> {<0><28><30><100>}
<p>a school blazer</p> {<0><56><26><100>}
<p>the hand of a man</p> {<20><61><33><81>}
<p>shorts</p> {<19><56><42><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a colorful shirt and glasses is playing guitar on stage 
CaptionToObject answer <p>A man</p> {<55><11><80><94>}
<p>a colorful shirt</p> {<55><22><78><58>}
<p>glasses</p> {<65><18><73><24>}
<p>guitar</p> {<61><18><94><53>}
<p>stage</p> {<1><91><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two people ride on a white motorcycle between two rows of parked motorcycles , and the driver smokes a cigarette 
CaptionToObject answer <p>Two people</p> {<20><10><47><76>}
<p>a white motorcycle</p> {<19><33><46><91>}
<p>two rows of parked motorcycles</p> {<46><22><100><100>}<delim>{<0><37><13><100>}
<p>the driver</p> {<20><19><46><78>}
<p>a cigarette</p> {<33><27><38><30>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] 2 women walk down the sidewalk wearing gloves , face masks and carrying brooms 
CaptionToObject answer <p>2 women</p> {<41><13><83><90>}<delim>{<25><23><55><82>}
<p>the sidewalk</p> {<2><59><100><99>}
<p>gloves</p> {<69><38><82><54>}<delim>{<40><34><51><42>}
<p>face masks</p> {<61><19><72><25>}<delim>{<33><29><43><34>}
<p>brooms</p> {<30><31><47><87>}<delim>{<17><36><33><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two children , a boy and a girl , laying down crossed legs with their heads down 
CaptionToObject answer <p>Two children</p> {<59><21><100><94>}<delim>{<2><21><49><99>}
<p>a boy</p> {<59><21><100><94>}
<p>a girl</p> {<2><21><49><99>}
<p>crossed legs</p> {<59><66><100><93>}<delim>{<4><67><48><100>}
<p>their heads</p> {<75><22><92><50>}<delim>{<20><23><42><50>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There is a boy wearing a cap , long shorts and slide on slippers sitting in a fold up chair on the dock of a lake or river , fishing 
CaptionToObject answer <p>a boy</p> {<23><19><81><73>}
<p>a cap</p> {<56><18><79><29>}
<p>long shorts</p> {<42><42><74><59>}
<p>slippers</p> {<23><65><50><72>}
<p>a fold</p> {<54><23><96><73>}
<p>chair</p> {<54><23><96><73>}
<p>the dock of a lake or river</p> {<0><58><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] women in white shirt and blue jeans wearing gray scarf around her neck 
CaptionToObject answer <p>women</p> {<48><36><85><100>}
<p>white shirt</p> {<53><52><85><76>}
<p>blue jeans</p> {<56><76><82><100>}
<p>gray scarf</p> {<58><48><82><78>}
<p>her neck</p> {<66><47><75><53>}<delim>{<65><47><78><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two people are standing on a boat in the water near shore with the sun above the horizon in the background 
CaptionToObject answer <p>Two people</p> {<57><60><60><68>}<delim>{<31><60><37><69>}
<p>a boat</p> {<28><48><61><71>}
<p>the water</p> {<0><59><100><79>}
<p>shore</p> {<0><76><100><100>}
<p>the sun</p> {<50><30><61><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl in a hat , striped shirt , and red shorts walking on a rope bridge 
CaptionToObject answer <p>A little girl</p> {<39><13><64><93>}
<p>a hat</p> {<50><13><66><28>}
<p>striped shirt</p> {<42><26><58><56>}
<p>red shorts</p> {<42><51><59><78>}
<p>a rope bridge</p> {<0><0><100><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A female clown plugs her ears with her fingers while holding an orange balloon in her left hand 
CaptionToObject answer <p>A female clown</p> {<10><17><77><100>}
<p>her ears</p> {<34><38><39><47>}<delim>{<51><41><53><50>}
<p>her fingers</p> {<34><41><40><59>}<delim>{<52><42><58><47>}
<p>an orange balloon</p> {<44><46><75><74>}
<p>her left hand</p> {<52><43><77><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with short brown hair and glasses laughs with a brunette man in a brown shirt 
CaptionToObject answer <p>A woman</p> {<0><20><51><100>}
<p>short brown hair</p> {<1><19><36><70>}
<p>glasses</p> {<25><38><36><46>}
<p>a brunette man</p> {<51><6><100><100>}
<p>a brown shirt</p> {<50><44><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two children play in a bedroom , fully furnished with bookshelves , a ' Dora the Explorer ' poster , and a bunk-bed shaped like a fantasy castle 
CaptionToObject answer <p>Two children</p> {<32><57><49><89>}<delim>{<51><1><61><27>}
<p>bookshelves</p> {<87><50><100><98>}
<p>a ' Dora</p> {<20><37><27><50>}
<p>the Explorer</p> {<18><34><27><50>}
<p>' poster</p> {<17><33><28><51>}
<p>a bunk-bed</p> {<26><16><90><94>}
<p>a fantasy castle</p> {<26><16><90><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman in a plaid jacket and face mask drives a passenger on a scooter 
CaptionToObject answer <p>A young woman</p> {<22><26><75><83>}
<p>a plaid jacket</p> {<1><29><27><100>}<delim>{<25><43><56><78>}
<p>face mask</p> {<41><35><56><44>}
<p>a passenger</p> {<0><29><25><100>}
<p>a scooter</p> {<1><53><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young girl with a bib smiles at a man while she sits behind a purple lunch tray and pie at a table 
CaptionToObject answer <p>A young girl</p> {<47><20><100><61>}
<p>a bib</p> {<54><38><82><60>}
<p>a man</p> {<1><12><49><82>}
<p>a purple lunch tray</p> {<30><60><96><72>}
<p>pie</p> {<23><71><89><95>}
<p>a table</p> {<0><60><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An adult riding a bike on a beach with many visible vapour trails in the sky 
CaptionToObject answer <p>An adult</p> {<39><48><50><79>}
<p>a bike</p> {<38><69><52><85>}
<p>a beach</p> {<1><76><100><100>}
<p>many visible vapour trails</p> {<1><0><100><64>}
<p>the sky</p> {<1><0><100><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy being fitted in a brown robe by a man in a white shirt and red cap , another man in a light blue shirt is twirling a ball 
CaptionToObject answer <p>A boy</p> {<42><26><57><100>}
<p>a brown robe</p> {<43><37><54><73>}
<p>a man</p> {<36><39><47><92>}
<p>a white shirt</p> {<37><48><45><80>}
<p>red cap</p> {<35><39><44><54>}
<p>another man</p> {<7><25><36><100>}
<p>a light blue shirt</p> {<15><42><35><79>}
<p>a ball</p> {<26><27><34><38>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a green jacket stands next to a man in a yellow jacket , who is looking at his leg 
CaptionToObject answer <p>A man</p> {<55><0><95><59>}
<p>a green jacket</p> {<55><0><95><58>}
<p>a man</p> {<55><0><95><59>}
<p>a yellow jacket</p> {<15><19><56><51>}
<p>his leg</p> {<60><40><73><60>}<delim>{<28><46><40><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman playing on a tire swing that is surrounded by trees with a smile on her face 
CaptionToObject answer <p>A woman</p> {<3><1><76><88>}
<p>a tire swing</p> {<11><1><89><94>}
<p>trees</p> {<55><1><100><80>}<delim>{<1><0><56><100>}
<p>a smile</p> {<34><7><43><13>}
<p>her face</p> {<33><0><46><13>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a gray shirt is talking and a woman wearing a red tank top and a man wearing a green shirt is listening to him 
CaptionToObject answer <p>A man</p> {<8><25><86><100>}
<p>a gray shirt</p> {<9><45><41><74>}
<p>a woman</p> {<52><29><100><100>}
<p>a red tank top</p> {<53><46><70><73>}
<p>a man</p> {<8><25><86><100>}<delim>{<72><40><100><91>}
<p>a green shirt</p> {<72><49><88><64>}<delim>{<72><50><88><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a black backpack and a woman with long dark hair and a teal colored shirt standing on some rocks looking at the ocean 
CaptionToObject answer <p>A man</p> {<17><50><33><100>}
<p>a black backpack</p> {<16><64><30><100>}
<p>a woman</p> {<37><50><51><100>}
<p>long dark hair</p> {<38><50><47><70>}
<p>a teal colored shirt</p> {<37><64><49><92>}
<p>some rocks</p> {<0><81><84><100>}
<p>the ocean</p> {<1><1><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a yellow shirt is looking down while a lady in a blue shirt holds a shirt up to him to see if it fits 
CaptionToObject answer <p>A boy</p> {<59><7><82><100>}
<p>a yellow shirt</p> {<63><33><82><63>}<delim>{<63><36><82><95>}
<p>a lady</p> {<23><17><58><100>}
<p>a blue shirt</p> {<25><40><56><94>}
<p>a shirt</p> {<51><34><84><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man wearing a t-shirt that says " We are the champions " is laughing with other young people at a bar 
CaptionToObject answer <p>A young man</p> {<26><18><47><100>}
<p>a t-shirt</p> {<25><34><48><79>}<delim>{<12><40><29><89>}
<p>We</p> {<36><42><41><47>}
<p>the champions</p> {<34><45><44><51>}
<p>other young people</p> {<69><28><100><100>}<delim>{<34><20><66><100>}<delim>{<3><17><30><100>}<delim>{<61><21><74><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a beige purse is crossing the street at a crosswalk with a Spring sign behind her 
CaptionToObject answer <p>A woman</p> {<28><25><51><100>}
<p>a beige purse</p> {<27><43><42><82>}<delim>{<29><43><40><83>}
<p>the street</p> {<0><70><100><100>}
<p>a crosswalk</p> {<0><78><100><100>}
<p>a Spring sign</p> {<49><35><69><43>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Many people walk on a sidewalk filled with blue street signs next to a row of buildings including one with yellow balconies 
CaptionToObject answer <p>Many people</p> {<9><34><98><100>}
<p>a sidewalk</p> {<9><34><98><100>}
<p>blue street signs</p> {<35><37><43><60>}<delim>{<64><37><68><44>}
<p>one</p> {<65><36><71><43>}
<p>yellow balconies</p> {<80><0><93><28>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men are at polling place counter , filling out forms :while a clerk in a red shirt and black pants waits on them 
CaptionToObject answer <p>Two men</p> {<0><24><30><95>}<delim>{<13><15><44><76>}<delim>{<13><16><45><76>}
<p>forms</p> {<12><80><35><89>}<delim>{<29><66><49><76>}
<p>a clerk</p> {<66><17><93><100>}
<p>a red shirt</p> {<70><35><94><79>}
<p>black pants</p> {<72><76><91><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing blue jeans and a vest is laying down on a city bench next to a beer bottle 
CaptionToObject answer <p>A man</p> {<16><37><86><62>}
<p>blue jeans</p> {<49><38><78><59>}
<p>a vest</p> {<27><36><53><60>}
<p>a city bench</p> {<10><56><100><91>}
<p>a beer bottle</p> {<50><74><55><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy in a black sweatshirt and khakis is holding a leaf blower with a gravel road with two mailboxes in the background 
CaptionToObject answer <p>A boy</p> {<29><8><53><100>}
<p>a black sweatshirt</p> {<28><21><51><64>}
<p>khakis</p> {<32><64><50><100>}
<p>a leaf blower</p> {<46><60><86><100>}
<p>a gravel road</p> {<0><24><99><51>}
<p>two mailboxes</p> {<50><2><58><46>}<delim>{<63><5><71><16>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady wearing a headset and a microphone talking on the phone and standing next to a light pole waiting to cross the street 
CaptionToObject answer <p>A lady</p> {<49><41><75><100>}
<p>a headset</p> {<58><44><64><48>}
<p>a microphone</p> {<61><46><67><50>}
<p>the phone</p> {<67><45><70><50>}
<p>a light pole</p> {<18><20><33><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a white hat and shirt stands near debris on wet sand near the water 
CaptionToObject answer <p>A woman</p> {<50><22><78><87>}
<p>a white hat</p> {<48><22><61><31>}
<p>shirt</p> {<59><26><77><56>}
<p>wet sand</p> {<0><8><100><100>}
<p>the water</p> {<1><0><100><46>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young adult male , wearing black pants , a white shirt and a red belt , is practicing martial arts 
CaptionToObject answer <p>A young adult male</p> {<29><28><61><100>}
<p>black pants</p> {<35><64><61><100>}
<p>a white shirt</p> {<35><44><57><67>}
<p>a red belt</p> {<43><65><50><69>}
<p>martial arts</p> {<17><28><62><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a light purple shirt raises his hand and looks at the floor while some other individuals sit or stand in the background 
CaptionToObject answer <p>A man</p> {<16><12><66><100>}
<p>a light purple shirt</p> {<28><32><66><76>}
<p>his hand</p> {<16><35><23><49>}<delim>{<16><37><22><50>}
<p>the floor</p> {<10><61><81><100>}
<p>some other individuals</p> {<87><22><100><68>}<delim>{<79><35><89><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a green polo shirt and glasses smiles as he looks at his computer at his desk , which is a little messy 
CaptionToObject answer <p>A man</p> {<32><15><87><100>}
<p>a green polo shirt</p> {<56><42><88><100>}
<p>glasses</p> {<59><30><74><40>}
<p>his computer</p> {<11><44><51><100>}
<p>his desk</p> {<0><45><67><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A red-haired woman dressed in black looks down at the papers in her hands as a subway train approaches 
CaptionToObject answer <p>A red-haired woman</p> {<13><8><47><100>}
<p>black</p> {<11><32><42><100>}
<p>the papers</p> {<36><48><54><67>}
<p>her hands</p> {<39><51><48><70>}
<p>a subway train</p> {<35><10><94><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in a hat and blue coat rides his bicycle past an outdoor gao quy stand on a sunny day 
CaptionToObject answer <p>A man</p> {<53><32><74><92>}
<p>a hat</p> {<57><33><66><42>}
<p>blue coat</p> {<57><33><66><42>}<delim>{<54><44><74><71>}
<p>his bicycle</p> {<42><57><88><98>}
<p>an outdoor gao</p> {<13><9><92><78>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bearded man in a light blue shirt peers through a magnifier to work on something that rests on a white paper box 
CaptionToObject answer <p>A bearded man</p> {<0><0><71><100>}
<p>a light blue shirt</p> {<0><27><49><100>}
<p>a magnifier</p> {<37><11><100><47>}
<p>something</p> {<75><51><88><58>}
<p>a white paper box</p> {<52><51><80><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is talking into a microphone , there is a boy in the background , a man is playing a keyboard and is wearing a camouflaged jacket 
CaptionToObject answer <p>A man</p> {<0><10><72><100>}
<p>a microphone</p> {<43><43><68><63>}
<p>a boy</p> {<61><23><89><84>}
<p>a man</p> {<0><10><72><100>}
<p>a keyboard</p> {<29><83><99><100>}
<p>a camouflaged jacket</p> {<0><36><53><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a shirt that says " Gigolo " is standing at a front desk area with his back to the camera 
CaptionToObject answer <p>A man</p> {<41><34><63><100>}
<p>a shirt</p> {<43><48><61><81>}
<p>Gigolo</p> {<46><49><58><54>}
<p>a front desk area</p> {<5><70><95><100>}
<p>his back</p> {<45><69><62><98>}<delim>{<42><47><62><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two woman with a stroller purchasing something from a man in a white t-shirt 
CaptionToObject answer <p>Two woman</p> {<47><22><87><76>}<delim>{<72><25><100><100>}
<p>a stroller</p> {<50><77><96><100>}
<p>something</p> {<76><58><80><62>}<delim>{<45><39><50><42>}
<p>a man</p> {<1><5><52><48>}
<p>a white t-shirt</p> {<3><20><30><46>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt is cutting something with a knife and fork on a kitchen cutting board 
CaptionToObject answer <p>A man</p> {<34><12><100><100>}
<p>a blue shirt</p> {<61><23><100><91>}
<p>something</p> {<29><73><43><79>}
<p>a knife</p> {<33><68><52><78>}
<p>fork</p> {<31><69><40><76>}
<p>a kitchen cutting board</p> {<15><72><50><86>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is putting sand on the ground near a large statute of a lady sitting down in a red dress holding a bottle 
CaptionToObject answer <p>A man</p> {<40><72><53><96>}
<p>sand</p> {<1><76><84><100>}
<p>a large statute of a lady</p> {<35><9><59><57>}
<p>a red dress</p> {<35><20><59><45>}
<p>a bottle</p> {<35><29><53><37>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man sells food from a cart on the street while pedestrians walk past 
CaptionToObject answer <p>A man</p> {<31><16><46><79>}
<p>food</p> {<41><26><50><43>}
<p>a cart</p> {<34><2><77><75>}
<p>the street</p> {<0><40><100><100>}
<p>pedestrians</p> {<2><0><27><96>}<delim>{<27><23><34><71>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man dressed in a red t-shirt and blue jeans eats food he 's holding in his hand , as he walks along a busy sidewalk , with an antique-style sign advertising wedding rings on the right-hand side of the picture 
CaptionToObject answer <p>A man</p> {<25><14><43><100>}
<p>a red t-shirt</p> {<26><28><43><64>}
<p>blue jeans</p> {<25><63><40><99>}
<p>food</p> {<27><37><31><45>}
<p>his hand</p> {<25><40><30><49>}<delim>{<28><41><35><50>}
<p>an antique-style sign</p> {<79><0><99><46>}
<p>wedding rings</p> {<80><19><98><27>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A bicyclist with a red cap and blue shirt rides a blue bicycle through a pedestrian area 
CaptionToObject answer <p>A bicyclist</p> {<63><33><100><84>}
<p>a red cap</p> {<73><33><88><41>}
<p>blue shirt</p> {<67><42><100><60>}
<p>a blue bicycle</p> {<38><61><100><100>}
<p>a pedestrian area</p> {<1><1><100><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue hat is standing next to a car with a shovel in the snow 
CaptionToObject answer <p>A man</p> {<22><33><52><79>}
<p>a blue hat</p> {<31><34><43><37>}
<p>a car</p> {<45><42><100><97>}
<p>a shovel</p> {<33><48><46><80>}
<p>the snow</p> {<1><28><100><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] a woman in a brown coat places a baby on a skateboard that is on a wooden runway on the beach 
CaptionToObject answer <p>a woman</p> {<47><22><100><74>}
<p>a brown coat</p> {<46><24><97><70>}
<p>a baby</p> {<22><30><61><66>}
<p>a skateboard</p> {<14><52><60><88>}
<p>a wooden runway</p> {<0><33><74><100>}
<p>the beach</p> {<0><13><100><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is biking down the street while holding a ladder , off to the side , a man is carrying a large bucket and two sticks 
CaptionToObject answer <p>A man</p> {<23><31><46><93>}
<p>a ladder</p> {<18><22><39><79>}
<p>a man</p> {<23><31><46><93>}<delim>{<50><42><63><80>}
<p>a large bucket</p> {<56><61><61><72>}
<p>two sticks</p> {<46><50><72><65>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt with a duffel bag and a woman in a yellow jacket pushing a baby stroller crossing a city street 
CaptionToObject answer <p>A man</p> {<60><4><100><100>}
<p>a blue shirt</p> {<60><17><91><60>}
<p>a duffel bag</p> {<83><22><100><61>}
<p>a woman</p> {<17><20><39><70>}
<p>a yellow jacket</p> {<16><23><33><53>}
<p>a baby stroller</p> {<7><40><27><77>}
<p>a city street</p> {<2><31><100><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young couple , with the guy wearing a sports t-shirt , sunglasses pulled over his face , squinting while blond female , in a white blouse , wearing her sunglasses , has a black purse strap across her shoulder 
CaptionToObject answer <p>A young couple</p> {<46><24><85><100>}
<p>the guy</p> {<33><23><62><99>}
<p>a sports t-shirt</p> {<32><57><62><100>}
<p>his face</p> {<45><24><58><35>}
<p>blond female</p> {<46><24><85><100>}
<p>a white blouse</p> {<48><67><82><100>}
<p>her sunglasses</p> {<55><35><67><47>}
<p>a black purse strap</p> {<47><69><87><100>}
<p>her shoulder</p> {<63><69><83><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three people , two adult women and a young girl , talk about a clock the girl is holding 
CaptionToObject answer <p>Three people</p> {<45><4><89><100>}<delim>{<1><2><47><80>}<delim>{<25><2><61><55>}
<p>two adult women</p> {<1><2><47><80>}
<p>a young girl</p> {<45><4><89><100>}
<p>a clock</p> {<38><73><73><98>}
<p>the girl</p> {<45><4><89><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a red and white bodysuit and funnel shaped helmet is riding a racing bicycle past four onlookers behind a metal barricade 
CaptionToObject answer <p>A man</p> {<41><8><71><70>}
<p>a red and white bodysuit</p> {<45><13><71><45>}
<p>shaped helmet</p> {<46><9><58><25>}
<p>a racing bicycle</p> {<40><30><83><90>}
<p>four onlookers</p> {<14><0><34><70>}<delim>{<79><0><90><48>}<delim>{<61><0><78><53>}<delim>{<26><1><46><67>}
<p>a metal barricade</p> {<0><16><100><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in a short dress carrying a silver purse looks at food in a bakery 
CaptionToObject answer <p>A girl</p> {<22><8><72><91>}
<p>a short dress</p> {<21><18><72><64>}
<p>a silver purse</p> {<28><21><59><65>}
<p>food</p> {<0><44><25><86>}
<p>a bakery</p> {<0><31><32><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young boy at a water park pouring a bucket water on a young girl in a swimsuit 
CaptionToObject answer <p>A young boy</p> {<24><13><50><89>}
<p>a water park</p> {<0><0><100><100>}
<p>a bucket water</p> {<41><34><55><86>}
<p>a young girl</p> {<46><33><79><71>}
<p>a swimsuit</p> {<54><34><76><52>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing sunglasses is holding an infant with a colorful hat in her arms 
CaptionToObject answer <p>A woman</p> {<36><34><83><100>}
<p>sunglasses</p> {<53><46><67><53>}
<p>an infant</p> {<39><64><68><100>}
<p>a colorful hat</p> {<43><64><61><81>}
<p>her arms</p> {<34><69><83><100>}<delim>{<38><89><61><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Three children sit on the grass , one laying down , one in overalls smiling and one in green looking through a tote bag 
CaptionToObject answer <p>Three children</p> {<38><16><62><79>}<delim>{<5><49><44><100>}<delim>{<48><26><90><90>}
<p>one</p> {<8><49><42><99>}<delim>{<38><16><62><79>}<delim>{<48><26><90><90>}
<p>overalls</p> {<38><41><62><79>}
<p>green</p> {<63><43><87><78>}
<p>a tote bag</p> {<69><58><96><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a green shirt and black helmet struggles with a man in jeans and a light blue shirt 
CaptionToObject answer <p>A woman</p> {<33><25><58><100>}
<p>a green shirt</p> {<34><45><58><82>}
<p>black helmet</p> {<38><26><48><44>}
<p>a man</p> {<33><25><79><100>}
<p>jeans</p> {<51><72><71><100>}
<p>a light blue shirt</p> {<50><39><76><80>}

Train: data epoch: [0]  [ 250/1000]  eta: 0:04:02  lr: 0.000003  loss: 1.3250  time: 0.3198  data: 0.0000  max mem: 30529
CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman in black hat , black button-down shirt , and red tie holds a drink in one hand while making an obscene gesture at crotch-level with the other hand 
CaptionToObject answer <p>black hat</p> {<33><0><64><16>}
<p>black button-down shirt</p> {<18><21><82><72>}
<p>red tie</p> {<47><24><63><81>}
<p>a drink</p> {<69><69><83><86>}
<p>one hand</p> {<66><68><85><85>}
<p>an obscene gesture</p> {<39><75><59><89>}
<p>the other hand</p> {<39><73><60><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in glasses with short , dark hair wearing light capri style pants , green t-shirt and sandals on a swing 
CaptionToObject answer <p>A woman</p> {<8><34><96><71>}
<p>glasses</p> {<17><41><32><44>}
<p>short , dark hair</p> {<16><38><31><49>}
<p>light capri style pants</p> {<42><41><77><72>}
<p>green t-shirt</p> {<14><49><47><72>}
<p>sandals</p> {<82><48><97><60>}
<p>a swing</p> {<0><47><61><67>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two older people , one man and one woman , sit on a bench with a cityscape in the background 
CaptionToObject answer <p>Two older people</p> {<72><48><86><79>}<delim>{<53><48><64><79>}
<p>one man</p> {<72><48><86><79>}
<p>one woman</p> {<53><48><64><79>}
<p>a bench</p> {<53><56><81><78>}
<p>a cityscape</p> {<2><1><100><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with black hair and glasses is holding a camera on a tripod 
CaptionToObject answer <p>A man</p> {<10><5><59><100>}
<p>black hair</p> {<15><3><32><33>}
<p>glasses</p> {<20><18><33><24>}
<p>a camera</p> {<54><40><69><60>}
<p>a tripod</p> {<44><64><69><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There are two wrestlers , one with a red helmet and another with a black helmet , are having their fight broken up by a referee 
CaptionToObject answer <p>two wrestlers</p> {<40><2><100><83>}<delim>{<12><24><100><90>}
<p>one</p> {<40><2><100><83>}
<p>a red helmet</p> {<40><2><100><83>}
<p>a black helmet</p> {<15><67><34><86>}
<p>their fight</p> {<0><11><58><83>}
<p>a referee</p> {<1><13><55><70>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A father is carrying his son on his shoulders as the son makes a funny face 
CaptionToObject answer <p>A father</p> {<1><42><99><100>}
<p>his son</p> {<4><18><51><78>}
<p>his shoulders</p> {<0><76><83><96>}
<p>the son</p> {<4><18><51><78>}
<p>a funny face</p> {<23><20><47><40>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a cowboy hate and black vest rides a horse in front of spectators 
CaptionToObject answer <p>A man</p> {<47><10><68><61>}
<p>a cowboy hate</p> {<52><10><63><20>}<delim>{<68><22><75><26>}<delim>{<11><44><18><50>}
<p>black vest</p> {<56><16><68><38>}
<p>a horse</p> {<28><32><100><89>}
<p>spectators</p> {<67><2><100><44>}<delim>{<6><45><21><90>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Young male looks on as another male sitting on a fence wraps his legs around a female in a zebra styled tank top and skirt 
CaptionToObject answer <p>Young male</p> {<56><28><75><79>}
<p>another male</p> {<56><28><75><79>}
<p>a fence</p> {<56><44><100><89>}
<p>his legs</p> {<56><52><76><79>}
<p>a female</p> {<60><35><74><95>}
<p>a zebra styled tank top</p> {<61><44><74><75>}
<p>skirt</p> {<63><45><71><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a white shirt and black pants is falling down onto a bed in front of a window facing the ocean 
CaptionToObject answer <p>A man</p> {<8><23><100><51>}
<p>a white shirt</p> {<34><30><60><51>}
<p>black pants</p> {<57><23><100><45>}
<p>a bed</p> {<0><71><100><100>}
<p>a window</p> {<29><3><83><76>}
<p>the ocean</p> {<30><45><81><74>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two street musicians , one wearing a mini leather cowboy hat , white t-shirt and black pants , holds a banjo while the other wears a orange shirt and black jeans leans against a fire hydrant 
CaptionToObject answer <p>Two street musicians</p> {<35><40><54><87>}<delim>{<31><12><83><96>}
<p>one</p> {<65><12><83><96>}
<p>a mini leather cowboy hat</p> {<39><41><47><49>}
<p>white t-shirt</p> {<36><50><52><68>}
<p>black pants</p> {<37><63><54><81>}
<p>a banjo</p> {<30><57><64><72>}
<p>the other wears</p> {<65><12><83><96>}
<p>a orange shirt</p> {<69><23><83><57>}
<p>black jeans</p> {<68><53><80><93>}
<p>a fire hydrant</p> {<74><54><88><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A dark-haired man , wearing sungalsses and a white shirt and jeans , is holding a guitar and sitting in front of a microphone 
CaptionToObject answer <p>A dark-haired man</p> {<14><32><71><100>}
<p>sungalsses</p> {<34><39><49><43>}
<p>a white shirt</p> {<11><47><61><85>}
<p>jeans</p> {<14><80><70><100>}
<p>a guitar</p> {<29><49><70><82>}
<p>a microphone</p> {<52><44><73><56>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a green paisley headscarf , green pants and a multi color shirt sits on a set of steps next to a blue striped backpack 
CaptionToObject answer <p>A woman</p> {<24><8><80><94>}
<p>a green paisley headscarf</p> {<39><8><66><21>}<delim>{<36><7><67><25>}
<p>green pants</p> {<24><47><81><71>}
<p>a multi color shirt</p> {<28><24><75><42>}
<p>a set of steps</p> {<2><1><100><100>}
<p>a blue striped backpack</p> {<10><46><29><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A girl in ripped jeans and a white t-shirt leads others in a synchronized dance 
CaptionToObject answer <p>A girl</p> {<25><8><100><99>}
<p>ripped jeans</p> {<29><51><87><91>}<delim>{<0><53><24><83>}
<p>a white t-shirt</p> {<0><28><22><53>}<delim>{<37><26><74><55>}
<p>others</p> {<0><17><28><85>}<delim>{<43><9><86><53>}
<p>a synchronized dance</p> {<0><17><28><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men and a bull are in a fenced area with dirt on the ground and a rope laying between the bull and men 
CaptionToObject answer <p>Two men</p> {<68><21><91><92>}<delim>{<23><53><54><91>}
<p>a bull</p> {<16><36><45><94>}
<p>dirt</p> {<1><76><100><100>}
<p>a rope</p> {<34><89><90><93>}
<p>the bull</p> {<16><36><45><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man wearing a suit and tie is in front of a podium with a microphone in front of him 
CaptionToObject answer <p>Man</p> {<18><9><70><88>}
<p>a suit</p> {<16><42><70><93>}
<p>tie</p> {<42><48><50><75>}
<p>a podium</p> {<18><74><100><100>}
<p>a microphone</p> {<47><44><59><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Young boy and girl squeeze tubes of frosting onto cupcakes with adults around them 
CaptionToObject answer <p>Young boy</p> {<43><8><82><88>}
<p>girl</p> {<1><1><47><100>}
<p>tubes of frosting</p> {<58><41><80><81>}<delim>{<35><73><47><98>}
<p>cupcakes</p> {<71><80><82><95>}
<p>adults</p> {<26><0><100><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Female with short hair and glasses looks on as another points to a line in a book 
CaptionToObject answer <p>Female</p> {<31><28><100><100>}
<p>short hair</p> {<52><27><82><54>}<delim>{<22><1><37><23>}
<p>glasses</p> {<22><17><37><29>}
<p>a line</p> {<14><72><44><91>}
<p>a book</p> {<14><72><44><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] There are two carts being driven by mules , each carrying some crops and people 
CaptionToObject answer <p>two carts</p> {<21><50><43><78>}<delim>{<53><37><84><79>}
<p>mules</p> {<81><45><89><57>}<delim>{<23><47><35><77>}
<p>each</p> {<51><19><84><78>}
<p>some crops</p> {<53><37><81><61>}<delim>{<51><35><85><61>}
<p>people</p> {<62><20><70><40>}<delim>{<29><39><37><60>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] The girl in the salmon colored bikini is standing next to two young people ; one is wearing a black outfit and the other is drinking pop 
CaptionToObject answer <p>The girl</p> {<1><20><31><100>}
<p>the salmon colored bikini</p> {<10><34><30><98>}
<p>two young people</p> {<56><15><77><94>}<delim>{<1><2><31><100>}<delim>{<74><8><99><82>}
<p>one</p> {<56><15><77><94>}
<p>a black outfit</p> {<56><27><78><93>}
<p>the other</p> {<74><6><98><84>}<delim>{<73><9><98><87>}
<p>pop</p> {<78><18><84><24>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in gray trousers is at a counter as a man in woman a farther down the aisle 
CaptionToObject answer <p>A man</p> {<6><42><36><96>}
<p>gray trousers</p> {<14><74><34><84>}
<p>a counter</p> {<1><44><13><100>}
<p>a man</p> {<60><59><73><93>}
<p>woman</p> {<69><59><88><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman in a plaid dress with a black bag looks out over a busy street while leaning on a rail 
CaptionToObject answer <p>A young woman</p> {<13><61><25><90>}
<p>a plaid dress</p> {<13><66><21><82>}
<p>a black bag</p> {<13><66><24><78>}
<p>over a busy street</p> {<33><71><100><78>}
<p>a rail</p> {<20><63><65><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt and brown pants is raking some in between two paved paths that are next to a field 
CaptionToObject answer <p>A man</p> {<26><29><59><76>}
<p>a blue shirt</p> {<31><32><53><49>}
<p>brown pants</p> {<27><43><51><72>}
<p>some</p> {<67><58><92><75>}
<p>between two paved paths</p> {<0><57><100><84>}
<p>a field</p> {<0><42><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Four youth and an elder man and woman playing in water just up to the bottom of man 's swim trunks 
CaptionToObject answer <p>Four youth</p> {<70><12><92><38>}<delim>{<72><70><85><90>}<delim>{<58><21><73><40>}<delim>{<52><19><64><39>}
<p>an elder man</p> {<21><30><44><82>}
<p>woman</p> {<8><69><30><94>}
<p>water</p> {<0><0><100><100>}
<p>man 's swim trunks</p> {<25><67><42><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman with a metallic purple shirt and black pants standing in a dry pool in a yoga pose 
CaptionToObject answer <p>A young woman</p> {<44><11><76><99>}
<p>a metallic purple shirt</p> {<50><23><76><41>}
<p>black pants</p> {<51><33><69><84>}
<p>a dry pool</p> {<1><14><100><99>}
<p>a yoga pose</p> {<44><11><76><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A kneeling person in a black coat , blue jeans and sunglasses hunches over and holds a camera to her eye , tilted sideways 
CaptionToObject answer <p>A kneeling person</p> {<2><2><100><99>}
<p>a black coat</p> {<30><3><96><96>}
<p>blue jeans</p> {<39><27><100><96>}
<p>sunglasses hunches</p> {<31><24><45><57>}
<p>a camera</p> {<35><36><64><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a white shirt with glasses is typing on his MacBook in front of a fashion ad with an attractive woman 
CaptionToObject answer <p>A man</p> {<36><30><100><100>}
<p>a white shirt</p> {<56><59><100><100>}
<p>glasses</p> {<73><44><88><51>}
<p>his MacBook</p> {<20><65><44><100>}
<p>a fashion ad</p> {<13><23><38><46>}
<p>an attractive woman</p> {<14><0><41><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman and a child are walking on a leaf-lined sidewalk , heading towards two people riding horses 
CaptionToObject answer <p>A woman</p> {<70><3><94><100>}
<p>a child</p> {<43><48><67><99>}
<p>a leaf-lined sidewalk</p> {<1><25><100><99>}<delim>{<1><24><72><100>}
<p>two people</p> {<29><2><37><20>}<delim>{<17><3><25><19>}
<p>horses</p> {<17><9><25><27>}<delim>{<19><10><24><26>}<delim>{<29><6><36><28>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man is standing beside a projection screen , and he is directing the attention of a certain area of the screen to other people sitting at tables to listen and watch 
CaptionToObject answer <p>A man</p> {<37><7><78><88>}
<p>a projection screen</p> {<70><0><100><37>}
<p>the screen</p> {<70><0><100><37>}
<p>other people</p> {<65><19><100><100>}<delim>{<46><27><80><100>}
<p>tables</p> {<0><64><57><83>}<delim>{<0><85><29><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An older man with a beard uses a hay broom to sweep the ground in front of cubed cardboard trash in a parking lot 
CaptionToObject answer <p>An older man</p> {<39><21><53><76>}
<p>a beard</p> {<46><26><49><31>}
<p>a hay broom</p> {<47><32><64><74>}
<p>cubed cardboard trash</p> {<67><34><91><72>}<delim>{<88><35><100><81>}
<p>a parking lot</p> {<0><46><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two children , a boy and a girl , sit on a swing overlooking trees 
CaptionToObject answer <p>Two children</p> {<29><31><62><81>}
<p>a boy</p> {<27><35><57><75>}
<p>a girl</p> {<29><31><62><81>}
<p>a swing</p> {<28><0><57><73>}
<p>trees</p> {<35><7><90><100>}<delim>{<1><50><29><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a flannel shirt and black pants is working on a new reed roof on top of a house 
CaptionToObject answer <p>A man</p> {<36><50><42><67>}
<p>a flannel shirt</p> {<38><53><43><59>}
<p>black pants</p> {<37><58><43><67>}
<p>a new reed roof</p> {<7><47><82><88>}
<p>a house</p> {<7><56><73><88>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A boy wearing a white apron has is arms out in a communal darts and craft room whilst a boy in blue looks on 
CaptionToObject answer <p>A boy</p> {<12><41><68><100>}
<p>a white apron</p> {<31><58><50><100>}
<p>is arms</p> {<44><59><69><91>}<delim>{<9><61><29><72>}
<p>craft room</p> {<0><1><100><100>}
<p>a boy</p> {<12><41><68><100>}
<p>blue</p> {<22><38><44><62>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with dark hair and a white shirt sitting at a table holding a young child with shorts and no shirt 
CaptionToObject answer <p>A woman</p> {<0><0><70><100>}
<p>dark hair</p> {<1><0><68><27>}
<p>a white shirt</p> {<0><29><37><100>}
<p>a table</p> {<78><58><100><89>}
<p>a young child</p> {<3><37><87><100>}
<p>shorts</p> {<37><88><84><100>}
<p>no shirt</p> {<13><63><74><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] there is a middle-aged women in red and shes kneeling down holding a little boy who looks like he could be her grandson the little boy is wearing a white long-sleeve shirt with blue pants the two of them are next to some grass and in front of a hill of dirt they look like they are posing for a family picture 
CaptionToObject answer <p>a middle-aged women</p> {<20><17><98><100>}
<p>a little boy</p> {<19><29><81><100>}
<p>her grandson</p> {<19><29><81><100>}
<p>the little boy</p> {<19><29><81><100>}
<p>a white long-sleeve shirt</p> {<21><52><76><81>}
<p>blue pants</p> {<30><82><58><100>}
<p>some grass</p> {<1><44><21><99>}
<p>a hill of dirt</p> {<47><8><100><77>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in red shorts is about to land in a body of water , he has one hand touching the water 
CaptionToObject answer <p>A man</p> {<36><14><62><64>}
<p>red shorts</p> {<51><34><58><39>}
<p>a body of water</p> {<1><45><100><100>}
<p>one hand</p> {<50><60><54><64>}
<p>the water</p> {<1><45><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man in a blue shirt with hand on forehead behind two cushions 
CaptionToObject answer <p>Man</p> {<68><16><100><50>}
<p>a blue shirt</p> {<69><27><100><51>}
<p>hand</p> {<86><21><97><34>}
<p>forehead</p> {<86><16><96><26>}
<p>two cushions</p> {<0><48><97><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing a gray jacket , black shirt , and gray pants is standing by a grill on a deck on a cloudy evening 
CaptionToObject answer <p>A man</p> {<39><31><100><94>}
<p>a gray jacket</p> {<45><42><100><70>}
<p>black shirt</p> {<45><42><100><70>}
<p>gray pants</p> {<63><68><94><100>}
<p>a grill</p> {<0><55><47><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in a jean jacket and wearing sunglasses and red scarf is juggling oranges near a gazebo and a house 
CaptionToObject answer <p>A woman</p> {<12><34><100><100>}
<p>a jean jacket</p> {<12><58><100><100>}
<p>sunglasses</p> {<45><42><66><47>}
<p>red scarf</p> {<38><54><74><91>}
<p>oranges</p> {<21><94><34><100>}<delim>{<37><17><50><27>}<delim>{<82><80><94><89>}
<p>a gazebo</p> {<0><18><23><47>}
<p>a house</p> {<1><23><99><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man and a girl are painting crafts at a table while a woman observes 
CaptionToObject answer <p>A man</p> {<2><27><45><65>}
<p>a girl</p> {<52><32><99><93>}
<p>crafts</p> {<30><56><36><63>}<delim>{<51><63><60><70>}
<p>a table</p> {<0><62><100><100>}
<p>a woman</p> {<54><3><83><64>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soldier , wearing fatigues playing the snare drum in the Army 's Marching Band with other members of the band in the background 
CaptionToObject answer <p>A soldier</p> {<5><21><66><99>}
<p>fatigues</p> {<5><21><66><99>}
<p>the snare drum</p> {<30><1><100><65>}
<p>the Army 's Marching Band</p> {<5><19><68><100>}<delim>{<59><56><100><100>}<delim>{<4><1><100><97>}
<p>other members of the band</p> {<5><19><68><100>}<delim>{<59><56><100><100>}<delim>{<4><1><100><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black woman in a white tank top , red pants , and white sneakers carries a plastic bag and walks down a sidewalk with paintings on one side 
CaptionToObject answer <p>A black woman</p> {<35><3><54><99>}
<p>a white tank top</p> {<38><16><50><46>}
<p>red pants</p> {<37><43><51><94>}
<p>white sneakers</p> {<37><90><53><99>}<delim>{<39><92><45><100>}
<p>a plastic bag</p> {<33><54><39><73>}
<p>paintings</p> {<24><20><32><50>}<delim>{<15><37><21><56>}<delim>{<20><21><26><49>}<delim>{<13><2><24><21>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man on stilts wearing a giant top hat stares down at a little girl in a red shirt 
CaptionToObject answer <p>A man</p> {<52><22><96><93>}
<p>stilts</p> {<50><46><96><93>}
<p>a giant top hat</p> {<55><22><74><37>}
<p>a little girl</p> {<6><57><26><95>}
<p>a red shirt</p> {<8><63><25><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An elderly woman is sitting at a restaurant table beneath a sign on the wall reading " Oh boy mom 's pancakes ! " 
CaptionToObject answer <p>An elderly woman</p> {<0><21><49><100>}
<p>a restaurant table</p> {<68><75><100><100>}
<p>a sign</p> {<12><0><77><45>}
<p>the wall</p> {<0><0><100><100>}
<p>Oh boy mom 's pancakes</p> {<36><7><75><39>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] An elderly person stands in the street during winter with evergreen tree branches in one hand and a cane in the other 
CaptionToObject answer <p>An elderly person</p> {<67><31><83><77>}
<p>the street</p> {<0><21><100><99>}
<p>evergreen tree branches</p> {<71><52><82><77>}
<p>one hand</p> {<72><49><75><54>}<delim>{<72><50><75><55>}
<p>a cane</p> {<67><51><71><75>}
<p>the other</p> {<68><49><70><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A horse has bucked in an arena and the rider is coming off of its back in midair in front of a crowd in the stands 
CaptionToObject answer <p>A horse</p> {<17><25><67><98>}
<p>an arena</p> {<57><51><98><71>}<delim>{<0><47><100><100>}
<p>the rider</p> {<22><13><46><45>}
<p>its back</p> {<22><35><41><69>}
<p>a crowd</p> {<0><46><100><73>}
<p>the stands</p> {<0><46><100><73>}<delim>{<23><7><45><45>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two hockey players on opposing teams , one in a red and white jersey and one in a blue and black jersey , are standing on the rink 
CaptionToObject answer <p>Two hockey players</p> {<18><11><76><67>}<delim>{<35><20><90><83>}
<p>opposing teams</p> {<18><11><76><67>}<delim>{<35><20><90><83>}
<p>one</p> {<35><20><90><83>}<delim>{<18><11><76><67>}
<p>a red and white jersey</p> {<39><28><85><67>}
<p>a blue and black jersey</p> {<25><15><72><58>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man reads to his son while mother spends time with the other child on the sofa 
CaptionToObject answer <p>Man</p> {<67><22><96><96>}
<p>his son</p> {<62><32><96><82>}<delim>{<22><47><34><94>}
<p>mother</p> {<14><24><40><95>}
<p>the other child</p> {<62><32><96><82>}
<p>the sofa</p> {<5><34><97><84>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a tan coat holding an infant and a young girl sitting on a brown couch 
CaptionToObject answer <p>A man</p> {<54><66><83><99>}
<p>a tan coat</p> {<54><71><84><99>}
<p>an infant</p> {<69><78><81><90>}
<p>a young girl</p> {<74><85><95><100>}
<p>a brown couch</p> {<13><78><74><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Lady with gray hair using cellphone and carrying a shopping bag in front of a boutique 
CaptionToObject answer <p>Lady</p> {<36><41><58><99>}
<p>gray hair</p> {<44><41><58><64>}
<p>cellphone</p> {<35><70><39><75>}
<p>a shopping bag</p> {<33><85><53><100>}
<p>a boutique</p> {<28><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a long-sleeve blue shirt is eating ice cream with his three daughter in a crowded place 
CaptionToObject answer <p>A man</p> {<59><47><73><94>}
<p>a long-sleeve blue shirt</p> {<60><53><70><73>}
<p>ice cream</p> {<69><54><73><58>}
<p>his three daughter</p> {<73><56><85><94>}<delim>{<89><62><100><93>}<delim>{<80><60><96><89>}
<p>a crowded place</p> {<47><56><61><79>}<delim>{<73><56><85><94>}<delim>{<41><59><50><73>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two workers are on a cherry-picker , one leaning out with a safety harness and the other smiling at the camera 
CaptionToObject answer <p>Two workers</p> {<24><7><67><97>}
<p>a cherry-picker</p> {<0><58><54><100>}
<p>one</p> {<24><7><67><97>}
<p>a safety harness</p> {<33><26><50><55>}
<p>the other</p> {<40><53><60><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Graffiti on a wall depicts children drawing the words " Brick City " on the wall 
CaptionToObject answer <p>Graffiti</p> {<25><1><100><99>}
<p>a wall</p> {<25><1><100><99>}
<p>children</p> {<62><6><100><98>}<delim>{<40><23><50><82>}<delim>{<45><37><58><91>}<delim>{<29><34><38><77>}<delim>{<35><19><43><77>}
<p>the words</p> {<40><10><54><33>}
<p>Brick City</p> {<40><11><54><34>}
<p>the wall</p> {<25><1><100><99>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little girl in a swimsuit on the beach at the edge of the water between large rocksA woman with 
CaptionToObject answer <p>A little girl</p> {<45><49><54><80>}
<p>a swimsuit</p> {<46><54><51><66>}
<p>the beach</p> {<0><64><100><100>}
<p>the edge of the water</p> {<1><63><100><82>}
<p>large rocks</p> {<59><9><100><46>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Man in gray sweatshirts stands in subway station with crowd of people as blue subway train goes by 
CaptionToObject answer <p>Man</p> {<38><34><51><100>}
<p>gray sweatshirts</p> {<39><43><50><73>}
<p>subway station</p> {<0><0><100><100>}
<p>crowd of people</p> {<38><34><51><100>}<delim>{<58><38><73><98>}<delim>{<57><32><100><100>}
<p>blue subway train</p> {<0><4><69><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A black or African descendant woman wearing an orange blouse with large earrings is checking her or looking at her cellphone while carrying a bag next to a bag in a chair with a man behind her in a blue shirt 
CaptionToObject answer <p>A black or African descendant woman</p> {<31><26><93><95>}
<p>an orange blouse</p> {<44><57><88><90>}
<p>large earrings</p> {<65><42><76><49>}<delim>{<46><42><57><48>}
<p>her cellphone</p> {<59><67><72><72>}
<p>a bag</p> {<29><73><58><100>}<delim>{<29><73><58><100>}
<p>a chair</p> {<13><69><40><100>}
<p>a man</p> {<64><13><100><100>}<delim>{<64><19><100><80>}
<p>a blue shirt</p> {<72><29><100><81>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two people dressed in athletic clothing walk down the street , while the taller of the two is holding a basketball 
CaptionToObject answer <p>Two people</p> {<20><19><43><100>}<delim>{<40><18><65><100>}
<p>athletic clothing</p> {<21><29><38><80>}<delim>{<41><28><58><80>}
<p>the street</p> {<53><41><100><100>}
<p>the taller of the two</p> {<40><18><65><100>}
<p>a basketball</p> {<56><54><64><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young man in glasses is drinking beer and holding the 10 of clubs to his forehead 
CaptionToObject answer <p>A young man</p> {<15><17><85><100>}
<p>glasses</p> {<29><33><50><39>}
<p>beer</p> {<16><73><29><92>}
<p>the 10 of clubs</p> {<27><22><35><35>}
<p>his forehead</p> {<33><25><46><33>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a red bag , a woman carrying a child and two others cross the street in a crosswalk 
CaptionToObject answer <p>A man</p> {<11><20><34><100>}
<p>a red bag</p> {<8><73><14><93>}<delim>{<8><72><15><94>}
<p>a woman</p> {<38><30><53><99>}
<p>a child</p> {<36><31><52><78>}
<p>two others</p> {<11><20><34><100>}<delim>{<52><32><65><75>}
<p>a crosswalk</p> {<36><38><70><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in yellow shorts and a red bandanna wrapped around her head is walking in the street in front of a blue house 
CaptionToObject answer <p>A woman</p> {<44><54><60><92>}
<p>yellow shorts</p> {<50><70><57><79>}
<p>a red bandanna</p> {<50><54><55><60>}
<p>her head</p> {<50><54><55><61>}
<p>a blue house</p> {<13><2><94><79>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A small kid wearing red and gray is opening a gray and white striped gift while sitting on a man 's lap who is wearing a blue shirt and both are in front of a window and a small Christmas tree 
CaptionToObject answer <p>A small kid</p> {<25><46><92><88>}
<p>red and gray</p> {<39><60><92><84>}
<p>a gray and white striped gift</p> {<62><67><76><77>}
<p>a man 's lap</p> {<45><73><85><93>}
<p>a blue shirt</p> {<50><50><100><68>}
<p>a window</p> {<0><1><26><31>}
<p>a small Christmas tree</p> {<25><1><100><44>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Little boy in orange shirt and black pants is playing in a park pond with his toy 
CaptionToObject answer <p>Little boy</p> {<9><27><32><78>}
<p>orange shirt</p> {<16><35><31><54>}
<p>black pants</p> {<19><52><29><76>}
<p>a park pond</p> {<0><56><100><100>}
<p>his toy</p> {<30><48><67><80>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a black shirt holding an empty glass and wearing a watch on his left wrist sits next to a man with glasses who is wearing a green shirt with a logo on the front 
CaptionToObject answer <p>A man</p> {<45><23><75><100>}
<p>a black shirt</p> {<50><40><75><69>}
<p>an empty glass</p> {<49><64><55><77>}
<p>a watch</p> {<63><77><68><81>}
<p>his left wrist</p> {<62><76><69><84>}
<p>a man</p> {<45><23><75><100>}<delim>{<19><25><44><100>}
<p>glasses</p> {<25><31><35><35>}
<p>a green shirt</p> {<21><41><42><66>}
<p>the front</p> {<21><41><42><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing a white top , white tennis skirt and white tennis shoes serving on a grass tennis court while two line judges watch 
CaptionToObject answer <p>A woman</p> {<34><25><55><85>}
<p>a white top</p> {<44><31><56><55>}
<p>white tennis skirt</p> {<34><22><54><85>}
<p>white tennis shoes</p> {<41><71><52><84>}<delim>{<41><77><48><85>}
<p>a grass tennis court</p> {<1><4><100><100>}
<p>two line judges</p> {<52><13><62><58>}<delim>{<84><26><98><66>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two women are sitting in front of a table where they have many items on display such as parts of fish 
CaptionToObject answer <p>Two women</p> {<25><40><43><67>}<delim>{<7><45><25><91>}
<p>a table</p> {<31><51><100><100>}
<p>many items</p> {<17><66><32><83>}<delim>{<30><65><42><84>}<delim>{<35><48><100><72>}
<p>display</p> {<16><52><100><83>}
<p>parts of fish</p> {<63><18><100><57>}<delim>{<30><53><100><72>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A small boy in jeans and a white shirt holding a piece of paper in a black vehicle 
CaptionToObject answer <p>A small boy</p> {<11><27><43><85>}<delim>{<14><27><46><98>}
<p>jeans</p> {<15><62><39><93>}
<p>a white shirt</p> {<12><41><44><65>}
<p>a piece of paper</p> {<25><49><43><59>}
<p>a black vehicle</p> {<0><0><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young woman is wearing a red shirt , black riding helmet , black pants , and black shoes , while riding in a saddle on a white horse 
CaptionToObject answer <p>A young woman</p> {<46><18><58><59>}
<p>a red shirt</p> {<45><22><57><39>}
<p>black riding helmet</p> {<47><18><54><25>}
<p>black pants</p> {<47><35><56><59>}
<p>black shoes</p> {<47><52><54><59>}
<p>a saddle</p> {<44><37><56><51>}
<p>a white horse</p> {<20><30><76><83>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman in full bike gear pedals her road bike on a street near a field 
CaptionToObject answer <p>A woman</p> {<52><24><91><97>}
<p>full bike gear</p> {<56><24><64><40>}<delim>{<71><87><84><98>}<delim>{<66><26><91><57>}
<p>her road bike</p> {<44><46><100><100>}
<p>a street</p> {<1><83><100><100>}
<p>a field</p> {<1><2><100><94>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Woman with hair in low ponytail , with the number 43 on her leg , is running wearing green shoes and a green outfit 
CaptionToObject answer <p>Woman</p> {<7><6><99><95>}
<p>hair</p> {<38><6><56><22>}
<p>low ponytail</p> {<47><15><55><21>}
<p>the number 43</p> {<21><69><25><76>}
<p>her leg</p> {<16><48><47><85>}
<p>green shoes</p> {<6><85><29><92>}
<p>a green outfit</p> {<29><20><66><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing blue pants , a white helmet , and a green-striped shirt is shown on skis in midair , against a blue sky with a single puffy cloud 
CaptionToObject answer <p>A man</p> {<46><22><63><59>}
<p>blue pants</p> {<46><36><59><54>}
<p>a white helmet</p> {<54><22><65><33>}
<p>a green-striped shirt</p> {<45><26><60><40>}
<p>skis</p> {<36><46><69><65>}
<p>a single puffy cloud</p> {<31><83><54><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A young boy wearing a white martial arts gi with a yellow belt jumps high in the air as a girl in a yellow outfit watches 
CaptionToObject answer <p>A young boy</p> {<9><21><100><90>}
<p>a white martial arts</p> {<9><21><100><90>}
<p>a yellow belt</p> {<43><50><62><55>}
<p>a girl</p> {<1><55><24><95>}
<p>a yellow outfit</p> {<1><62><24><95>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Two men are standing : one has body modifications and the other is wearing a hat 
CaptionToObject answer <p>Two men</p> {<35><34><75><100>}<delim>{<0><8><34><100>}
<p>one</p> {<33><32><81><99>}
<p>body modifications</p> {<35><34><75><100>}<delim>{<42><38><58><62>}
<p>the other</p> {<0><8><34><100>}
<p>a hat</p> {<1><12><16><22>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with a bright reflective vest and headphones is standing next to a man with a suit and scarf 
CaptionToObject answer <p>A man</p> {<50><14><100><100>}
<p>a bright reflective vest</p> {<60><51><97><100>}
<p>headphones</p> {<63><15><85><40>}
<p>a man</p> {<3><4><50><100>}
<p>a suit</p> {<3><32><53><99>}
<p>scarf</p> {<20><24><39><92>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man with long blond-hair and sunglasses is sitting in the grass holding a beverage 
CaptionToObject answer <p>A man</p> {<15><4><99><100>}
<p>long blond-hair</p> {<35><4><95><45>}
<p>sunglasses</p> {<49><16><74><25>}
<p>the grass</p> {<0><48><100><100>}
<p>a beverage</p> {<23><54><36><68>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a gray jacket and cap is holding a sign with pictures of food items 
CaptionToObject answer <p>A man</p> {<35><46><67><94>}
<p>a gray jacket</p> {<35><55><66><87>}
<p>cap</p> {<44><47><61><56>}
<p>a sign</p> {<23><8><95><40>}
<p>pictures of food items</p> {<24><12><52><32>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Middle-aged man and woman , she is holding a log , he is using a drill on the log 
CaptionToObject answer <p>Middle-aged man</p> {<40><24><95><69>}
<p>woman</p> {<1><11><68><100>}
<p>a log</p> {<48><69><67><91>}
<p>a drill</p> {<51><61><66><70>}
<p>the log</p> {<46><69><69><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Male with dark blond-hair , eyeglasses , watch , gray shirt , with a brown folded bag and white coffee cup on a white table 
CaptionToObject answer <p>Male</p> {<33><14><91><94>}
<p>dark blond-hair</p> {<59><14><75><37>}
<p>eyeglasses</p> {<59><23><72><28>}
<p>gray shirt</p> {<39><36><81><73>}
<p>a brown folded bag</p> {<47><65><75><87>}
<p>white coffee cup</p> {<29><66><41><81>}
<p>a white table</p> {<1><65><99><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] People sit in a crowded stadium watching some sort of event - there is a woman with red-hair in the foreground and in the bottom left corner two people stare directly at the picture taker 
CaptionToObject answer <p>People</p> {<1><50><100><100>}
<p>a woman</p> {<49><67><79><100>}
<p>red-hair</p> {<51><65><73><93>}
<p>the bottom left corner</p> {<79><65><100><100>}
<p>two people</p> {<79><65><100><100>}<delim>{<69><58><84><97>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] One man places his hand on the back of a black-haired man wearing yellow earmuffs and a red windbreaker 
CaptionToObject answer <p>One man</p> {<32><19><94><100>}
<p>his hand</p> {<48><57><75><87>}
<p>the back of a black-haired man</p> {<42><59><94><100>}
<p>yellow earmuffs</p> {<49><21><77><48>}
<p>a red windbreaker</p> {<32><41><94><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man wearing an orange shirt , camouflage pants , and a protective mask uses a chainsaw to chop down a tree on the sidewalk 
CaptionToObject answer <p>A man</p> {<10><42><35><91>}
<p>an orange shirt</p> {<11><47><34><69>}
<p>camouflage pants</p> {<10><63><27><86>}
<p>a protective mask</p> {<26><43><38><50>}
<p>a chainsaw</p> {<22><65><34><79>}
<p>a tree</p> {<1><0><100><91>}
<p>the sidewalk</p> {<0><49><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A brown and white dog walking away from a black and brown dog with a tennis ball in its mouth while standing in water 
CaptionToObject answer <p>A brown and white dog</p> {<59><7><87><62>}
<p>a black and brown dog</p> {<22><25><48><92>}
<p>a tennis ball</p> {<29><52><37><61>}
<p>its mouth</p> {<29><51><37><62>}
<p>water</p> {<0><10><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A lady kneeling taking a photo with a camera and a man wearing jeans 
CaptionToObject answer <p>A lady</p> {<28><2><74><68>}
<p>a photo</p> {<52><8><75><20>}
<p>a camera</p> {<53><8><74><21>}
<p>a man</p> {<1><1><37><100>}
<p>jeans</p> {<0><22><34><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] On a sidewalk , tall man in a black shirt and a police officer with their backs to the viewer walk past a man in a white t-shirt , black shorts , and sandals 
CaptionToObject answer <p>a sidewalk</p> {<1><37><100><100>}
<p>tall man</p> {<35><13><71><89>}
<p>a black shirt</p> {<35><20><69><50>}
<p>a police officer</p> {<70><23><96><83>}
<p>their backs</p> {<70><23><96><83>}<delim>{<39><21><63><51>}
<p>the viewer</p> {<5><25><32><90>}
<p>a man</p> {<5><25><32><90>}
<p>a white t-shirt</p> {<6><34><30><58>}
<p>black shorts</p> {<7><56><23><75>}<delim>{<6><54><26><75>}
<p>sandals</p> {<11><85><19><91>}<delim>{<11><83><19><91>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman wearing glasses and an orange dress is standing with another woman wearing glasses and a green dress 
CaptionToObject answer <p>A woman</p> {<10><8><48><100>}
<p>glasses</p> {<26><26><43><41>}<delim>{<59><19><73><27>}<delim>{<61><20><74><25>}
<p>an orange dress</p> {<8><9><45><100>}
<p>another woman</p> {<46><12><86><100>}
<p>a green dress</p> {<47><22><86><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in beige clothes is sitting on a bus with a messenger bag slung across his chest , while a woman with a purse stands near him 
CaptionToObject answer <p>A man</p> {<5><13><50><100>}
<p>beige clothes</p> {<10><29><51><81>}
<p>a messenger bag</p> {<20><46><40><76>}
<p>his chest</p> {<22><42><46><60>}
<p>a woman</p> {<68><0><100><100>}
<p>a purse</p> {<72><1><94><51>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A yellow muscle car is burning rubber while a man in the car with blond-hair looks at the tire 
CaptionToObject answer <p>A yellow muscle car</p> {<11><2><100><100>}
<p>rubber</p> {<34><36><54><88>}
<p>a man</p> {<79><13><99><49>}
<p>the car</p> {<11><2><100><100>}
<p>blond-hair</p> {<81><14><90><31>}
<p>the tire</p> {<34><39><54><76>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a green shirt , black pants , black hat , and a backpack , acting like he was pushing a stone wall 
CaptionToObject answer <p>A man</p> {<40><44><70><80>}
<p>a green shirt</p> {<42><48><62><64>}
<p>black pants</p> {<45><63><68><78>}
<p>black hat</p> {<54><49><60><54>}
<p>a backpack</p> {<52><52><67><63>}
<p>a stone wall</p> {<4><2><76><82>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A soccer player for Eik leaps high in the air to kick the ball , pursued by several opponents and a teammate 
CaptionToObject answer <p>A soccer player</p> {<17><0><56><60>}
<p>Eik</p> {<17><0><56><60>}
<p>the ball</p> {<49><11><59><23>}
<p>several opponents</p> {<59><31><71><78>}<delim>{<35><27><56><98>}
<p>a teammate</p> {<68><31><87><92>}<delim>{<59><31><71><78>}<delim>{<35><27><56><98>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a cap , sweatshirt , and jeans works on wooden banisters 
CaptionToObject answer <p>A man</p> {<28><31><54><98>}
<p>a cap</p> {<38><30><46><42>}
<p>sweatshirt</p> {<29><34><51><63>}
<p>jeans</p> {<29><61><47><98>}
<p>wooden banisters</p> {<46><47><99><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] Several men are standing on a city street , and one man in a yellow shirt is approaching a silver car 
CaptionToObject answer <p>Several men</p> {<68><39><72><60>}<delim>{<21><41><26><56>}<delim>{<39><42><43><58>}<delim>{<45><43><50><58>}<delim>{<31><44><34><58>}
<p>a city street</p> {<1><53><100><100>}
<p>one man</p> {<67><39><73><58>}
<p>a yellow shirt</p> {<67><41><73><52>}
<p>a silver car</p> {<54><47><86><61>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A guy is playing the bagpipes while standing next to a woman in a light blue outfit with her belly button showing 
CaptionToObject answer <p>A guy</p> {<39><32><99><100>}
<p>the bagpipes</p> {<62><3><100><100>}
<p>a woman</p> {<1><32><43><100>}<delim>{<0><33><41><84>}
<p>a light blue outfit</p> {<2><55><40><100>}
<p>her belly button</p> {<13><82><17><85>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A woman with pigtails is riding a yellow and blue bicycle in the dirt while wearing a blue outfit 
CaptionToObject answer <p>A woman</p> {<13><8><75><100>}
<p>pigtails</p> {<37><29><59><58>}
<p>a yellow and blue bicycle</p> {<13><72><72><100>}
<p>the dirt</p> {<1><63><100><100>}
<p>a blue outfit</p> {<23><29><72><87>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] two people wearing white shirts and jeans each carrying a skateboard 
CaptionToObject answer <p>two people</p> {<55><1><100><100>}<delim>{<12><1><47><91>}
<p>white shirts</p> {<19><0><39><42>}<delim>{<72><1><98><37>}
<p>jeans</p> {<58><33><91><100>}<delim>{<21><40><45><83>}
<p>each</p> {<55><1><100><100>}<delim>{<12><1><47><91>}
<p>a skateboard</p> {<72><37><100><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A dark-haired woman in a black bra sleeping in the bed with tan sheets and creme blanket with a blond-haired baby in a white and blue shirt 
CaptionToObject answer <p>A dark-haired woman</p> {<0><10><97><100>}
<p>a black bra</p> {<41><20><67><57>}
<p>the bed</p> {<45><52><97><100>}
<p>tan sheets</p> {<0><6><49><100>}
<p>creme blanket</p> {<1><7><25><100>}
<p>a blond-haired baby</p> {<0><41><60><100>}
<p>a white and blue shirt</p> {<27><57><47><100>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in a blue shirt watches a man in a black shirt and jeans lean against a shovel that 's embedded in a patch of dirt in a garden 
CaptionToObject answer <p>A man</p> {<68><25><87><97>}
<p>a blue shirt</p> {<73><36><87><61>}
<p>a man</p> {<68><25><87><97>}<delim>{<17><33><36><83>}
<p>a black shirt</p> {<17><36><33><54>}
<p>jeans</p> {<17><49><29><79>}
<p>a shovel</p> {<31><54><38><80>}
<p>a patch of dirt</p> {<26><52><98><93>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A man in camo pants and a blue and white shirt running on a concrete surface with other men dressed the same running behind him 
CaptionToObject answer <p>A man</p> {<9><13><53><92>}
<p>camo pants</p> {<13><47><48><85>}<delim>{<45><44><65><61>}
<p>a blue and white shirt</p> {<29><23><44><48>}
<p>a concrete surface</p> {<1><47><100><100>}
<p>other men</p> {<9><13><53><92>}
<p>the same</p> {<45><28><67><63>}

CaptionToObject instruction <Img><ImageHere></Img> [detection] A little boy is playing with a water squirting toy in the swimming pool as others around him watch 
CaptionToObject answer <p>A little boy</p> {<22><48><42><91>}
<p>a water</p> {<1><49><100><100>}
<p>toy</p> {<33><52><50><69>}
<p>the swimming pool</p> {<1><49><100><100>}
<p>others</p> {<51><1><63><46>}

| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 0:37:22  lr: 0.000001  loss: 3.6249  time: 2.2424  data: 0.0000  max mem: 24877
Train: data epoch: [0]  [  50/1000]  eta: 0:04:53  lr: 0.000001  loss: 2.8552  time: 0.2708  data: 0.0000  max mem: 25735
Train: data epoch: [0]  [ 100/1000]  eta: 0:04:21  lr: 0.000002  loss: 2.0142  time: 0.2696  data: 0.0000  max mem: 25735
Train: data epoch: [0]  [ 150/1000]  eta: 0:04:01  lr: 0.000002  loss: 1.9274  time: 0.2697  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 200/1000]  eta: 0:03:44  lr: 0.000003  loss: 1.3062  time: 0.2690  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 250/1000]  eta: 0:03:28  lr: 0.000003  loss: 1.2751  time: 0.2718  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 300/1000]  eta: 0:03:14  lr: 0.000004  loss: 1.1853  time: 0.2733  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 350/1000]  eta: 0:02:59  lr: 0.000004  loss: 1.1292  time: 0.2705  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 400/1000]  eta: 0:02:45  lr: 0.000005  loss: 1.0770  time: 0.2671  data: 0.0000  max mem: 25834
Train: data epoch: [0]  [ 450/1000]  eta: 0:02:31  lr: 0.000005  loss: 0.8868  time: 0.2712  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 500/1000]  eta: 0:02:17  lr: 0.000005  loss: 0.8305  time: 0.2712  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 550/1000]  eta: 0:02:03  lr: 0.000006  loss: 1.0108  time: 0.2718  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 600/1000]  eta: 0:01:49  lr: 0.000006  loss: 1.0709  time: 0.2698  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 650/1000]  eta: 0:01:35  lr: 0.000007  loss: 1.0387  time: 0.2710  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 700/1000]  eta: 0:01:22  lr: 0.000007  loss: 1.0618  time: 0.2700  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 750/1000]  eta: 0:01:08  lr: 0.000008  loss: 0.8773  time: 0.2672  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 800/1000]  eta: 0:00:55  lr: 0.000008  loss: 1.1117  time: 0.2702  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 850/1000]  eta: 0:00:41  lr: 0.000009  loss: 1.0995  time: 0.2707  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 900/1000]  eta: 0:00:27  lr: 0.000009  loss: 1.0520  time: 0.2686  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 950/1000]  eta: 0:00:13  lr: 0.000010  loss: 0.9702  time: 0.2694  data: 0.0000  max mem: 25867
Train: data epoch: [0]  [ 999/1000]  eta: 0:00:00  lr: 0.000010  loss: 1.1442  time: 0.2711  data: 0.0000  max mem: 25867
Train: data epoch: [0] Total time: 0:04:35 (0.2752 s / it)
Train: data epoch: [1]  [   0/1000]  eta: 0:04:25  lr: 0.000010  loss: 1.1457  time: 0.2658  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [  50/1000]  eta: 0:04:16  lr: 0.000010  loss: 1.0289  time: 0.2689  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [ 100/1000]  eta: 0:04:03  lr: 0.000010  loss: 0.9328  time: 0.2704  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [ 150/1000]  eta: 0:03:49  lr: 0.000010  loss: 0.8438  time: 0.2691  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [ 200/1000]  eta: 0:03:35  lr: 0.000010  loss: 0.9749  time: 0.2699  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [ 250/1000]  eta: 0:03:22  lr: 0.000010  loss: 1.1666  time: 0.2696  data: 0.0000  max mem: 25867
Train: data epoch: [1]  [ 300/1000]  eta: 0:03:08  lr: 0.000010  loss: 0.9222  time: 0.2727  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 350/1000]  eta: 0:02:55  lr: 0.000010  loss: 1.0851  time: 0.2687  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 400/1000]  eta: 0:02:41  lr: 0.000010  loss: 1.1344  time: 0.2692  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 450/1000]  eta: 0:02:28  lr: 0.000010  loss: 1.0713  time: 0.2687  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 500/1000]  eta: 0:02:14  lr: 0.000010  loss: 1.0215  time: 0.2702  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 550/1000]  eta: 0:02:01  lr: 0.000010  loss: 0.5961  time: 0.2701  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 600/1000]  eta: 0:01:49  lr: 0.000010  loss: 1.1635  time: 0.2704  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 650/1000]  eta: 0:01:35  lr: 0.000010  loss: 1.1265  time: 0.2677  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 700/1000]  eta: 0:01:22  lr: 0.000010  loss: 1.0952  time: 0.2691  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 750/1000]  eta: 0:01:08  lr: 0.000010  loss: 1.0773  time: 0.2694  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 800/1000]  eta: 0:00:54  lr: 0.000010  loss: 0.8741  time: 0.2702  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 850/1000]  eta: 0:00:40  lr: 0.000010  loss: 1.0277  time: 0.2687  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 900/1000]  eta: 0:00:27  lr: 0.000010  loss: 0.8129  time: 0.2707  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 950/1000]  eta: 0:00:13  lr: 0.000010  loss: 0.9746  time: 0.2706  data: 0.0000  max mem: 25908
Train: data epoch: [1]  [ 999/1000]  eta: 0:00:00  lr: 0.000010  loss: 1.0638  time: 0.2720  data: 0.0000  max mem: 25908
Train: data epoch: [1] Total time: 0:04:32 (0.2728 s / it)
Train: data epoch: [2]  [   0/1000]  eta: 0:04:28  lr: 0.000010  loss: 1.1418  time: 0.2681  data: 0.0000  max mem: 25908
Train: data epoch: [2]  [  50/1000]  eta: 0:04:15  lr: 0.000010  loss: 0.9855  time: 0.2672  data: 0.0000  max mem: 25908
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 1:43:10  lr: 0.000001  loss: 1.9175  time: 6.1904  data: 0.0000  max mem: 34315
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[1]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 0:42:02  lr: 0.000001  loss: 1.8501  time: 2.5226  data: 0.0000  max mem: 26021
Train: data epoch: [0]  [  50/1000]  eta: 0:04:44  lr: 0.000001  loss: 2.1095  time: 0.2519  data: 0.0000  max mem: 27992
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[1]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 3:01:36  lr: 0.000001  loss: 1.7835  time: 10.8961  data: 0.0000  max mem: 18984
Train: data epoch: [0]  [  50/1000]  eta: 0:05:44  lr: 0.000001  loss: 2.1917  time: 0.1041  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 100/1000]  eta: 0:03:37  lr: 0.000002  loss: 0.4186  time: 0.1107  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 150/1000]  eta: 0:02:46  lr: 0.000002  loss: 1.0442  time: 0.1034  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 200/1000]  eta: 0:02:18  lr: 0.000003  loss: 0.4748  time: 0.1038  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 250/1000]  eta: 0:01:59  lr: 0.000003  loss: 3.6558  time: 0.1046  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 300/1000]  eta: 0:01:45  lr: 0.000004  loss: 1.6074  time: 0.1049  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 350/1000]  eta: 0:01:33  lr: 0.000004  loss: 2.3343  time: 0.1000  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 400/1000]  eta: 0:01:23  lr: 0.000005  loss: 1.7940  time: 0.1051  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 450/1000]  eta: 0:01:14  lr: 0.000005  loss: 1.2360  time: 0.1066  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 500/1000]  eta: 0:01:06  lr: 0.000005  loss: 1.6688  time: 0.1040  data: 0.0000  max mem: 19793
Train: data epoch: [0]  [ 550/1000]  eta: 0:00:58  lr: 0.000006  loss: 0.7130  time: 0.1046  data: 0.0000  max mem: 19793
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[4], [4]]
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 5:29:17  lr: 0.000001  loss: 1.1560  time: 19.7575  data: 0.0000  max mem: 23187
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 1, world 2): env://
| distributed init (rank 0, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
| distributed init (rank 0, world 2): env://
| distributed init (rank 1, world 2): env://
trainable params: 27262976 || all params: 8057524224 || trainable%: 0.33835425426081844
Position interpolate from 16x16 to 32x32
Load Minigpt-4-LLM Checkpoint: /home/users/nus/idmwyk/scratch/temp/output/saved-ckpt/minigptv4/stage1/20240907183/checkpoint_10.pth
model arch:
 MiniGPTv4(
  (llama_model): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlamaForCausalLM(
        (model): LlamaModel(
          (embed_tokens): Embedding(128256, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): Linear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=4096, bias=False)
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): Linear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_A): Linear(in_features=4096, out_features=64, bias=False)
                  (lora_B): Linear(in_features=64, out_features=1024, bias=False)
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            )
          )
          (norm): LlamaRMSNorm((4096,), eps=1e-05)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (lm_head): CastOutputToFloat(
          (0): Linear(in_features=4096, out_features=128256, bias=False)
        )
      )
    )
  )
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (local_attn): LocalAttention(
    (txt): Linear(in_features=4096, out_features=1408, bias=True)
    (img): Linear(in_features=1408, out_features=1408, bias=True)
  )
  (llama_proj): Linear(in_features=5632, out_features=4096, bias=True)
)
batch sizes [[2]]
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight
module.llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight
module.local_attn.txt.weight
module.local_attn.txt.bias
module.local_attn.img.weight
module.local_attn.img.bias
module.llama_proj.weight
module.llama_proj.bias
Train: data epoch: [0]  [   0/1000]  eta: 3:32:13  lr: 0.000001  loss: 0.8405  time: 12.7330  data: 0.0000  max mem: 23878
Train: data epoch: [0]  [  50/1000]  eta: 0:08:26  lr: 0.000001  loss: 1.1595  time: 0.2464  data: 0.0000  max mem: 24859
Train: data epoch: [0]  [ 100/1000]  eta: 0:05:54  lr: 0.000002  loss: 2.0751  time: 0.2518  data: 0.0000  max mem: 25286
Train: data epoch: [0]  [ 150/1000]  eta: 0:04:54  lr: 0.000002  loss: 2.6261  time: 0.2509  data: 0.0000  max mem: 25286
Train: data epoch: [0]  [ 200/1000]  eta: 0:04:18  lr: 0.000003  loss: 0.8987  time: 0.2544  data: 0.0000  max mem: 25594
Train: data epoch: [0]  [ 250/1000]  eta: 0:04:00  lr: 0.000003  loss: 0.5719  time: 0.4044  data: 0.0000  max mem: 25594
Train: data epoch: [0]  [ 300/1000]  eta: 0:03:36  lr: 0.000004  loss: 0.1750  time: 0.2494  data: 0.0000  max mem: 25594
Train: data epoch: [0]  [ 350/1000]  eta: 0:03:15  lr: 0.000004  loss: 0.7201  time: 0.2499  data: 0.0000  max mem: 25664
Train: data epoch: [0]  [ 400/1000]  eta: 0:02:56  lr: 0.000005  loss: 0.7550  time: 0.2513  data: 0.0000  max mem: 25664
Train: data epoch: [0]  [ 450/1000]  eta: 0:02:38  lr: 0.000005  loss: 0.7677  time: 0.2498  data: 0.0000  max mem: 26425
Train: data epoch: [0]  [ 500/1000]  eta: 0:02:25  lr: 0.000005  loss: 0.4597  time: 0.3992  data: 0.0000  max mem: 26425
